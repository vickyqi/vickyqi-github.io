<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Vicky's Blog]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://vickyqi.com/"/>
  <updated>2015-10-29T13:59:30.000Z</updated>
  <id>http://vickyqi.com/</id>
  
  <author>
    <name><![CDATA[Vicky]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[JDK并发工具类源码学习系列——ConcurrentLinkedQueue]]></title>
    <link href="http://vickyqi.com/2015/10/29/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentLinkedQueue/"/>
    <id>http://vickyqi.com/2015/10/29/JDK并发工具类源码学习系列——ConcurrentLinkedQueue/</id>
    <published>2015-10-29T13:51:00.000Z</published>
    <updated>2015-10-29T13:59:30.000Z</updated>
    <content type="html"><![CDATA[<p>ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait－free”算法来实现，该算法在Michael &amp; Scott算法上进行了一些修改, Michael &amp; Scott算法的详细信息可以参见<a href="http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf" target="_blank" rel="external">参考资料一</a>。<br><a id="more"></a><br>上一篇文章介绍了JDK java.util.concurrent包下很重要的一个类：<a href="http://vickyqi.com/2015/10/26/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentHashMap/">ConcurrentHashMap</a>，今天来看下另一个重要的类——ConcurrentLinkedQueue。<br>在多线程编程环境下并发安全队列是不可或缺的一个重要工具类，为了实现并发安全可以有两种方式：一种是阻塞式的，例如：LinkedBlockingQueue；另一种即是我们将要探讨的非阻塞式，例如：ConcurrentLinkedQueue。相比较于阻塞式，非阻塞的最显著的优点就是性能，非阻塞式算法使用CAS来原子性的更新数据，避免了加锁的时间，同时也保证了数据的一致性。</p>
<h4 id="简单介绍"><strong>简单介绍</strong></h4><p>ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait－free”算法来实现，该算法在Michael &amp; Scott算法上进行了一些修改, Michael &amp; Scott算法的详细信息可以参见<a href="http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf" target="_blank" rel="external">参考资料一</a>。</p>
<h4 id="结构预览"><strong>结构预览</strong></h4><p>首先看看结构图：</p>
<p><strong>图1：ConcurrentLinkedQueue结构图：</strong><br><img src="http://7xnnj7.com1.z0.glb.clouddn.com/blogConcurrentLinkedQueue%E7%BB%93%E6%9E%84%E5%9B%BE.png" alt="ConcurrentLinkedQueue结构图"><br>从图中可以看到ConcurrentLinkedQueue中包含两个内部类：Node&lt;E&gt;和Itr。Node&lt;E&gt;用来表示ConcurrentLinkedQueue链表中的一个节点，通过Node&lt;E&gt;的next字段指向下一个节点，从而形成一个链表结构；Itr实现Iterator&lt;E&gt;接口，用来遍历ConcurrentLinkedQueue。ConcurrentLinkedQueue中的方法不多，其中最主要的两个方法是：offer(E)和poll()，分别实现队列的两个重要的操作：入队和出队。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>offer(E)</td>
<td>插入一个元素到队列尾部</td>
</tr>
<tr>
<td>poll()</td>
<td>从队列头部取出一个元素</td>
</tr>
<tr>
<td>add(E)</td>
<td>同offer(E)</td>
</tr>
<tr>
<td>peek()</td>
<td>获取头部元素，但不删除</td>
</tr>
<tr>
<td>isEmpty()</td>
<td>判断队列是否为空</td>
</tr>
<tr>
<td>size()</td>
<td>获取队列长度(元素个数)</td>
</tr>
<tr>
<td>contains(Object)</td>
<td>判断队列是否包含指定元素</td>
</tr>
<tr>
<td>remove(Object)</td>
<td>删除队列中指定元素</td>
</tr>
<tr>
<td>toArray(T[])</td>
<td>将队列的元素复制到一个数组</td>
</tr>
<tr>
<td>iterator()</td>
<td>返回一个可遍历该队列的迭代器</td>
</tr>
</tbody>
</table>
<p>下面会着重分析offer(E)和poll()两个方法，同时会讲解remove(Object)和iterator()方法。</p>
<h4 id="常用方法解读"><strong>常用方法解读</strong></h4><h5 id="入队——offer"><strong>入队——offer</strong></h5><p>首先看看入队操作，由于是无阻塞的队列，所以整个入队操作是在无锁模式下进行的，下面来分析下JDK到底是如何实现无锁并保证安全性的。<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line"> * Inserts the specified element at the tail of this queue.</span><br><span class="line"> *</span><br><span class="line"> * <span class="doctag">@return</span> &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;<span class="doctag">@link</span> Queue#offer&#125;)</span><br><span class="line"> * <span class="doctag">@throws</span> NullPointerException if the specified element is null</span><br><span class="line"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">boolean</span> <span class="title">offer</span><span class="params">(E e)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (e == <span class="keyword">null</span>) <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    Node&lt;E&gt; n = <span class="keyword">new</span> Node&lt;E&gt;(e, <span class="keyword">null</span>);</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;<span class="comment">//①</span></span><br><span class="line">        Node&lt;E&gt; t = tail;<span class="comment">//②</span></span><br><span class="line">        Node&lt;E&gt; s = t.getNext();<span class="comment">//②</span></span><br><span class="line">        <span class="keyword">if</span> (t == tail) &#123;<span class="comment">//③</span></span><br><span class="line">            <span class="keyword">if</span> (s == <span class="keyword">null</span>) &#123;<span class="comment">//④</span></span><br><span class="line">                <span class="keyword">if</span> (t.casNext(s, n)) &#123;<span class="comment">//⑥</span></span><br><span class="line">                    casTail(t, n);<span class="comment">//⑦</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                casTail(t, s);<span class="comment">//⑤</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>代码不长，但是思路还是很巧妙的，下面我们逐句深入分析每一行代码。<code>if (e == null) throw new NullPointerException(); Node<e> n = new Node<e>(e, null);</e></e></code>检查NULL，避免NullPointerException，然后创建一个Node，该Node的item为传入的参数e，next为NULL。<code>for (;;) {}</code>接着是一个死循环，死循环保证该入队操作能够一直重试直至入队成功。<code>Node<e> t = tail; Node<e> s = t.getNext();</e></e></code>使用局部变量t引用tail节点，同时获取tail节点的next节点，赋予变量s。<code>if (t == tail) {}</code>只有在t==tail的情况下才会执行入队操作，否则进行下一轮循环，直到t==tail，因为是无锁模式，所以如果同时有多个线程在执行入队操作，那么在一个线程读取了tail之后，很可能会有其他线程已经修改了tail（<strong>此处的修改是指将tail指向另一个节点，所以t还引用着原来的节点，导致t!=tail，而并非是修改了tail所指向的节点的值</strong>），此处的判断避免了一开始的错误，但是并不能保证后续的执行过程中不会插入其他线程的操作，其实ConcurrentLinkedQueue的设计使得if内的代码即使在有其他线程插入的情况下依旧能够很好地执行，下面我们接着分析。</p>
<p><code>if (s == null) {} else { casTail(t, s); }</code>这里判断s（tail的next是否为NULL），如果不为NULL，则直接将tail指向s。这里需要说明一下：由于tail指向的是队列的尾部，所以tail的next应该始终是NULL，那么当发生tail的next不为NULL，则说明当前队列处于不一致状态，这时当前线程需要帮助队列进入一致性状态，这就是ConcurrentLinkedQueue设计的巧妙之处！那么如果帮助队列进入一致性状态呢？这个问题我们先留着，继续看什么情况下会导致队列进入不一致状态！<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (t.casNext(s, <span class="keyword">n</span>)) &#123;</span><br><span class="line">	casTail(t, <span class="keyword">n</span>);</span><br><span class="line">    <span class="keyword">return</span> true;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这几句代码完成了入队的操作，第一步CAS的设置t（指向tail）的next为n（新创建的节点），该更新操作能够完成的前提是t的next值==s，即tail的next值在该线程首次读取期间并未发生变化。此处的CAS操作保证了tail的next值更新的原子性，所以不会出现不一致情况。当成功更新了tail的next节点之后，接下来就是原子性的更新tail为n，此处如果更新成功，则入队顺利完成完成，但是奇怪的是如果此处更新失败，入队依旧是成功的！为什么呢？看下文。</p>
<p>我们试想如果一个线程成功的原子性更新了tail的next值为新创建的节点，由于Node的next是volatile修饰的，所以会立即被之后的所有线程可见，那么就会出现tail未变化但是tail的next已经不是NULL了，此时就会出现上面提到的tail的next不为NULL的情况了，现在我们再来看看上面是如何处理这种情况的，<code>casTail(t, s);</code>，从这句可以看出当一个线程看到tail的next不为NULL时就会直接将tail更新成s（tail的next所指向的节点），即将tail指向其next节点，当然这里的更新也是CAS保证的原子性更新。为什么敢这么大胆，正是因为如果当前线程（T1）看到tail的next不为NULL，那么必然是有一个线程（T2）处于入队操作中，且成功执行了<code>t.casNext(s, n)</code>（将新创建的节点赋到tail的next上），正准备执行<code>casTail(t, n);</code>（将tail执行其next指向的节点），那么T1直接将T2准备做的工作完成，然后再进入循环重新进行入队操作，而T2也不在乎自己这一步是否顺利完成，反正只要有人完成了就行，所以T2就直接返回入队成功，最终T1帮助T2顺利完成了入队操作，并且全程无锁，此设计真的是巧妙啊~~~</p>
<p>下面我们使用流程图形象的描绘下入队过程，整个入队方法被划分成7步（见上面的代码中的注释）。说明：虽然入队是在无锁模式下进行，但是由于使用CAS进行原子性更新，所以很多地方其实还是实现了线程安全的，除了⑥-&gt;⑦，下面的图描绘的也正是⑥-&gt;⑦这一步可能出现的冲突情况。</p>
<p><strong>图2：ConcurrentLinkedQueue入队流程图：</strong><br><img src="http://7xnnj7.com1.z0.glb.clouddn.com/blog/ConcurrentLinkedQueue%E5%85%A5%E9%98%9F%E6%B5%81%E7%A8%8B%E5%9B%BE.png" alt="ConcurrentLinkedQueue入队流程图"></p>
<p>上面介绍了ConcurrentLinkedQueue是如何实现无锁入队的，但是我们只说明了多个线程同时入队操作是线程安全的，但是如果多个线程同时进行入队和出队，以及删除操作呢？这个问题在下面分析另外两个方法时会提到，同时最后也会进行一个总结，下面我们先看看删除操作是如何实现的。</p>
<h5 id="删除——remove"><strong>删除——remove</strong></h5><p>先介绍删除，是因为出队操作有个地方需要在这里提前介绍下。<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">boolean</span> <span class="title">remove</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (o == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;<span class="comment">// ①</span></span><br><span class="line">    <span class="keyword">for</span> (Node&lt;E&gt; p = first(); p != <span class="keyword">null</span>; p = p.getNext()) &#123;<span class="comment">// ②</span></span><br><span class="line">        E item = p.getItem();<span class="comment">// ③</span></span><br><span class="line">        <span class="keyword">if</span> (item != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">            o.equals(item) &amp;&amp;</span><br><span class="line">            p.casItem(item, <span class="keyword">null</span>))<span class="comment">// ④</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>源码中的注释申明了remove方法会使用equals()判断两个节点的值与待删除的值是否相同，同时如果队列有多个与待删除值相同的节点则只删除最前面的一个节点。</p>
<p>同样remove()方法也是无锁模式，①判断是否为NULL，②从队列头部开始查找，③获取每个节点的item值，用于跟o进行equals比较，前面三步都很平常，重点在④，<code>if (item != null &amp;&amp; o.equals(item) &amp;&amp; p.casItem(item, null))</code>这里首先判断item不为NULL，然后判断item与o相等，前面两个都满足的话，那说明已经查找到一个节点的值与待删除的值一样，后面就是删除该节点，这里删除其实并非真的删除，而只是原子性的将节点的item值设置为NULL。从上面的分析可以看出ConcurrentLinkedQueue的删除只是将队列中的某个节点值置为NULL，由于Node的item是volatile的，所以不存在线程安全问题，同时由于remove并未修改队列的结构，所以多个线程同时进行remove，或者同其他方法一起进行也不会发生线程安全性问题。</p>
<h5 id="出队——poll"><strong>出队——poll</strong></h5><p>出队从逻辑上来说就是从队列的头部往外取出数据并删除，下面看看ConcurrentLinkedQueue是如何实现无锁出队的。<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">E</span> poll() &#123;</span><br><span class="line">    <span class="keyword">for</span> (;;) &#123;<span class="comment">// ①</span></span><br><span class="line">        Node&lt;<span class="keyword">E</span>&gt; <span class="keyword">h</span> = head;<span class="comment">// ②</span></span><br><span class="line">        Node&lt;<span class="keyword">E</span>&gt; t = tail;<span class="comment">// ②</span></span><br><span class="line">        Node&lt;<span class="keyword">E</span>&gt; first = <span class="keyword">h</span>.getNext();<span class="comment">// ②</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">h</span> == head) &#123;<span class="comment">// ③</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">h</span> == t) &#123;<span class="comment">// ④</span></span><br><span class="line">                <span class="keyword">if</span> (first == null)<span class="comment">// ⑤</span></span><br><span class="line">                    <span class="keyword">return</span> null;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    casTail(t, first);<span class="comment">// ⑥</span></span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (casHead(<span class="keyword">h</span>, first)) &#123;<span class="comment">// ⑦</span></span><br><span class="line">                <span class="keyword">E</span> item = first.getItem();<span class="comment">// ⑧</span></span><br><span class="line">                <span class="keyword">if</span> (item != null) &#123;<span class="comment">// ⑨</span></span><br><span class="line">                    first.setItem(null);<span class="comment">// ⑩</span></span><br><span class="line">                    <span class="keyword">return</span> item;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// else skip over deleted item, continue loop,</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>出队的步骤略多些，不过理解了也就很简单了。首先①是一个死循环；②的三步分别是获取head/tail/head.next三个节点；③判断h==head，避免操作过程中已有其他线程移动了head；④判断head是否等于tail，即队列是否为NULL，说到这里我们先来看看head和tail在队列中到底处于什么位置。我们用一个队列入队出队的时序图来描绘下在入队和出队过程中head和tail到底是如何变化的。</p>
<p><strong>图3：ConcurrentLinkedQueue队列时序图：</strong><br><img src="http://7xnnj7.com1.z0.glb.clouddn.com/blog/ConcurrentLinkedQueue%E9%98%9F%E5%88%97%E6%97%B6%E5%BA%8F%E5%9B%BE.png" alt="ConcurrentLinkedQueue队列"><br>从图中我们可以看出head的next指向的是队列的第一个元素，我们出队也是将head的next指向的元素出队，同时head==tail说明队列已经没有元素了。明白了这两点我们再接着④分析，如果④这里为真，说明队列已经为NULL，接着⑤判断f（head的next指向的节点）是否为NULL，不为NULL则执行⑥将tail指向f，到这里如果理解了上面入队操作，那么应该是可以理解这一步的用意的——帮助其他线程执行入队操作，跟入队时的⑤是一样的，因为head==tail，head的next不为NULL，则说明tail的next不为NULL，所以要将tail重新指向他的next，帮助正在执行入队的线程完成入队工作。理解了这一步那么出队操作就已经理解了一大半了，下面继续看⑦⑧⑨⑩。</p>
<p>如果head!=tail，则队列不为NULL，那么直接将head指向下一个节点，将当前节点踢出队列即可，当然需要CAS保证原子性更新，然后将踢出队列的节点的item取出返回，并置为NULL即完成了出队操作。这里需要注意的是如果被踢出队列的节点的item是NULL，说明该节点已经被删除了（因为remove()方法只是将节点的item设置为NULL，而不将节点踢出队列），那就只能再次循环了。再提一点，为什么⑦⑧⑨⑩能够被线程安全的执行，因为在⑦这一步是原子更新的，而且更新之后这个节点就立即不会被其他任何线程访问到了，所以后面⑧⑨⑩想怎么处理都是安全的。</p>
<p>到这里出队操作应该很清楚了，下面就来综合分析下为什么针对ConcurrentLinkedQueue的整个入队/出队/删除都是不需要锁的。</p>
<ol>
<li>上面已经分析了如果多个线程同时访问其中任一个方法（offer/poll/remove）都是无需加锁而且线程安全的</li>
<li>由于remove方法不修改ConcurrentLinkedQueue的结构，所以跟其他两个方法都不会有冲突</li>
<li>如果同时两个线程，一个入队，一个出队，在队列不为NULL的情况下是不是有任何问题的，因为一个操作tail，一个操作head，完全不相关。但是如果队列为NULL时还是会发生冲突的，因为tail==head。这里我们在分析出队时也提到了，如果出队线程发现tail的next不为NULL，那么就会感知到当前有一个线程在执行入队操作，所以出队线程就会帮助入队线程完成入队操作，而且每个操作都是通过CAS保证原子性更新，所以就算同时两个线程，一个入队，一个出队也不会发生冲突。</li>
</ol>
<p>综上，ConcurrentLinkedQueue最终实现了无锁队列。</p>
<h4 id="使用场景"><strong>使用场景</strong></h4><p>ConcurrentLinkedQueue适合在对性能要求相对较高，同时对队列的读写存在多个线程同时进行的场景，即如果对队列加锁的成本较高则适合使用无锁的ConcurrentLinkedQueue来替代。下面我们来简单对比下ConcurrentLinkedQueue与我们常用的阻塞队列LinkedBlockingQueue的性能。<br><strong>表1：入队性能对比</strong></p>
<table>
<thead>
<tr>
<th style="text-align:left">线程数</th>
<th style="text-align:left">ConcurrentLinkedQueue耗时(ms)</th>
<th style="text-align:left">LinkedBlockingQueue耗时(ms)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">5</td>
<td style="text-align:left">22</td>
<td style="text-align:left">29</td>
</tr>
<tr>
<td style="text-align:left">10</td>
<td style="text-align:left">50</td>
<td style="text-align:left">59</td>
</tr>
<tr>
<td style="text-align:left">20</td>
<td style="text-align:left">99</td>
<td style="text-align:left">112</td>
</tr>
<tr>
<td style="text-align:left">30</td>
<td style="text-align:left">139</td>
<td style="text-align:left">171</td>
</tr>
</tbody>
</table>
<p>测试数据：N个线程，每个线程入队10000个元素。</p>
<hr>
<h4 id="参考文章"><strong>参考文章</strong></h4><p><a href="http://www.infoq.com/cn/articles/ConcurrentLinkedQueue" target="_blank" rel="external">聊聊并发（六）——ConcurrentLinkedQueue的实现原理分析</a><br><a href="http://www.ibm.com/developerworks/cn/java/j-lo-concurrent/index.html" target="_blank" rel="external">非阻塞算法在并发容器中的实现</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它会添加到队列的尾部，当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait－free”算法来实现，该算法在Michael &amp; Scott算法上进行了一些修改, Michael &amp; Scott算法的详细信息可以参见<a href="http://www.cs.rochester.edu/~scott/papers/1996_PODC_queues.pdf">参考资料一</a>。<br>]]>
    
    </summary>
    
      <category term="ConcurrentLinkedQueue" scheme="http://vickyqi.com/tags/ConcurrentLinkedQueue/"/>
    
      <category term="JDK" scheme="http://vickyqi.com/tags/JDK/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="并发" scheme="http://vickyqi.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="JDK源码学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/JDK%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[JDK并发工具类源码学习系列——ConcurrentHashMap]]></title>
    <link href="http://vickyqi.com/2015/10/26/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentHashMap/"/>
    <id>http://vickyqi.com/2015/10/26/JDK并发工具类源码学习系列——ConcurrentHashMap/</id>
    <published>2015-10-26T10:19:11.000Z</published>
    <updated>2015-10-26T10:02:46.000Z</updated>
    <content type="html"><![CDATA[<p>ConcurrentHashMap类在我的开发过程中经常被使用，个人觉得如果在共享一个Map时，如果无法判断是否需要加锁，那么就干脆直接使用ConcurrentHashMap，即能保证并发安全，同时性能也不会有太多下降，因为ConcurrentHashMap可实现无锁读，不过内存会占用的多些，但是并不明显，基本可以忽略。<br><a id="more"></a></p>
<p>作为JDK并发工具类源码学习系列的第一个被分析的类，ConcurrentHashMap类在我的开发过程中经常被使用。个人觉得如果在共享一个Map时，如果无法判断是否需要加锁，那么就干脆直接使用ConcurrentHashMap，即能保证并发安全，同时性能也不会有太多下降，因为ConcurrentHashMap可实现无锁读，不过内存会占用的多些，但是并不明显，基本可以忽略。<br>下面我们就来看看ConcurrentHashMap类的内部构造。</p>
<h4 id="结构预览"><strong>结构预览</strong></h4><h5 id="类定义"><strong>类定义</strong></h5><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">ConcurrentHashMap&lt;K</span>, <span class="title">V&gt;</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">AbstractMap&lt;K</span>, <span class="title">V&gt;</span> <span class="title">implements</span> <span class="title">ConcurrentMap&lt;K</span>, <span class="title">V&gt;</span>, <span class="title">Serializable</span></span></span><br></pre></td></tr></table></figure>
<p>上面是ConcurrentHashMap类的定义，从ConcurrentHashMap的定义可以看出ConcurrentHashMap是实现了ConcurrentMap接口，而非直接实现Map接口。同时ConcurrentMap的子接口还有一个ConcurrentNavigableMap，表示可支持导航的并发Map。可见ConcurrentMap接口定义可支持并发，NavigableMap接口定义可支持导航，SortedMap接口定义可支持排序，NavigableMap继承自SortedMap。从Map的API介绍可以看出Java Collections Framework家族中重要一员——Map的组织结构——通过接口定义Map的行为，或者说Map可支持的功能，多个接口之间可交叉，如ConcurrentNavigableMap即实现ConcurrentMap接口又实现NavigableMap接口。</p>
<h5 id="类结构"><strong>类结构</strong></h5><p><img src="http://img.blog.csdn.net/20151009213243833" alt="ConcurrentHashMap结构图"><br>从图中可以看出ConcurrentHashMap内部包含了多个内部类，其中最重要的也是我们最需要关心的是：<strong>Segment</strong>和<strong>HashEntry</strong>。<br><strong>Segment</strong>是ConcurrentHashMap非常重要的一个内部类，是ConcurrentHashMap实现高并发的关键点，Segment在ConcurrentHashMap中承担着所有的操作，即所有对ConcurrentHashMap的操作最终都会对Segment进行操作。因为Segment保存了最终的数据，而ConcurrentHashMap只是保存了一个Segment的数组。ConcurrentHashMap通过N个Segment将数据切分成N块，而每块之间是互不影响的，所以理论上可以同时并行的执行N个需要加锁的操作，这就是ConcurrentHashMap并发的基础。<br><strong>HashEntry</strong>同HashMap中的Entry，每个HashEntry是一个节点，保存key和value，以及下一个节点。HashEntry中的key，hash 和 next 域都被声明为 final 型，value 域被声明为 volatile 型，可见HashEntry类的value是可变的，其他的key和next都是不可变的。<br>EntryIterator，EntrySet，HashIterator，KeyIterator，KeySet，ValueIterator，Values是辅助ConcurrentHashMap实现遍历的内部类。<br>下面简单介绍下<strong>Segment</strong>和<strong>HashEntry</strong>类。<br><strong>HashEntry</strong><br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">class</span> HashEntry&lt;K,V&gt; &#123;</span><br><span class="line">        <span class="keyword">final</span> K key;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">        <span class="keyword">volatile</span> V value;</span><br><span class="line">        <span class="keyword">final</span> HashEntry&lt;K,V&gt; <span class="keyword">next</span>;</span><br><span class="line"></span><br><span class="line">        HashEntry(K key, <span class="keyword">int</span> hash, HashEntry&lt;K,V&gt; <span class="keyword">next</span>, V value) &#123;</span><br><span class="line">            <span class="keyword">this</span>.key = key;</span><br><span class="line">            <span class="keyword">this</span>.hash = hash;</span><br><span class="line">            <span class="keyword">this</span>.<span class="keyword">next</span> = <span class="keyword">next</span>;</span><br><span class="line">            <span class="keyword">this</span>.value = value;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">		@SuppressWarnings(<span class="string">"unchecked"</span>)</span><br><span class="line">		<span class="keyword">static</span> <span class="keyword">final</span> &lt;K,V&gt; HashEntry&lt;K,V&gt;[] newArray(<span class="keyword">int</span> i) &#123;</span><br><span class="line">		    <span class="keyword">return</span> <span class="keyword">new</span> HashEntry[i];</span><br><span class="line">		&#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>HashEntry类的结构很简单，就是四个变量，一个构造函数，一个static方法。由于没有任何getter和setter方法，所以对其操作是直接访问变量。在 ConcurrentHashMap 中，在散列时如果产生“碰撞”，将采用“分离链接法”来处理“碰撞”：把“碰撞”的 HashEntry 对象链接成一个链表。由于 HashEntry 的 next 域为 final 型，所以新节点只能在链表的表头处插入。所以链表中节点的顺序和插入的顺序相反。<br><strong>Segment</strong><br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">static <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Segment&lt;K</span>,<span class="title">V&gt;</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">ReentrantLock</span> <span class="title">implements</span> <span class="title">Serializable</span></span></span><br></pre></td></tr></table></figure></p>
<p>Segment继承自ReentrantLock ，所以它可以作为一个锁使用，其在ConcurrentHashMap也正是作为一个锁来使用的。</p>
<figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> <span class="keyword">int</span> <span class="keyword">count</span>;<span class="comment">//Segment中保存的元素数量</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount;<span class="comment">//记录Segment被修改的次数，用于在读取时判断读取期间改Segment是否有过修改，有的话则重试</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> threshold;<span class="comment">//阀值，元素数量达到该值则会进行自动扩展</span></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">volatile</span> HashEntry&lt;K,V&gt;[] table;<span class="comment">//桶，一个HashEntry的数组，按HashCode值散列保存，采用链表解决hash碰撞问题</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">float</span> loadFactor;<span class="comment">//负载因子</span></span><br></pre></td></tr></table></figure>
<p><strong>count </strong>变量是一个计数器，它表示每个 Segment 对象管理的 table 数组（若干个 HashEntry 组成的链表）包含的 HashEntry 对象的个数。每一个 Segment 对象都有一个 count 对象来表示本 Segment 中包含的 HashEntry 对象的总数。注意，之所以在每个 Segment 对象中包含一个计数器，而不是在 ConcurrentHashMap 中使用全局的计数器，是为了避免出现“热点域”而影响 ConcurrentHashMap 的并发性。<br><img src="http://img.blog.csdn.net/20151012120235225" alt="Segment结构"><br>从Segment拥有的方法可以看出，针对ConcurrentHashMap的操作基本上都会调用具体某个Segment的对应方法，如put会调用Segment的put方法。所以Segment是最终的操作类。</p>
<p>下图是依次插入 ABC 三个 HashEntry 节点后，Segment 的结构示意图。<br><img src="http://img.blog.csdn.net/20151012120621035" alt="插入三个节点后 Segment 的结构示意图"><br>Segment的方法会在介绍ConcurrentHashMap的方法时进行解释，这里先不介绍。</p>
<h4 id="构造器解读"><strong>构造器解读</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(initialCapacity, loadFactor, DEFAULT_CONCURRENCY_LEVEL);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>以上的构造器都只是一个个重载函数，最终都会调用下面的构造器。其中使用到了三个常量：</p>
<ul>
<li>DEFAULT_INITIAL_CAPACITY：默认初始容量</li>
<li>DEFAULT_LOAD_FACTOR：默认加载因子</li>
<li>DEFAULT_CONCURRENCY_LEVEL：默认并发级别，该值决定一个包含多少个Segment，即将ConcurrentHashMap切分成多少块</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ConcurrentHashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity,</span><br><span class="line">                             <span class="keyword">float</span> loadFactor, <span class="keyword">int</span> concurrencyLevel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (!(loadFactor &gt; <span class="number">0</span>) || initialCapacity &lt; <span class="number">0</span> || concurrencyLevel &lt;= <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (concurrencyLevel &gt; MAX_SEGMENTS)</span><br><span class="line">            concurrencyLevel = MAX_SEGMENTS;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Find power-of-two sizes best matching arguments</span></span><br><span class="line">        <span class="keyword">int</span> sshift = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> ssize = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (ssize &lt; concurrencyLevel) &#123;</span><br><span class="line">            ++sshift;</span><br><span class="line">            ssize &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        segmentShift = <span class="number">32</span> - sshift;</span><br><span class="line">        segmentMask = ssize - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">this</span>.segments = Segment.newArray(ssize);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">            initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">        <span class="keyword">int</span> c = initialCapacity / ssize;</span><br><span class="line">        <span class="keyword">if</span> (c * ssize &lt; initialCapacity)</span><br><span class="line">            ++c;</span><br><span class="line">        <span class="keyword">int</span> cap = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (cap &lt; c)</span><br><span class="line">            cap &lt;&lt;= <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.segments.length; ++i)</span><br><span class="line">            <span class="keyword">this</span>.segments[i] = <span class="keyword">new</span> Segment&lt;K,V&gt;(cap, loadFactor);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>该构造函数需要制定初始容量、加载因子以及并发级别，对应上面提到的三个常量（默认值）。代码前几句是对参数进行正确性校验。<strong>// Find power-of-two sizes best matching arguments</strong>这句注释的意思是寻找一个参数的最佳匹配值：最接近指定的参数的2的幂方值。下面我们对照着代码来说明这句话的含义：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Find power-of-two sizes best matching arguments</span></span><br><span class="line"><span class="keyword">int</span> sshift = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> ssize = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (ssize &lt; concurrencyLevel) &#123;</span><br><span class="line">    ++sshift;</span><br><span class="line">    ssize &lt;&lt;= <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里定义了一个ssize变量，该变量就是concurrencyLevel的最佳匹配值，可以看见首先是循环，直到ssize&gt;=concurrencyLevel，所以最佳匹配值是大于等于指定参数的，循环里面每次会将ssize右移一位，即*2，所以最终得到的值就是一个最接近且大于等于concurrencyLevel的2次幂方值。同时定义了一个sshift变量，该变量随着ssize的每次右移而+1，最终得到的即是ssize是2的多少次方，即sszie=2^sshift。继续往下看：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">segmentShift = <span class="number">32</span> - sshift;<span class="comment">//偏移量</span></span><br><span class="line">segmentMask = ssize - <span class="number">1</span>;<span class="comment">//掩码值</span></span><br><span class="line"><span class="keyword">this</span>.segments = Segment.newArray(ssize);<span class="comment">//初始化segments数组</span></span><br></pre></td></tr></table></figure>
<p>segmentShift以及segmentMask在后面将一个hash映射到某一个segments时使用，目的是将hash均匀的分配到每个segments，具体为什么使用这两个来进行均匀分配我们这里不介绍。最后一句是初始化一个segments数组，大小是ssize，而非参数concurrencyLevel值。下面继续看：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">    initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line"><span class="keyword">int</span> c = initialCapacity / ssize;</span><br><span class="line"><span class="keyword">if</span> (c * ssize &lt; initialCapacity)</span><br><span class="line">    ++c;</span><br><span class="line"><span class="keyword">int</span> cap = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (cap &lt; c)</span><br><span class="line">    cap &lt;&lt;= <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="keyword">this</span>.segments.length; ++i)</span><br><span class="line">    <span class="keyword">this</span>.segments[i] = <span class="keyword">new</span> Segment&lt;K,V&gt;(cap, loadFactor);</span><br></pre></td></tr></table></figure>
<p>initialCapacity是构造器指定的初始化容量，ssize是segments数组大小，所以c的值就是每个segments的容量。下面定义了一个cap，这里的cap和前面的ssize是一个含义，即选择一个最接近且大于等于c的2的幂方值，然后初始化segments数组，传入的参数有cap（segment容量）和loadFactor（负载因子）。这里选择cap作为segment容量，而非c，是出于方便后期对segment的容量进行扩充考虑，如果容量是2的幂方，那么想要将容量扩充一倍只需右移1位即可，同时保证依旧是2的幂方。<br>对于segment的初始化很简单，对loadFactor赋值，然后根据指定的初始容量创建一个HashEntry数组，并计算出threshold（阀值，当segment中的元素超过这个阈值则进行容量扩充）。</p>
<h4 id="常用方法解读"><strong>常用方法解读</strong></h4><p>ConcurrentHashMap实现了Map接口，那么他的核心方法包括我们常用的put(K, V)、get(Object)、remove(Object)、contains(Object)、size()，同时继承自ConcurrentMap让他包含了putIfAbsent(K, V)、remove(Object, Object)、replace(K, V, V)、replace(K, V)四个并发方法。后面的四个并发方法是ConcurrentMap为我们提供的在并发情景下使用的工具方法，都是基于CAS来实现的。<br>在看put(K, V)、get(Object)等方法实现之前，先来看下这两个方法：hash(int)和segmentFor(int)。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/* ---------------- Small Utilities -------------- */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Applies a supplemental hash function to a given hashCode, which</span><br><span class="line"> * defends against poor quality hash functions.  This is critical</span><br><span class="line"> * because ConcurrentHashMap uses power-of-two length hash tables,</span><br><span class="line"> * that otherwise encounter collisions for hashCodes that do not</span><br><span class="line"> * differ in lower or upper bits.</span><br><span class="line"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(<span class="keyword">int</span> h)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// Spread bits to regularize both segment and index locations,</span></span><br><span class="line">    <span class="comment">// using variant of single-word Wang/Jenkins hash.</span></span><br><span class="line">    h += (h &lt;&lt;  <span class="number">15</span>) ^ <span class="number">0xffffcd7d</span>;</span><br><span class="line">    h ^= (h &gt;&gt;&gt; <span class="number">10</span>);</span><br><span class="line">    h += (h &lt;&lt;   <span class="number">3</span>);</span><br><span class="line">    h ^= (h &gt;&gt;&gt;  <span class="number">6</span>);</span><br><span class="line">    h += (h &lt;&lt;   <span class="number">2</span>) + (h &lt;&lt; <span class="number">14</span>);</span><br><span class="line">    <span class="keyword">return</span> h ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Returns the segment that should be used for key with given hash</span><br><span class="line"> * @param hash the hash code for the key</span><br><span class="line"> * @return the segment</span><br><span class="line"> */</span></span><br><span class="line">final Segment&lt;K,V&gt; segmentFor(<span class="keyword">int</span> hash) &#123;</span><br><span class="line">    <span class="keyword">return</span> segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>源码中对这两个方法的注释是：Small Utilities，即小工具方法。源码中对于hash方法的注释的意思是：该方法是一个补充hash方法，ConcurrentHashMap的hash表的长度是2的幂方，使用该补充hash函数可降低一些质量差的hash函数发生的碰撞概率。具体如何实现的就不看了，就算看懂了代码也很难理解这样做的原因，所以不浪费时间。segmentFor是为一个hash值找到它应该去的segment，这里使用到了segmentShift以及segmentMask，还记得segmentShift是32-sshift，这里将hash值无符号左移segmentShift位，即取hash值的高sshift位，然后同segmentMask按位与运算。其实就是取hash值的高sshift位将值限制在0~ssize之间，然后与ssize-1取余得到segments数组的下标（取高位是因为更加均匀，低位的重复率比高位高，臆测~！！！）。<br>了解了上面两个方法，下面我们就来看看put(K, V)、get(Object)、remove(Object)这三个方法的具体实现。</p>
<h5 id="put(K,_V)"><strong>put(K, V)</strong></h5><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span>(<span class="params">K key, V <span class="keyword">value</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">value</span> == <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException();</span><br><span class="line">    <span class="keyword">int</span> hash = hash(key.hashCode());</span><br><span class="line">    <span class="keyword">return</span> segmentFor(hash).put(key, hash, <span class="keyword">value</span>, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ConcurrentHashMap的put方法内部只是根据key的hash值找到对应的Segement，然后调用Segement的put方法，注意Segement的put方法的第四个参数，这里穿的值是false。我们主要分析下Segement的put方法。Segement在这里的作用就是将元素均匀分成N等份，各个Segement之间互不干扰，读写也不会发生冲突，降低并发要求。</p>
<figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">V <span class="title">put</span>(<span class="params">K key, <span class="keyword">int</span> hash, V <span class="keyword">value</span>, boolean onlyIfAbsent</span>) </span>&#123;</span><br><span class="line">    <span class="keyword">lock</span>();</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">int</span> c = count;</span><br><span class="line">        <span class="keyword">if</span> (c++ &gt; threshold) <span class="comment">// ensure capacity</span></span><br><span class="line">            rehash();</span><br><span class="line">        HashEntry&lt;K,V&gt;[] tab = table;</span><br><span class="line">        <span class="keyword">int</span> index = hash &amp; (tab.length - <span class="number">1</span>);</span><br><span class="line">        HashEntry&lt;K,V&gt; first = tab[index];</span><br><span class="line">        HashEntry&lt;K,V&gt; e = first;</span><br><span class="line">        <span class="keyword">while</span> (e != <span class="keyword">null</span> &amp;&amp; (e.hash != hash || !key.equals(e.key)))</span><br><span class="line">            e = e.next;</span><br><span class="line"></span><br><span class="line">        V oldValue;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">            oldValue = e.<span class="keyword">value</span>;</span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line">                e.<span class="keyword">value</span> = <span class="keyword">value</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            oldValue = <span class="keyword">null</span>;</span><br><span class="line">            ++modCount;</span><br><span class="line">            tab[index] = <span class="keyword">new</span> HashEntry&lt;K,V&gt;(key, hash, first, <span class="keyword">value</span>);</span><br><span class="line">            count = c; <span class="comment">// write-volatile</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> oldValue;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先第一步就是lock，看来再NB的并发类在写时也需要lock啊。读取count值，从count的注释可以看出该值是记录Segment包含的元素数量，volatile修饰的（这里利用了volatile变量的内存可见性）。然后判断增加之后元素数量是否超过阈值，超过的话提前扩容。接着找到该hash对应的table（桶），简单的取余操作。找到该table的第一个元素——first，因为ConcurrentHashMap使用链表来解决hash冲突问题，所以这里的table是一个链表。</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="keyword">e</span> != null &amp;&amp; (<span class="keyword">e</span>.hash != hash || !key.equals(<span class="keyword">e</span>.key)))</span><br><span class="line">      <span class="keyword">e</span> = <span class="keyword">e</span>.next;</span><br></pre></td></tr></table></figure>
<p>通过循环，并通过比较hash值以及equals()校验，寻找与key相同的已存在的元素。</p>
<figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">V oldValue;</span><br><span class="line"><span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">    oldValue = e.<span class="keyword">value</span>;</span><br><span class="line">    <span class="keyword">if</span> (!onlyIfAbsent)</span><br><span class="line">        e.<span class="keyword">value</span> = <span class="keyword">value</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span> &#123;</span><br><span class="line">    oldValue = <span class="keyword">null</span>;</span><br><span class="line">    ++modCount;</span><br><span class="line">    tab[index] = <span class="keyword">new</span> HashEntry&lt;K,V&gt;(key, hash, first, <span class="keyword">value</span>);</span><br><span class="line">    count = c; <span class="comment">// write-volatile</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>e!=null说明找到与要插入的元素key相同的元素，那么onlyIfAbsent=false则直接将原元素的value值替换，返回原值，由于HashEntry的value是volatile的，所以修改之后会立即被后续线程可见；onlyIfAbsent=true则不做任何操作。e==null时，modCount自增（modCount记录了对该Segment的进行的结构性修改的次数，modCount值使得在进行批量读取时能够知道在读取期间Segment结构是否被修改来决定是否进行加锁读取）。<strong>tab[index] = new HashEntry(key, hash, first, value)</strong>这句就是将被插入的元素添加到链表中，但是插入的位置是头部，而非尾部。HashEntry的构造器传入一个HashEntry对象，该对象是链表原来的头部，被作为新创建的节点的next指针，所以新的链表的头部元素是新增加的，后面接着是原来的链表。<br>注意：此处的lock并非对整个Map进行加锁，而只是对该Segment进行加锁，所以如果一个线程进行put操作，其他的另外15个（ssize-1）Segment仍是可访问的。</p>
<h5 id="remove(Object)"><strong>remove(Object)</strong></h5><figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">public V remove(Object <span class="built_in">key</span>) &#123;</span><br><span class="line">	<span class="typename">int</span> hash = hash(<span class="built_in">key</span>.hashCode());</span><br><span class="line">    return segmentFor(hash).remove(<span class="built_in">key</span>, hash, <span class="built_in">null</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Remove; match on <span class="built_in">key</span> only if <span class="built_in">value</span> <span class="built_in">null</span>, else match both.</span><br><span class="line"> */</span><br><span class="line">V remove(Object <span class="built_in">key</span>, <span class="typename">int</span> hash, Object <span class="built_in">value</span>) &#123;</span><br><span class="line">	<span class="comment">//由于remove是结构性修改，所以第一步便是lock</span></span><br><span class="line">    lock();</span><br><span class="line">    try &#123;</span><br><span class="line">	    <span class="comment">//读取count值，此处是利用volatile变量的内存可见性来保证读线程能够及时的读取到最新值(后面会单独介绍)</span></span><br><span class="line">        <span class="typename">int</span> c = <span class="built_in">count</span> - <span class="number">1</span>;</span><br><span class="line">        <span class="comment">//是根据key的hashCode找到该节点对应的桶</span></span><br><span class="line">        HashEntry&lt;K,V&gt;[] tab = table;</span><br><span class="line">        <span class="typename">int</span> index = hash &amp; (tab.length - <span class="number">1</span>);</span><br><span class="line">        HashEntry&lt;K,V&gt; <span class="built_in">first</span> = tab[index];</span><br><span class="line">        HashEntry&lt;K,V&gt; e = <span class="built_in">first</span>;</span><br><span class="line">        <span class="comment">//循环找到该节点</span></span><br><span class="line">        <span class="keyword">while</span> (e != <span class="built_in">null</span> &amp;&amp; (e.hash != hash || !<span class="built_in">key</span>.equals(e.<span class="built_in">key</span>)))</span><br><span class="line">            e = e.<span class="built_in">next</span>;</span><br><span class="line"></span><br><span class="line">        V oldValue = <span class="built_in">null</span>;</span><br><span class="line">        if (e != <span class="built_in">null</span>) &#123;</span><br><span class="line">        <span class="comment">//找到待删除节点</span></span><br><span class="line">            V v = e.<span class="built_in">value</span>;</span><br><span class="line">            <span class="comment">//如果value==null，则无需关心节点的值是否与指定值相同，否则只有在两者相同情况才可删除</span></span><br><span class="line">            if (<span class="built_in">value</span> == <span class="built_in">null</span> || <span class="built_in">value</span>.equals(v)) &#123;</span><br><span class="line">                oldValue = v;</span><br><span class="line">                <span class="comment">// All entries following removed node can stay</span></span><br><span class="line">                <span class="comment">// in list, but all preceding ones need to be</span></span><br><span class="line">                <span class="comment">// cloned.</span></span><br><span class="line">                ++modCount;</span><br><span class="line">                HashEntry&lt;K,V&gt; newFirst = e.<span class="built_in">next</span>;</span><br><span class="line">                for (HashEntry&lt;K,V&gt; p = <span class="built_in">first</span>; p != e; p = p.<span class="built_in">next</span>)</span><br><span class="line">                    newFirst = new HashEntry&lt;K,V&gt;(p.<span class="built_in">key</span>, p.hash,</span><br><span class="line">                                                  newFirst, p.<span class="built_in">value</span>);</span><br><span class="line">                tab[index] = newFirst;</span><br><span class="line">                <span class="built_in">count</span> = c; <span class="comment">// write-volatile</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return oldValue;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>依旧调用的是对应的Segment的remove()方法。由于remove是结构性修改，所以需要进行加锁操作。在删除一个节点时，为了不影响正在遍历链表的线程，这里采用了复制方式，而非直接移除待删除节点。具体工作方式：将待删除节点之后的节点不动，而待删除节点之后的节点复制到另外一个链表，看代码：<code>HashEntry&lt;K,V&gt; newFirst = e.next;</code>这句将待删除节点的next节点赋值给newFirst <code>for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next)</code>此处的for循环从链表的头部开始一直循环到待删除节点为止，<code>newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value);</code>for循环内部根据当前循环的节点新建了一个key和value、hash都相同的节点，不同的是next指向了前一个新建的节点（第一个newFirst是待删除节点的下一个节点），即构成了一个以待删除节点的前一个节点为头结点的新的链表，然后<code>tab[index] = newFirst;</code>将该链表赋到对应的桶上，便完成了整个删除操作，最终新的链表以待删除节点的前一个节点为头结点。<br>下面通过图例来说明 remove 操作。假设写线程执行 remove 操作，要删除链表的 C 节点，另一个读线程同时正在遍历这个链表。<br><strong>执行删除之前的原链表：</strong><br><img src="http://7xnnj7.com1.z0.glb.clouddn.com/blogJDK并发工具类源码学习系列——ConcurrentHashMap_图4.jpg" alt="执行删除之前的原链表"><br><strong>执行删除之后的新链表：</strong><br><img src="http://7xnnj7.com1.z0.glb.clouddn.com/blogJDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentHashMap_%E5%9B%BE5.jpg" alt="执行删除之后的新链表"><br>从图中可以看出被删除节点之后的节点原封不动保留在链表中，而之前的链表从后往前依次被复制到新的链表中，但是原链表在我们进行remove操作过程中始终是会发生任何变化的，所以写线程对某个链表进行remove操作不会影响其他的并发读线程对这个链表的遍历访问。</p>
<h5 id="get(Object)"><strong>get(Object)</strong></h5><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> V <span class="built_in">get</span>(<span class="keyword">Object</span> <span class="variable">key</span>) &#123;</span><br><span class="line">    <span class="built_in">int</span> hash = hash(<span class="variable">key</span>.hashCode());</span><br><span class="line">    <span class="keyword">return</span> segmentFor(hash).<span class="built_in">get</span>(<span class="variable">key</span>, hash);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>ConcurrentHashMap的get()方法同put()一样，也是依赖于Segment的get()方法。下面看看Segment的get()方法</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">V <span class="literal">get</span>(Object key, int hash) &#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">count</span> != 0) &#123; <span class="comment">// read-volatile</span></span><br><span class="line">        HashEntry&lt;K,V&gt; <span class="keyword">e</span> = getFirst(hash);</span><br><span class="line">        <span class="keyword">while</span> (<span class="keyword">e</span> != null) &#123;</span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">e</span>.hash == hash &amp;&amp; key.equals(<span class="keyword">e</span>.key)) &#123;</span><br><span class="line">                V v = <span class="keyword">e</span>.value;</span><br><span class="line">                <span class="keyword">if</span> (v != null)</span><br><span class="line">                    <span class="keyword">return</span> v;</span><br><span class="line">                <span class="keyword">return</span> readValueUnderLock(<span class="keyword">e</span>); <span class="comment">// recheck</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">e</span> = <span class="keyword">e</span>.next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> null;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"> <span class="comment">/**</span><br><span class="line"> * Returns properly casted first entry of bin for given hash.</span><br><span class="line">  */</span></span><br><span class="line"> HashEntry&lt;K,V&gt; getFirst(int hash) &#123;</span><br><span class="line">     HashEntry&lt;K,V&gt;[] <span class="keyword">tab</span> = <span class="keyword">table</span>;</span><br><span class="line">     <span class="keyword">return</span> <span class="keyword">tab</span>[hash &amp; (<span class="keyword">tab</span>.length - 1)];</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span><br><span class="line"> * Reads value field of an entry under lock. Called if value</span><br><span class="line"> * field ever appears to be null. This is possible only if a</span><br><span class="line"> * compiler happens to reorder a HashEntry initialization with</span><br><span class="line"> * its table assignment, which is legal under memory model</span><br><span class="line"> * but is not known to ever occur.</span><br><span class="line"> */</span></span><br><span class="line">V readValueUnderLock(HashEntry&lt;K,V&gt; <span class="keyword">e</span>) &#123;</span><br><span class="line">    lock();</span><br><span class="line">    try &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">e</span>.value;</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        unlock();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>从代码可以看到get()方法在读取时无需进行加锁操作，除非读取到的值为NULL。为什么读取一个节点的值为NULL的时候需要加锁呢？因为ConcurrentHashMap是不允许NULL作为key或者value的，所以是不应该出现读取一个节点的值为NULL的情况，如果出现这种情况，说明出现了并发问题，所以加上锁再次读取！(什么情况下会出现这种情况并不清楚)。</p>
<h5 id="总结"><strong>总结</strong></h5><p>ConcurrentHashMap在进行结构性修改，如put/remove/replace时都需要进行加锁，但是读取并未加锁，并发情况下，由于内存不同步问题，会导致一个线程的写操作并不会立即对另一个线程可见。这里ConcurrentHashMap通过volatile变量的内存可见性特性来保证一个线程的写操作立即被其他线程可见，每个方法在一开始都会读取count这个变量，该变量就是一个volatile变量，多个线程之间通过读写这个变量来保证内存可见性，具体可参考下方的关于JVM内存可见性的说明。<br>上面三个方法基本包含了整个ConcurrentHashMap的读写操作（replace(K, V)方法只是简单的更新节点的value值，由于value是volatile的，所以也不会影响读线程），从三个方法的分析来看ConcurrentHashMap首先通过Segment对整个数据集进行切分，并通过对各个部分的数据集进行加锁来提高整个数据集的并发性；通过读写分离的方式实现无锁读，加锁写，进一步提高ConcurrentHashMap的读写效率；并通过volatile变量的特性实现读写的可见性保证。</p>
<h4 id="使用场景"><strong>使用场景</strong></h4><p>ConcurrentHashMap由于其即使在同步的情况下依旧保证高效的读写性能，所以在很多需要使用HashMap的情况都适用，当然单线程情况并不需要使用同步的ConcurrentHashMap。如果无法保证你的HashMap只是在单线程情况下使用那么就使用ConcurrentHashMap，因为其在单线程情况下的效率也并不低。<br>下面是针对单线程环境下ConcurrentHashMap和HashMap的put性能的对比：<br>硬件PC：普通PC机，i5<br>JVM：内存1G<br>测试数据：执行10次，计算均值<br>结果：表格</p>
<table>
<thead>
<tr>
<th>Map</th>
<th style="text-align:center">PUT1W次</th>
<th style="text-align:right">PUT10W次</th>
<th style="text-align:right">PUT100W次</th>
</tr>
</thead>
<tbody>
<tr>
<td>ConcurrentHashMap</td>
<td style="text-align:center">2175317</td>
<td style="text-align:right">28068193</td>
<td style="text-align:right">1355076232</td>
</tr>
<tr>
<td>HashMap</td>
<td style="text-align:center">1201131</td>
<td style="text-align:right">28068193</td>
<td style="text-align:right">407341713</td>
</tr>
</tbody>
</table>
<hr>
<h4 id="Java_内存模型"><strong>Java 内存模型</strong></h4><p>由于 ConcurrentHashMap 是建立在 Java 内存模型基础上的，为了更好的理解 ConcurrentHashMap，让我们首先来了解一下 Java 的内存模型。<br>Java 语言的内存模型由一些规则组成，这些规则确定线程对内存的访问如何排序以及何时可以确保它们对线程是可见的。下面我们将分别介绍 Java 内存模型的重排序，内存可见性和 happens-before 关系。</p>
<h5 id="重排序"><strong>重排序</strong></h5><p>内存模型描述了程序的可能行为。具体的编译器实现可以产生任意它喜欢的代码 – 只要所有执行这些代码产生的结果，能够和内存模型预测的结果保持一致。这为编译器实现者提供了很大的自由，包括操作的重排序。<br>编译器生成指令的次序，可以不同于源代码所暗示的“显然”版本。重排序后的指令，对于优化执行以及成熟的全局寄存器分配算法的使用，都是大有脾益的，它使得程序在计算性能上有了很大的提升。<br>重排序类型包括：</p>
<ul>
<li>编译器生成指令的次序，可以不同于源代码所暗示的“显然”版本。</li>
<li>处理器可以乱序或者并行的执行指令。</li>
<li>缓存会改变写入提交到主内存的变量的次序。<h5 id="内存可见性"><strong>内存可见性</strong></h5>由于现代可共享内存的多处理器架构可能导致一个线程无法马上（甚至永远）看到另一个线程操作产生的结果。所以 Java 内存模型规定了 JVM 的一种最小保证：什么时候写入一个变量对其他线程可见。<br>在现代可共享内存的多处理器体系结构中每个处理器都有自己的缓存，并周期性的与主内存协调一致。假设线程 A 写入一个变量值 V，随后另一个线程 B 读取变量 V 的值，在下列情况下，线程 B 读取的值可能不是线程 A 写入的最新值：</li>
<li>执行线程 A 的处理器把变量 V 缓存到寄存器中。</li>
<li>执行线程 A 的处理器把变量 V 缓存到自己的缓存中，但还没有同步刷新到主内存中去。</li>
<li>执行线程 B 的处理器的缓存中有变量 V 的旧值。<h5 id="Happens-before_关系"><strong>Happens-before 关系</strong></h5>happens-before 关系保证：如果线程 A 与线程 B 满足 happens-before 关系，则线程 A 执行动作的结果对于线程 B 是可见的。如果两个操作未按 happens-before 排序，JVM 将可以对他们任意重排序。<br>下面介绍几个与理解 ConcurrentHashMap 有关的 happens-before 关系法则：</li>
</ul>
<ol>
<li>程序次序法则：如果在程序中，所有动作 A 出现在动作 B 之前，则线程中的每动作 A 都 happens-before 于该线程中的每一个动作 B。</li>
<li>监视器锁法则：对一个监视器的解锁 happens-before 于每个后续对同一监视器的加锁。</li>
<li>Volatile 变量法则：对 Volatile 域的写入操作 happens-before 于每个后续对同一 Volatile 的读操作。</li>
<li>传递性：如果 A happens-before 于 B，且 B happens-before C，则 A happens-before C。</li>
</ol>
<p>以上摘自<a href="https://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/" target="_blank" rel="external">探索 ConcurrentHashMap 高并发性的实现机制</a></p>
<hr>
<h4 id="参考文章"><strong>参考文章</strong></h4><p>1.<a href="https://www.ibm.com/developerworks/cn/java/java-lo-concurrenthashmap/" target="_blank" rel="external">探索 ConcurrentHashMap 高并发性的实现机制</a><br>2.<a href="http://www.infoq.com/cn/articles/ConcurrentHashMap" target="_blank" rel="external">聊聊并发（四）——深入分析ConcurrentHashMap</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>ConcurrentHashMap类在我的开发过程中经常被使用，个人觉得如果在共享一个Map时，如果无法判断是否需要加锁，那么就干脆直接使用ConcurrentHashMap，即能保证并发安全，同时性能也不会有太多下降，因为ConcurrentHashMap可实现无锁读，不过内存会占用的多些，但是并不明显，基本可以忽略。<br>]]>
    
    </summary>
    
      <category term="ConcurrentHashMap" scheme="http://vickyqi.com/tags/ConcurrentHashMap/"/>
    
      <category term="JDK" scheme="http://vickyqi.com/tags/JDK/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="并发" scheme="http://vickyqi.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="JDK源码学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/JDK%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[JDK并发工具类源码学习系列——介绍]]></title>
    <link href="http://vickyqi.com/2015/10/24/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94%E4%BB%8B%E7%BB%8D/"/>
    <id>http://vickyqi.com/2015/10/24/JDK并发工具类源码学习系列——介绍/</id>
    <published>2015-10-24T12:32:11.000Z</published>
    <updated>2015-10-31T06:38:20.000Z</updated>
    <content type="html"><![CDATA[<p>JDK并发工具类是JDK1.5引入的一大重要的功能，集中在java.util.concurrent包下，java.util.concurrent包下还包括了java.util.concurrent.atomic以及java.util.concurrent.locks两个子包。java.util.concurrent包主要包含了并发集合类以及线程池和信号量三组重要工具类；java.util.concurrent.atomic包下是JDK提供的一组原子操作类；java.util.concurrent.locks包下是JDK提供的锁机制。本系列主要关注java.util.concurrent包下的并发集合类：</p>
<ul>
<li><a href="http://vickyqi.com/2015/10/26/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentHashMap/">ConcurrentHashMap</a></li>
<li><a href="http://vickyqi.com/2015/10/29/JDK%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0%E7%B3%BB%E5%88%97%E2%80%94%E2%80%94ConcurrentLinkedQueue/">ConcurrentLinkedQueue</a></li>
<li>ConcurrentSkipListMap</li>
<li>CopyOnWriteArrayList</li>
<li>LinkedBlockingQueue</li>
<li>PriorityBlockingQueue</li>
<li>SynchronousQueue</li>
<li>ArrayBlockingQueue</li>
</ul>
<p>以上暂定为本系列将要分析源码的类，每完成一篇会来更新一下链接，欢迎大家关注。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>JDK并发工具类是JDK1.5引入的一大重要的功能，集中在java.util.concurrent包下，java.util.concurrent包下还包括了java.util.concurrent.atomic以及java.util.concurrent.locks两个子包]]>
    </summary>
    
      <category term="JDK" scheme="http://vickyqi.com/tags/JDK/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="并发" scheme="http://vickyqi.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="JDK源码学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/JDK%E6%BA%90%E7%A0%81%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[几种常用JSON库性能比较]]></title>
    <link href="http://vickyqi.com/2015/10/19/%E5%87%A0%E7%A7%8D%E5%B8%B8%E7%94%A8JSON%E5%BA%93%E6%80%A7%E8%83%BD%E6%AF%94%E8%BE%83/"/>
    <id>http://vickyqi.com/2015/10/19/几种常用JSON库性能比较/</id>
    <published>2015-10-19T06:47:47.000Z</published>
    <updated>2015-10-20T08:01:52.000Z</updated>
    <content type="html"><![CDATA[<p>JSON不管是在Web开发还是服务器开发中是相当常见的数据传输格式，一般情况我们对于JSON解析构造的性能并不需要过于关心，除非是在性能要求比较高的系统。<br>目前对于Java开源的JSON类库有很多种，下面我们取三个常用的JSON库进行性能测试对比，同时根据测试结果分析如果根据实际应用场景选择最合适的JSON库。<br>四个JSON类库分别为：Gson，FastJson，Jackson，Json-lib。<br>简单介绍下四个类库的身份背景。</p>
<ul>
<li>Gson（项目地址：<a href="https://github.com/google/gson）" target="_blank" rel="external">https://github.com/google/gson）</a><ul>
<li>Gson是目前功能最全的Json解析神器，Gson当初是为因应Google公司内部需求而由Google自行研发而来，但自从在2008年五月公开发布第一版后已被许多公司或用户应用。Gson的应用主要为toJson与fromJson两个转换函数，无依赖，不需要例外额外的jar，能够直接跑在JDK上。而在使用这种对象转换之前需先创建好对象的类型以及其成员才能成功的将JSON字符串成功转换成相对应的对象。类里面只要有get和set方法，Gson完全可以将复杂类型的json到bean或bean到json的转换，是JSON解析的神器。</li>
</ul>
</li>
<li>FastJson（项目地址：<a href="https://github.com/alibaba/fastjson）" target="_blank" rel="external">https://github.com/alibaba/fastjson）</a><ul>
<li>Fastjson是一个Java语言编写的高性能的JSON处理器,由阿里巴巴公司开发。无依赖，不需要例外额外的jar，能够直接跑在JDK上。FastJson在复杂类型的Bean转换Json上会出现一些问题，可能会出现引用的类型，导致Json转换出错，需要制定引用。FastJson采用独创的算法，将parse的速度提升到极致，超过所有json库。</li>
</ul>
</li>
<li>Jackson（项目地址：<a href="https://github.com/FasterXML/jackson）" target="_blank" rel="external">https://github.com/FasterXML/jackson）</a><ul>
<li>相比json-lib框架，Jackson所依赖的jar包较少，简单易用并且性能也要相对高些。而且Jackson社区相对比较活跃，更新速度也比较快。Jackson对于复杂类型的json转换bean会出现问题，一些集合Map，List的转换出现问题。Jackson对于复杂类型的bean转换Json，转换的json格式不是标准的Json格式。</li>
</ul>
</li>
<li>Json-lib（项目地址：<a href="http://json-lib.sourceforge.net/index.html）" target="_blank" rel="external">http://json-lib.sourceforge.net/index.html）</a><ul>
<li>json-lib最开始的也是应用最广泛的json解析工具，json-lib 不好的地方确实是依赖于很多第三方包，包括commons-beanutils.jar，commons-collections-3.2.jar，commons-lang-2.6.jar，commons-logging-1.1.1.jar，ezmorph-1.0.6.jar，对于复杂类型的转换，json-lib对于json转换成bean还有缺陷，比如一个类里面会出现另一个类的list或者map集合，json-lib从json到bean的转换就会出现问题。json-lib在功能和性能上面都不能满足现在互联网化的需求。</li>
</ul>
</li>
</ul>
<p>选择一个合适的JSON库要从多个方面进行考虑：</p>
<ol>
<li>字符串解析成JSON性能</li>
<li>字符串解析成JavaBean性能</li>
<li>JavaBean构造JSON性能</li>
<li>集合构造JSON性能</li>
<li>易用性</li>
</ol>
<p>对于前四条其实都是从JSON的解析构造性能角度考虑，而最后一条则是考虑易用性，这点对于开发者来说其实也是需要考虑的一个问题，如果该库的API使用难度大，或者很复杂，那么不建议使用，毕竟JSON解析的性能差异并不大。下面的测试结果针对四个不同数量级的JSON字符串，以及分别测试上面提到的前四条性能，结果如下：<br><img src="http://img.blog.csdn.net/20150901164447842" alt="这里写图片描述"><br>Json-lib在数据量在10W时OOM了，内存开到1G都不行，所以直接Pass了。<br>从上面图表可以看到：</p>
<ol>
<li>字符串解析成JavaBean：当数据量较少时首选FastJson，数据量较大使用Jackson。但是Jackson无法堆一个对象集合进行解析，只能转成一个Map集合，这点Gson和FastJson处理的比较好。</li>
<li>字符串解析成JSON：当数据量较少时首选FastJson，数据量较大使用Jackson。</li>
<li>JavaBean构造JSON：当数据量较少时选择Gson，数据量较大可使用Jackson。</li>
<li>集合构造JSON：首先Jackson，其次Fastjson。</li>
</ol>
<p>上面是从性能角度分析四种JSON类库，从易用性角度来分析的话，FastJson的API设计的最简单，最方便使用，直接使用JSON的两个静态方法即可完成四种操作；而Gson和Jackson都需要new一个对象，虽然这个对象可以复用，但是在实际使用过程中还需要用一个全局变量来保存改变量，同时API设计的也不是很好理解，对于FastJson来说复杂的API是因为他支持流式解析，适合对JSON进行大量且复杂的操作，但是实际应用中对于JSON的操作都是简单的解析成JavaBean，然后JavaBean序列化成JSON字符串即可，复杂的操作很少。<br>下面从我自己实际的应用场景出发，考虑该如何选择合适的JSON类库。<br>应用场景：游戏服务器，基本是对客户端发送过来的JSON格式字符串解析成JavaBean，然后将封装好的指令转成JSON字符串返回给客户端，这里考虑到JavaBean转成JSON与集合转成JSON的性能差异，所以直接使用集合进行转成JSON，避免使用JavaBean。<br>考虑上述场景适合使用FastJson进行JSON字符串解析，Jackson将集合转成JSON格式字符串。<br>浅尝辄止，欢迎批评指出。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>JSON不管是在Web开发还是服务器开发中是相当常见的数据传输格式，一般情况我们对于JSON解析构造的性能并不需要过于关心，除非是在性能要求比较高的系统。<br>目前对于Java开源的JSON类库有很多种，下面我们取三个常用的JSON库进行性能测试对比，同时根据测试结果分析]]>
    </summary>
    
      <category term="JSON" scheme="http://vickyqi.com/tags/JSON/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[使用Apache Commons CLI开发命令行工具]]></title>
    <link href="http://vickyqi.com/2015/10/19/%E4%BD%BF%E7%94%A8Apache%20Commons%20CLI%E5%BC%80%E5%8F%91%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/"/>
    <id>http://vickyqi.com/2015/10/19/使用Apache Commons CLI开发命令行工具/</id>
    <published>2015-10-19T06:47:47.000Z</published>
    <updated>2015-10-20T05:11:24.000Z</updated>
    <content type="html"><![CDATA[<p>工作两年多，从没遇到需要使用命令行那样的参数形式执行命令的需求，突然好奇想试试，于是找到了Apache Commons CLI，大致了解试用了下，挺简单的，总共也就那点东西。<br>Apache Commons CLI官网地址：(<a href="https://commons.apache.org/cli/download_cli.cgi" target="_blank" rel="external">https://commons.apache.org/cli/download_cli.cgi</a>)<br>使用Apache Commons CLI开发命令行工具分成三步：<br>1）定义CLI<br>2）解析CLI<br>3）处理CLI<br>首先我们参考官网给出的一个例子：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ant [options] [target [target2 [target3] ...]]</span><br><span class="line">  Options: </span><br><span class="line">  -<span class="operator"><span class="keyword">help</span>                  print this message</span><br><span class="line">  -projecthelp           print <span class="keyword">project</span> <span class="keyword">help</span> information</span><br><span class="line">  -<span class="keyword">version</span>               print the <span class="keyword">version</span> information <span class="keyword">and</span> <span class="keyword">exit</span></span><br><span class="line">  -quiet                 be extra quiet</span><br><span class="line">  -verbose               be extra verbose</span><br><span class="line">  -debug                 print debugging information</span><br><span class="line">  -emacs                 produce <span class="keyword">logging</span> information <span class="keyword">without</span> adornments</span><br><span class="line">  -<span class="keyword">logfile</span> &lt;<span class="keyword">file</span>&gt;        <span class="keyword">use</span> given <span class="keyword">file</span> <span class="keyword">for</span> <span class="keyword">log</span></span><br><span class="line">  -logger &lt;classname&gt;    the <span class="keyword">class</span> which <span class="keyword">is</span> <span class="keyword">to</span> perform <span class="keyword">logging</span></span><br><span class="line">  -listener &lt;classname&gt;  <span class="keyword">add</span> an <span class="keyword">instance</span> <span class="keyword">of</span> <span class="keyword">class</span> <span class="keyword">as</span> a <span class="keyword">project</span> listener</span><br><span class="line">  -buildfile &lt;<span class="keyword">file</span>&gt;      <span class="keyword">use</span> given buildfile</span><br><span class="line">  -<span class="keyword">D</span>&lt;property&gt;=&lt;<span class="keyword">value</span>&gt;   <span class="keyword">use</span> <span class="keyword">value</span> <span class="keyword">for</span> given property</span><br><span class="line">  -find &lt;<span class="keyword">file</span>&gt;           <span class="keyword">search</span> <span class="keyword">for</span> buildfile towards the root <span class="keyword">of</span> the</span><br><span class="line">                         filesystem <span class="keyword">and</span> <span class="keyword">use</span> it</span></span><br></pre></td></tr></table></figure></p>
<p>该例子是ant的命令，我们可以对照着进行开发（其实官网就有，英文好的可以直接移步<br>(<a href="https://commons.apache.org/proper/commons-cli/usage.html)）。" target="_blank" rel="external">https://commons.apache.org/proper/commons-cli/usage.html)）。</a></p>
<p>####定义CLI：<br>首先参照上面的三部曲，第一步定义CLI：<br>Apache Commons CLI使用Option表示每一个命令，使用Options封装多个Option，创建Option的方式有三种：</p>
<ol>
<li>Option op = new Option(…);//构造器</li>
<li>Options.addOption(…);//Options直接构造</li>
<li>Option.Builder辅助类<br>1.2适合简单的创建的命令，如上面logfile命令以上的命令。我们举几个例子：</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Options ops = new Options();</span><br><span class="line">Option <span class="operator"><span class="keyword">help</span> = <span class="keyword">new</span> <span class="keyword">Option</span>( <span class="string">"help"</span>, <span class="string">"print this message"</span> );</span></span><br><span class="line">ops.addOption(<span class="operator"><span class="keyword">help</span>);</span></span><br><span class="line">ops.addOption("projecthelp", "print project <span class="operator"><span class="keyword">help</span> information<span class="string">");</span></span></span><br></pre></td></tr></table></figure>
<p>同时如果我们假设debug命令后可跟值true/false，那么我们可以这样定义命令：</p>
<figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ops.addOption(<span class="string">"debug"</span>, <span class="keyword">true</span>, <span class="string">"print debugging information"</span>); <span class="regexp">//</span>第二个参数<span class="keyword">true</span>表示该命令后可跟参数，其实就是命令后面跟上值</span><br></pre></td></tr></table></figure>
<p>下面我们看logfile以下除去<code>-D&lt;property&gt;=&lt;value&gt;</code> 之外的的命令如何创建，这里使用第三种方式：</p>
<figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">Option</span> logfile = <span class="built_in">Option</span>.builder(<span class="string">"logfile"</span>).argName(<span class="string">"file"</span>).hasArg().desc(<span class="string">"use given file for log"</span>).build();<span class="comment">// argName指定命令后跟的参数名称</span></span><br><span class="line">ops.addOption(logfile);</span><br></pre></td></tr></table></figure>
<p>最后我们看看如何定义<code>-D&lt;property&gt;=&lt;value&gt;</code>：</p>
<figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Option <span class="keyword">D</span> = Option.builder(<span class="string">"D"</span>).argName(<span class="string">"property=value"</span>).numberOfArgs(2).valueSeparator(<span class="string">"="</span>)</span><br><span class="line">				.<span class="keyword">desc</span>(<span class="string">"use value for given property"</span>).build();<span class="comment">// 这里numberOfArgs指定了后跟两个参数，且valueSeparator指定了连接符是=，这样CLI可以自动帮我们解析键值对</span></span><br><span class="line">ops.addOption(<span class="keyword">D</span>);</span><br></pre></td></tr></table></figure>
<h4 id="解析CLI：">解析CLI：</h4><p>以上全部定义好之后，就可以对传入的参数进行解析了。DefaultParser类是用来解析参数，得到每个命令以及对应的值，而且对于如上面的<code>-D&lt;property&gt;=&lt;value&gt;</code> 这种命令，由于我们制定了“=”为分隔符，DefaultParser可以自动为我们将参数解析成Properties，很方便。</p>
<figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CommandLine comm = <span class="literal">null</span>;</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line">	comm = <span class="keyword">new</span> DefaultParser().parse(ops, args);</span><br><span class="line">&#125; <span class="keyword">catch</span> (ParseException e) &#123;</span><br><span class="line">	e.printStackTrace();</span><br><span class="line">	<span class="built_in">log</span>.<span class="built_in">error</span>(<span class="string">"解析参数失败，参数：["</span> + Arrays.asList(args).toString() + <span class="string">"]"</span>);</span><br><span class="line">	<span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="处理CLI">处理CLI</h4><p>上面已经对传入的参数解析好了，剩下的就是获取到这些命令的值，以及进行相应的处理了，也就是我们的业务逻辑了。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (comm.getOptions().length == <span class="number">0</span>) &#123;</span><br><span class="line">	<span class="built_in">log</span>.info(<span class="string">"No any param to specify."</span>);</span><br><span class="line">	<span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (comm.hasOption(<span class="string">"h"</span>)) &#123;<span class="comment">// help</span></span><br><span class="line">	HelpFormatter formatter = <span class="keyword">new</span> HelpFormatter();</span><br><span class="line">	formatter.printHelp(<span class="string">"options"</span>, ops);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (comm.hasOption(<span class="string">"s"</span>)) &#123;<span class="comment">// 执行命令</span></span><br><span class="line">	<span class="keyword">new</span> SystemCommand().execute(comm.getOptionValue(<span class="string">"s"</span>));</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (comm.hasOption(<span class="string">"D"</span>)) &#123;<span class="comment">// 传递参数</span></span><br><span class="line">	Properties props = comm.getOptionProperties(<span class="string">"D"</span>);</span><br><span class="line">	<span class="keyword">new</span> ParamParser(props).parse();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上面是一个简单的例子，这里有个getOptionProperties方法，这个方法是针对使用分隔符的命令方便获取键值对行为的属性值而设计的，很好用，免去了自己再做字符串切分的麻烦。<br>到这里整个使用Apache Commons CLI开发命令行工具的工作就完成了，很简单。</p>
<ul>
<li>Apache Commons CLI总共支持的几种命令模式：</li>
<li>POSIX like options (ie. tar -zxvf foo.tar.gz)</li>
<li>GNU like long options (ie. du –human-readable –max-depth=1)</li>
<li>Java like properties (ie. java -Djava.awt.headless=true -Djava.net.useSystemProxies=true Foo)</li>
<li>Short options with value attached (ie. gcc -O2 foo.c)</li>
<li>long options with single hyphen (ie. ant -projecthelp)</li>
</ul>
<p>对于GNU模式官网还有一个例子，可以自行参考下。<br>附上官网的一个Option的属性表：</p>
<table>
<thead>
<tr>
<th>Name</th>
<th style="text-align:left">Type</th>
<th style="text-align:left">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>opt</td>
<td style="text-align:left">java.lang.String</td>
<td style="text-align:left">the identification string of the Option.</td>
</tr>
<tr>
<td>longOpt</td>
<td style="text-align:left">java.lang.String</td>
<td style="text-align:left">an alias and more descriptive identification string.</td>
</tr>
<tr>
<td>description</td>
<td style="text-align:left">java.lang.String</td>
<td style="text-align:left">a description of the function of the option.</td>
</tr>
<tr>
<td>required</td>
<td style="text-align:left">boolean</td>
<td style="text-align:left">a flag to say whether the option must appear on the command line.</td>
</tr>
<tr>
<td>arg</td>
<td style="text-align:left">boolean</td>
<td style="text-align:left">a flag to say whether the option takes an argument.</td>
</tr>
<tr>
<td>args</td>
<td style="text-align:left">boolean</td>
<td style="text-align:left">a flag to say whether the option takes more than one argument.</td>
</tr>
<tr>
<td>optionalArg</td>
<td style="text-align:left">boolean</td>
<td style="text-align:left">a flag to say whether the option’s argument is optional.</td>
</tr>
<tr>
<td>argName</td>
<td style="text-align:left">java.lang.String</td>
<td style="text-align:left">the name of the argument value for the usage statement.</td>
</tr>
<tr>
<td>valueSeparator</td>
<td style="text-align:left">char</td>
<td style="text-align:left">the character value used to split the argument string, that is used in conjunction with multipleArgs e.g. if the separator is ‘,’ and the argument string is ‘a,b,c’ then there are three argument values, ‘a’, ‘b’ and ‘c’.</td>
</tr>
<tr>
<td>type</td>
<td style="text-align:left">java.lang.Object</td>
<td style="text-align:left">the type of the argument.</td>
</tr>
<tr>
<td>value</td>
<td style="text-align:left">java.lang.String</td>
<td style="text-align:left">the value of the option.</td>
</tr>
<tr>
<td>values</td>
<td style="text-align:left">java.lang.String[]</td>
<td style="text-align:left">the values of the option.</td>
</tr>
</tbody>
</table>
<p>参考文章：<br><a href="https://www.ibm.com/developerworks/cn/java/j-lo-commonscli/" target="_blank" rel="external">使用 Apache Commons CLI 开发命令行工具</a><br><a href="https://commons.apache.org/proper/commons-cli/project-info.html" target="_blank" rel="external">Apache Commons CLI</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>工作两年多，从没遇到需要使用命令行那样的参数形式执行命令的需求，突然好奇想试试，于是找到了Apache Commons CLI，大致了解试用了下，挺简单的，总共也就那点东西。<br>Apache Commons CLI官网地址：(<a href="https://commo]]>
    </summary>
    
      <category term="Cli" scheme="http://vickyqi.com/tags/Cli/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="命令行" scheme="http://vickyqi.com/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[详解原码、反码、补码——深入理解补码]]></title>
    <link href="http://vickyqi.com/2015/10/19/%E8%AF%A6%E8%A7%A3%E5%8E%9F%E7%A0%81%E3%80%81%E5%8F%8D%E7%A0%81%E3%80%81%E8%A1%A5%E7%A0%81%E2%80%94%E2%80%94%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E8%A1%A5%E7%A0%81/"/>
    <id>http://vickyqi.com/2015/10/19/详解原码、反码、补码——深入理解补码/</id>
    <published>2015-10-19T06:19:11.000Z</published>
    <updated>2015-10-20T03:39:34.000Z</updated>
    <content type="html"><![CDATA[<p>学过计算机原理的人都知道原码、反码、补码，但是有多少人知道为什么会有这三种码呢，这三种码又是用来干嘛的呢。<br>众所周知，在计算机的世界只有01，那么显然所有的数都得转成二进制，这样计算机才能够理解。如何将一个十进制的数转成二进制就不说了，说下原码，正数的原码就是十进制转成二进制得到的二进制值，而负数是对应的正数转成二进制得到的二进制值，然后将最高位（符号位）置为1表示这是一个负数，如-10:10001010。</p>
<h5 id="1-_原码"><strong>1. 原码</strong></h5><p>计算机进行算术运算时为了简单效率所以要求能够使用加法代替减法，如1-1==1+(-1)==0，那么我们先看看原码能不能实现这种需求。<br>示例：<br><figure class="highlight asciidoc"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">计算76-10==66</span><br><span class="line"><span class="code">   十进制     二进制</span></span><br><span class="line"><span class="code">   76        01001100</span></span><br><span class="line"><span class="header"> +  -10       10001010</span><br><span class="line">---------------------</span></span><br><span class="line"><span class="code">   66        11010110（-86）</span></span><br></pre></td></tr></table></figure></p>
<h5 id="2-_反码"><strong>2. 反码</strong></h5><p>从上面算出的结果可见原码是无法完成对减法的运算需求的，那么由于1-1==1+（-1），所以人类又找到了一个看似能够解决这个问题的解决方法——反码，即将负数的符号位不变其余位取反。下面我们再看看反码能不能解决问题。<br>示例1：计算15-125<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">计算<span class="number">15</span>-<span class="number">125</span>==-<span class="number">110</span></span><br><span class="line">   十进制     二进制原码    二进制反码</span><br><span class="line">   <span class="number">15</span>        <span class="number">00001111</span>    <span class="number">00001111</span></span><br><span class="line"> +  -<span class="number">125</span>      <span class="number">11111101</span>    <span class="number">10000010</span></span><br><span class="line">---------------------------------</span><br><span class="line">   -<span class="number">110</span>      <span class="number">11101110</span>    <span class="number">10010001</span></span><br><span class="line">得到<span class="number">10010001</span>(反码)==<span class="number">11101110</span>(原码)==-<span class="number">110</span>，正确。注意：使用反码计算得到的结果也是反码，需要再次转换成原码。</span><br></pre></td></tr></table></figure></p>
<p>示例2：计算76-10<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">计算<span class="number">76</span>-<span class="number">10</span>==<span class="number">66</span></span><br><span class="line">   十进制     二进制原码    二进制反码</span><br><span class="line">   <span class="number">76</span>        <span class="number">01001100</span>    <span class="number">01001100</span></span><br><span class="line"> + -<span class="number">10</span>       <span class="number">10001010</span>    <span class="number">11110101</span></span><br><span class="line">---------------------------------</span><br><span class="line">   <span class="number">66</span>        <span class="number">01000010</span>    <span class="number">101000001</span>==<span class="number">01000010</span>  </span><br><span class="line">这里得到的值超过<span class="number">8</span>bit，所以最高的<span class="number">1</span>需要丢弃，丢弃后需要在最低位+<span class="number">1</span>，得到<span class="number">01000010</span>(反码)==<span class="number">01000010</span>(原码)==<span class="number">66</span>，正确。</span><br></pre></td></tr></table></figure></p>
<p>示例3：计算1-1<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">计算<span class="number">1</span>-<span class="number">1</span>==<span class="number">0</span></span><br><span class="line">   十进制     二进制原码    二进制反码</span><br><span class="line">   <span class="number">1</span>         <span class="number">00000001</span>    <span class="number">00000001</span></span><br><span class="line"> + -<span class="number">1</span>        <span class="number">10000001</span>    <span class="number">11111110</span></span><br><span class="line">---------------------------------</span><br><span class="line">   <span class="number">0</span>         <span class="number">10000000</span>    <span class="number">11111111</span>  </span><br><span class="line">得到<span class="number">11111111</span>(反码)==<span class="number">10000000</span>(原码)==-<span class="number">0</span>，-<span class="number">0</span>？通过反码计算会出现+<span class="number">0</span>和-<span class="number">0</span>，一个<span class="number">0</span>对应了两个码，显然是不合理的。</span><br></pre></td></tr></table></figure></p>
<p>从上面三个例子可以看出使用反码进行减法运算时存在两个问题：</p>
<ol>
<li>当计算结果溢出时需要额外进行+1操作，使得运算多了一步，效率降低</li>
<li><p>0存在+0和-0两种存在方式，不方便理解</p>
<h5 id="3-_模与互补、同余"><strong>3. 模与互补、同余</strong></h5><p>在看补码之前，先介绍三个概念——模、补数、同余。我们从现实生活举例来看：</p>
<ul>
<li>我们将一个时钟的分针往前拨20分钟，和往后拨40分钟，得到的结果是一样的。</li>
<li>把你的属年(属猴)往后退5年，和往前进7年，一样都是属兔。</li>
<li>把数字 87，减去 25，和加上 75，在不考虑百位数的条件下，得到的结果都是62。</li>
</ul>
</li>
</ol>
<p>上述几组数字，有这样的关系：<br>　　20 + 40 = 60<br>　　5 + 7 = 12<br>　　25 + 75 = 100<br>式中的 60、12 和 100，就是“模”。<br>式中的 20和40、5和7，以及25和75，就是一对对“互补”的数字。<br>而且20，80，140在模是60的情况下就是互为“同余”的数字。<br>通俗解释下模、补数、同余的概念：</p>
<ul>
<li><strong>模</strong>：就是一个轮回，比如分针转一圈，十二生肖一轮等等。</li>
<li><strong>互补 </strong>：一个数值针对某个模的互补值就是这个数值加上或者减去多少能够等于模，或者等于模的同余值。</li>
<li><strong>同余 </strong>：一个数值加上或者减去模的整数倍得到的所有数值即为该数值的同余值<strong>(也就是除上模，余数是一样，所以叫同余)</strong>，0是模的同余，-模也是模的同余。</li>
</ul>
<p>理解了什么是模，什么是互补、什么是同余，那么如果给一个模，以及一个值a，如果计算a的补数(与a互补的值)呢，其实很简单，只需要拿模-a即可，计算同余值可以直接加上或者减去模的整数倍即可。</p>
<h5 id="4-_那么互补的值有什么用呢？"><strong>4. 那么互补的值有什么用呢？</strong></h5><p>如果我们在进行减法运算时，用与减数互补的值代替减数与被减数进行加法运算会发生什么呢？废话不多说，看示例。<br>示例1：在分钟刻度下，计算55分钟往后拨动34分钟，转化成数学计算就是：55-34<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">被减数	     <span class="number">55</span></span><br><span class="line">减数		  <span class="number">34</span></span><br><span class="line">减数补数   <span class="number">60</span>-<span class="number">34</span>==<span class="number">26</span></span><br><span class="line">最终结果     <span class="number">55</span>+<span class="number">26</span>==<span class="number">81</span></span><br><span class="line">---------------------</span><br><span class="line">用减数补数代替减数得到结果为<span class="number">81</span>,<span class="number">81</span>在分钟刻度盘上正好是<span class="number">21</span>，也就是<span class="number">81</span>是<span class="number">21</span>的同余值，和<span class="number">55</span>-<span class="number">34</span>是一样的。注意：这里涉及到类似上面的<span class="number">87</span>+<span class="number">75</span>的情况，即忽略了进位。</span><br></pre></td></tr></table></figure></p>
<p>示例2：在十二生肖中，计算猴年往后退11年，转化成数学计算就是：9-11<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">被减数	     <span class="number">9</span></span><br><span class="line">减数		  <span class="number">11</span></span><br><span class="line">减数补数   <span class="number">12</span>-<span class="number">11</span>==<span class="number">1</span></span><br><span class="line">最终结果     <span class="number">9</span>+<span class="number">1</span>==<span class="number">10</span></span><br><span class="line">-------------------</span><br><span class="line">用减数互补值代替减数得到结果为<span class="number">10</span>,<span class="number">10</span>对应到十二生肖正好是鸡，和猴年往后退<span class="number">11</span>年是一样的，所以得到的也是一个同余值。</span><br></pre></td></tr></table></figure></p>
<p>从上面的示例可以看出，使用互补值计算出的结果与实际值其实是<strong>同余</strong>的关系。</p>
<h5 id="5-_二进制的模"><strong>5. 二进制的模</strong></h5><p>上面看了分钟刻度盘的模，十二生肖的模，以及两位整数的模，那么对于一个8bit的字节的模是多少呢？<br>分钟刻度盘的模为什么是60？是因为他的值是从1-59，总共60个值，十二生肖以及两位整数也是一样的，所以我们只需要看看一个8bit的字节的所有取值一共是多少个就是他的模，显示8个bit可表示的最小值是00000000==0，最大值是11111111==255，那么从0到255一共是256个值，所以一个8bit的字节的模就是256了。但是其实在计算机中为了能够表示负数，所以讲8bit的字节的最高位设为符号位，0表示整数，1表示负数，所以能够表示数值的也就只有7bit，如果我们忽视符号位，那么剩下7bit的模就是128，而不是256了。<strong>下面在计算时我们会直接使用128而非256！</strong></p>
<h5 id="6-_使用互补值进行二进制的减法计算"><strong>6. 使用互补值进行二进制的减法计算</strong></h5><p>下面我们就来看看如果使用互补值来进行二进制的减法计算，我们先来看一个公式：假设模式M，我们计算X-Y，然后我们使用减数的补数来计算，看看下面的换算：</p>
<figure class="highlight tp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">X</span>-<span class="keyword">Y</span> == <span class="keyword">X</span>+(M-<span class="keyword">Y</span>) == <span class="keyword">X</span>+((M-<span class="number">1</span>)-<span class="keyword">Y</span>+<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>下面我们来看示例，这个公式在下面会用到的。</p>
<p>示例1：计算15-125<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">           十进制          二进制</span><br><span class="line">被减数	     <span class="number">15</span>             <span class="number">0001111</span></span><br><span class="line">减数		  <span class="number">125</span>            <span class="number">1111101</span></span><br><span class="line">减数补数   <span class="number">128</span>-<span class="number">125</span>==<span class="number">3</span>     <span class="number">0000011</span></span><br><span class="line">最终结果     <span class="number">18</span>             <span class="number">0010010</span></span><br><span class="line">------------------------------------</span><br><span class="line">得到<span class="number">0010010</span>==<span class="number">18</span>，在模式<span class="number">128</span>的情况下，<span class="number">18</span>正好是-<span class="number">110</span>的同余值，跟上面现实的例子是一样的！</span><br></pre></td></tr></table></figure></p>
<p>示例2：计算76-10<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">           十进制          二进制</span><br><span class="line">被减数	     <span class="number">76</span>             <span class="number">01001100</span></span><br><span class="line">减数		  <span class="number">10</span>            <span class="number">00001010</span></span><br><span class="line">减数补数   <span class="number">256</span>-<span class="number">10</span>==<span class="number">246</span>   <span class="number">11110110</span></span><br><span class="line">最终结果     <span class="number">322</span>    <span class="number">101000010</span></span><br><span class="line">------------------------------------</span><br><span class="line">得到<span class="number">101000010</span>==<span class="number">322</span>，在模式<span class="number">256</span>的情况下，<span class="number">322</span>正好是<span class="number">66</span>的同余值，结果还是一样！</span><br></pre></td></tr></table></figure></p>
<p>从上面两个例子我们应该可以看出，如果我们使用减数的补数进行加法运算，那么得到的结果就是一个与正确结果同余的值。在现实生活中，我们可以直接把两个同余的值看做是相同的，例如分钟20和分钟80完全就是一样的，那么在计算机里我们可以这么假设吗？答案是可以的，看下面。<br>试想当计算机使用一个7bit的空间保存一个数值时是如何保存的，比如18，我们可以这么推算，首先分配一个7bit的空间，每个bit上的值都是0，那么如何表示18呢？我们可以这样理解：往这个7bit的空间内进行18次加1操作，满2就进1，最终就会得到0010010。那么如何表示-110，我们可以理解为往这个7bit的空间内进行110次减1操作，一开始全是0，那么如何减1呢？很简单直接减成1111111即可，可以这样理解，分钟在0刻度，你往后拨一下就会指向59，这里也是这个道理，所以连续减110次，就会得到0010010，根18是一样的，所以在计算机看来18和-110是一样的。<br>也就是说<strong>15-125 == 15+(128-125) == 15+(127-125+1) </strong>(上面的公式)，也就是说-125被127-125+1代替了，那么<strong>127-125+1（M-）</strong>又是什么？</p>
<h5 id="7-_补码"><strong>7. 补码</strong></h5><p>上面一路走来终于证明了使用补数可以代替减法，下面我们要解决的问题是M-1-Y+1是啥。<br>我们直接看二进制如何计算M-1-Y+1。<br>示例：计算M=128，Y=110</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">     十进制   二进制</span><br><span class="line"> M-<span class="number">1</span>  <span class="number">127</span>   <span class="number">1111111</span></span><br><span class="line"> -Y   <span class="number">110</span>   <span class="number">1101110</span></span><br><span class="line">            <span class="number">0010001</span></span><br><span class="line">--------------------</span><br><span class="line">M-<span class="number">1</span>换算成二进制就是N位<span class="number">1</span>，那么N位<span class="number">1</span>减去任何一个N位的二进制是啥呢？其实就是按位取反！因为遇到<span class="number">0</span>,<span class="number">1</span>-<span class="number">0</span>==<span class="number">1</span>，取反，遇到<span class="number">1</span>,<span class="number">1</span>-<span class="number">1</span>==<span class="number">0</span>，取反，所以整体就是按位取反，也就是反码。</span><br><span class="line">            </span><br><span class="line"> +<span class="number">1</span>   <span class="number">1</span>     <span class="number">0000001</span></span><br><span class="line">            <span class="number">0010010</span></span><br><span class="line"> ------------------</span><br><span class="line">所以总体就是在<span class="number">110</span>的二进制基础上按位取反然后加<span class="number">1</span>,也就是<span class="number">110</span>的反码加<span class="number">1</span>。</span><br></pre></td></tr></table></figure>
<p>看了上面的示例，应该知道M=128，Y=110，M-1-Y+1就是Y的反码加1，也就是说，如果我们需要计算X-Y，只需要计算X+(Y的反码+1)，由于我们得出这个结论是使用<strong>补数替代减法</strong>得到的，所以<strong>Y的反码+1</strong>就被叫做Y的<strong>补码</strong>。<br>到这里我们知道了110的补码，上面我们介绍了计算机使用1字节的最高位表示符号位，1表示负数，所以-110的最高位是1，由于在使用补码进行减法运算过程中最高位并不参与运算，所以这个最高位应该是固定不动的，所以负数的反码补码最高位始终都是1。<strong>也就得到了-110的补码是：10010010</strong>。对于正数，符号位是0，那么反码补码最高位就始终是0，而且对于正数在计算时也无需使用其补码进行操作，但是为了统一都是用补码，所以定正数的反码补码都等于原码。<br>根据补码的计算过程有些文章会说一个负数X的补码对应的值==2^n-|X|，理解了上面的过程这个公式就自然懂了，不过这个公式没啥用，也没必要记。<br>到这里终于把<strong>补码</strong>的来历说清楚了，至少我自己是明白了，但愿读者也可以明白吧！</p>
<h5 id="一些补码的其他知识"><strong>一些补码的其他知识</strong></h5><p>上面我们看了7bit的模式128，也就说是能表示0-127共128个数值，加上最高位的符号位就成了-127-127共计255个数值，因为没有-0这个数字。但是实际对于计算机来说8bit的空间是可以表示256个数字的，那么还有一个数字是啥呢？正是：<strong>10000000</strong>(注意：这是补码，因为计算机都存的补码)。我们可以试着计算下10000000的原码，可以得到10000000的原码就是10000000，也就是-0，但是如果存在+0和-0两个计算机码对应一个值(+0和-0都是0)，那么显然是没必要的，而且还会造成混乱，所以人为的规定<strong>10000000表示-128</strong>。所以一个8bit的空间可以表示的数字就是从-128到127了，而不是-127-127！</p>
<h5 id="8-_参考文章"><strong>8. 参考文章</strong></h5><p>感谢下面这些文章帮助我理解补码：<br><a href="http://www.cnblogs.com/zhangziqiu/archive/2011/03/30/computercode.html" target="_blank" rel="external">原码, 反码, 补码 详解</a><br><a href="http://www.douban.com/note/223507364/" target="_blank" rel="external">原码、反码和补码</a></p>
<p>欢迎大家点评讨论！</p>
]]></content>
    <summary type="html">
    <![CDATA[介绍计算机中的原码、反码、补码]]>
    
    </summary>
    
      <category term="二进制" scheme="http://vickyqi.com/tags/%E4%BA%8C%E8%BF%9B%E5%88%B6/"/>
    
      <category term="反码" scheme="http://vickyqi.com/tags/%E5%8F%8D%E7%A0%81/"/>
    
      <category term="补数" scheme="http://vickyqi.com/tags/%E8%A1%A5%E6%95%B0/"/>
    
      <category term="补码" scheme="http://vickyqi.com/tags/%E8%A1%A5%E7%A0%81/"/>
    
      <category term="计算机" scheme="http://vickyqi.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA/"/>
    
      <category term="计算机基础" scheme="http://vickyqi.com/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[正则学习二三事]]></title>
    <link href="http://vickyqi.com/2015/10/19/%E6%AD%A3%E5%88%99%E5%AD%A6%E4%B9%A0%E4%BA%8C%E4%B8%89%E4%BA%8B/"/>
    <id>http://vickyqi.com/2015/10/19/正则学习二三事/</id>
    <published>2015-10-19T06:19:11.000Z</published>
    <updated>2015-10-20T07:57:08.000Z</updated>
    <content type="html"><![CDATA[<p>正则一直是我一大痛点，一直都想解决这个问题，但是奈何每次看到那么多符号就发蒙，所以就一直拖下去了。直到最近总是被别人问到如何在hql中使用rlike查询符合特定规则的字段，然后各种不会，结果被鄙视的一塌糊涂，无奈，这才静下心来慢慢研究。<br>以前看正则就是一堆符号，代表各个意思，如\d表示数字，\d+表示一个或者多个连续数字，单看每个规则都可以理解，除了组合，但是实际使用时真的很难组织到一起。归根结底还是因为对这些符号的理解不够深入。所以正则还是得多写，推荐一个在线练习的网站<a href="http://regex.alf.nu/" target="_blank" rel="external">RegexGolf</a>。好了，下面写写自己学习正则的一些总结吧，希望能够帮助到别人，也帮助自己总结总结。</p>
<h4 id="正则的基础知识："><strong>正则的基础知识：</strong></h4><h5 id="字面值"><strong>字面值</strong></h5><p>正则表达式由只代表自身的字面值和代表特定含义的元字符组成。 只代表自身的字面值指的是普通的字符，如abcde，特殊含义的元字符包括：</p>
<table>
<thead>
<tr>
<th></th>
<th>字符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>\</td>
<td>反斜线字符</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\0n</td>
<td>带有八进制值 0 的字符 n (0 &lt;= n &lt;= 7)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\0nn</td>
<td>带有八进制值 0 的字符 nn (0 &lt;= n &lt;= 7)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\0mnn</td>
<td>带有八进制值 0 的字符 mnn（0 &lt;= m &lt;= 3、0 &lt;= n &lt;= 7）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\xhh</td>
<td>带有十六进制值 0x 的字符 hh</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\uhhhh</td>
<td>带有十六进制值 0x 的字符 hhhh</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\t</td>
<td>制表符 (‘\u0009’)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\n</td>
<td>新行（换行）符 (‘\u000A’)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\r</td>
<td>回车符 (‘\u000D’)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\f</td>
<td>换页符 (‘\u000C’)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\a</td>
<td>报警 (bell) 符 (‘\u0007’)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\e</td>
<td>转义符 (‘\u001B’)</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\cx</td>
<td>对应于 x 的控制符</td>
<td></td>
</tr>
</tbody>
</table>
<h5 id="字符类"><strong>字符类</strong></h5><p> 字符类是字符在方括号中的集合。表示“找到集合里任意一个字符“。例如：</p>
<table>
<thead>
<tr>
<th></th>
<th>字符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>[abc]</td>
<td>a、b 或 c（简单类）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>[^abc]</td>
<td>任何字符，除了 a、b 或 c（否定）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>[a-zA-Z]</td>
<td>a 到 z 或 A 到 Z，两头的字母包括在内（范围）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>[a-d[m-p]]</td>
<td>a 到 d 或 m 到 p：[a-dm-p]（并集）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>[a-z&amp;&amp;[def]]</td>
<td>d、e 或 f（交集）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>[a-z&amp;&amp;[^bc]]</td>
<td>a 到 z，除了 b 和 c：[ad-z]（减去）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>[a-z&amp;&amp;[^m-p]]</td>
<td>a 到 z，而非 m 到 p：[a-lq-z]（减去）</td>
<td></td>
</tr>
</tbody>
</table>
<p>从上表可以看出<strong>[]</strong>里面可进行并集/交集/差集操作。对于字符范围是根据ASCII值的大小来的，例如[A-z]也是可以的，甚至能够匹配[，但是完全不建议如此使用，推荐使用的字符范围：[0-9]/[a-z]/[A-Z]。<br>字符类还有一些预定义的字符类：</p>
<table>
<thead>
<tr>
<th></th>
<th>字符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>. 任何字符（与行结束符可能匹配也可能不匹配）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\d</td>
<td>数字：[0-9]</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\D</td>
<td>非数字： [^0-9]</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\s</td>
<td>空白字符：[ \t\n\x0B\f\r]</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\S</td>
<td>非空白字符：[^\s]</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\w</td>
<td>单词字符：[a-zA-Z_0-9]</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\W</td>
<td>非单词字符：[^\w]</td>
<td></td>
</tr>
</tbody>
</table>
<p>使用上面的预定义字符类能够更加方便的表示字符范围。需要牢记。<br><strong>注意</strong>： 区间是字符的区间，不是数字的区间。正则表达式[1-31]表示“找到一个1或一个2或一个3”，不是“找到一个从1到31的整数”。</p>
<h5 id="乘法器"><strong>乘法器</strong></h5><table>
<thead>
<tr>
<th></th>
<th>字符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>X?</td>
<td>X，一次或一次也没有</td>
<td></td>
</tr>
<tr>
<td></td>
<td>X*</td>
<td>X，零次或多次</td>
<td></td>
</tr>
<tr>
<td></td>
<td>X+</td>
<td>X，一次或多次</td>
<td></td>
</tr>
<tr>
<td></td>
<td>X{n}</td>
<td>X，恰好 n 次</td>
<td></td>
</tr>
<tr>
<td></td>
<td>X{n,}</td>
<td>X，至少 n 次</td>
<td></td>
</tr>
<tr>
<td></td>
<td>X{n,m}</td>
<td>X，至少 n 次，但是不超过 m 次</td>
<td></td>
</tr>
</tbody>
</table>
<p>X可以使一个普通字面值，如a+：一个或多个a，也可以是一个字符类，如[abc]{2}，表示a/b/c后跟a/b/c。<br>值得注意的是优先选择更长的匹配，因为乘法器是贪婪的。如果你输入的文本是I had an aaaaawful day，该正则表达式就会在aaaaawful中匹配到aaaaa。不会在第三个a后就停止匹配。<br>乘法器是贪婪的，但它不会忽略一个更好的匹配。如果你的输入文本为I had an aaawful daaaaay，之后这个正则表达式会在第一次的匹配中于aaawful找到aaa。只有在你说“给我找到另一个匹配”的时候，它才会继续搜索然后在daaaaay中找到aaaaa。<br>惰性：<br>正则表达式<em>“.</em>“<em>表示“找到一个双引号，接着找到尽可能多的字符，最后再找到一个双引号”。注意一下被.</em>匹配的内部字符，很可能包含多个双引号。这通常不是非常有用。乘法器可通过追加问号<strong>（?）</strong>来实现<strong>惰性</strong>。<em>“.</em>?”*表示“匹配一个双引号，跟着一个尽可能少的字符，再跟着一个双引号”。</p>
<h5 id="分支"><strong>分支</strong></h5><p>可以使用管道符号来实现匹配多种选择。</p>
<table>
<thead>
<tr>
<th></th>
<th>字符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>X!Y(用!代替竖线)</td>
<td>X或者Y</td>
<td></td>
</tr>
</tbody>
</table>
<h5 id="组合"><strong>组合</strong></h5><p>可以使用圆括号来组合表达式。例：<br>在一周中找到一天，使用<strong>(Mon|Tues|Wednes|Thurs|Fri|Satur|Sun)day</strong>，这里如果把小括号或者中括号，结果是完全不一样的，因为中括号是字符类，即里面的Mon并不是完全匹配Mon，而是只要匹配M/o/n其中一个即可。<br>同时组合后面还可跟上乘法器，如：<strong>\w+(\s+\w+)*</strong>代表“找到一个或多个单词，它们以空格隔开”。</p>
<h5 id="边界"><strong>边界</strong></h5><p>边界分成：单词边界，行边界，文本边界</p>
<ol>
<li>单词边界<br>单词边界是一个单词字符和非单词字符之间的位置。记住，一个单词字符是\w，它是[0-9A-Za-z<em>]，一个非单词字符是\W，也就是[^0-9A-Za-z</em>]。<br>文本的开头和结尾总是当作单词边界。<br>输入的文本<strong>it’s a cat</strong>有八个单词边界，分别为：文本开头-i，t-‘，’-s，s-空格，空格-a，a-空格，空格-c，t-文本结尾。</li>
<li>行边界<br>每一块文本会分解成一个或多个行，用换行符分隔。<br>注意文本不是以换行符结束，而是以行结束。然而，任何行，包括最后一行，可以包含零个字符。<br>起始行位置是在一个换行符和下一行的第一个字符之间。与单词边界一样，在文本的开头也算作一个起始的行。结束行位置是在行的最后一个字符和换行符之间。与单词边界一样，文本结束也算作行结束。</li>
<li>文本边界<br>很多实现提供一个标记，通过改变它来改变^和$的含义。从“行开始”和“行结束”变成“文本开始”和“文本结束”。其它的一些实现提供单独的元字符\A和\z来达到这个目的。<br>一些表示边界的符号：</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>字符</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>^</td>
<td>行的开头</td>
<td></td>
</tr>
<tr>
<td></td>
<td>$</td>
<td>行的结尾</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\b</td>
<td>单词边界</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\B</td>
<td>非单词边界</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\A</td>
<td>输入的开头</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\G</td>
<td>上一个匹配的结尾</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\Z</td>
<td>输入的结尾，仅用于最后的结束符（如果有的话）</td>
<td></td>
</tr>
<tr>
<td></td>
<td>\z</td>
<td>输入的结尾</td>
<td></td>
</tr>
</tbody>
</table>
<p>其中^$是最常用的两个边界分隔符。</p>
<h4 id="捕获和替换："><strong>捕获和替换：</strong></h4><ol>
<li><p>捕获组</p>
<p>()在正则中被用来表示组，同时也可以用来捕获匹配上的子串，可以拥有多个捕获组，它们甚至可以嵌套使用，捕获组从左到右进行编号，只要计算左圆括号。例如：<br>对于表达式：<strong>(\w+) had a ((\w+) \w+)</strong>，文本是I had a nice day，那么</p>
<ul>
<li>捕获组1是I。</li>
<li>捕获组2是nice day。</li>
<li>捕获组3是nice。</li>
<li>捕获组0是I had a nice day（根据具体实现不同）</li>
</ul>
<p>如果表达式使用了两个捕获组，但是只捕获到一组，那么组2是空字符串。引用捕获组使用+组序号，如\1表示引用第一个捕获组。</p>
</li>
<li>后向引用<br>可以在同样的表达式中引用同一个捕获组，这称为后向引用。<br>例：表达式[abc]{2}表示“匹配aa或ab或ac or ba或bb或bc或ca或cb或cc”，但是表达式([abc])\1表示“匹配aa或bb或cc”。</li>
</ol>
<p>以上就是正则的全部知识，其实了解正则的知识点很简单，但是真要应用到实际中还是需要通过大量的练习才能做到熟练使用。</p>
<h5 id="实际案例"><strong>实际案例</strong></h5><ol>
<li><p>压缩CSS文件，去掉CSS文件中的换行以及空格</p>
<figure class="highlight livescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">工具：Notepad++  查找：([&#123;;])<span class="string">\s+</span>  替换：<span class="string">\1</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>替换文件中连续出现的#，为其后面添加一个空格，例：####你好-&gt;#### 你好</p>
 <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">工具：Notepad++  查找：([<span class="preprocessor">#]+)  替换：\<span class="number">1</span> (<span class="number">1</span>后面有个空格)</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>以上案例会不断更新，已记录一些自己对正则使用的经历。</p>
<h4 id="参考文章"><strong>参考文章</strong></h4><p><a href="http://doslin.com/regular%20expressions/2014/03/11/learn-regular-expressions-in-about-55-minutes.html" target="_blank" rel="external">55分钟学会正则表达式(译)</a></p>
<p>JDK API文档</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>正则一直是我一大痛点，一直都想解决这个问题，但是奈何每次看到那么多符号就发蒙，所以就一直拖下去了。直到最近总是被别人问到如何在hql中使用rlike查询符合特定规则的字段，然后各种不会，结果被鄙视的一塌糊涂，无奈，这才静下心来慢慢研究。<br>以前看正则就是一堆符号，代表各]]>
    </summary>
    
      <category term="正则" scheme="http://vickyqi.com/tags/%E6%AD%A3%E5%88%99/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[FairScheduler的任务调度机制——assignTasks（续）]]></title>
    <link href="http://vickyqi.com/2013/12/15/FairScheduler%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94assignTasks%EF%BC%88%E7%BB%AD%EF%BC%89/"/>
    <id>http://vickyqi.com/2013/12/15/FairScheduler的任务调度机制——assignTasks（续）/</id>
    <published>2013-12-15T12:49:00.000Z</published>
    <updated>2015-10-31T07:15:36.000Z</updated>
    <content type="html"><![CDATA[<p><a href="http://vickyqi.com/2013/12/11/FairScheduler%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94assignTasks/">上一篇文章浅析了FairScheduler的assignTasks()方法</a>，介绍了FairScheduler任务调度的原理。略过了最后一步通过JobScheduler获取Task时调用JobInProgress的五个方法：<strong>obtainNewNodeLocalMapTask()，obtainNewNodeOrRackLocalMapTask()，obtainNewMapTask()，obtainNewReduceTask()</strong>。这篇文章将对这四个方法进行简单的源代码解析。<strong>obtainNewNodeLocalMapTask()，obtainNewNodeOrRackLocalMapTask()，obtainNewMapTask()</strong>这三个方法都是选择一个Map任务，其内部调用的方法也是一样的，都是obtainNewMapTaskCommon()方法，不同的只是maxCacheLevel参数值不同：</p>
<pre>
obtainNewNodeLocalMapTask()：maxCacheLevel==1；
obtainNewNodeOrRackLocalMapTask：maxCacheLevel==maxLevel；
obtainNewMapTask：maxCacheLevel==anyCacheLevel（maxLevel+1）。
</pre>

<p>下面着重分析obtainNewMapTaskCommon()方法。</p>
<h4 id="JobInProgress-obtainNewMapTaskCommon()："><strong>JobInProgress.obtainNewMapTaskCommon()：</strong></h4><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">public synchronized <span class="type">Task</span> obtainNewMapTaskCommon(</span><br><span class="line">      <span class="type">TaskTrackerStatus</span> tts, <span class="type">int</span> clusterSize, <span class="type">int</span> numUniqueHosts, </span><br><span class="line">      <span class="type">int</span> maxCacheLevel) throws <span class="type">IOException</span> &#123;</span><br><span class="line">    <span class="keyword">if</span> (!tasksInited) &#123;</span><br><span class="line">      <span class="type">LOG</span>.info(<span class="string">"Cannot create task split for "</span> + profile.getJobID());</span><br><span class="line">      <span class="keyword">try</span> &#123; throw new <span class="type">IOException</span>(<span class="string">"state = "</span> + status.getRunState()); &#125;</span><br><span class="line">      catch (<span class="type">IOException</span> ioe) &#123;ioe.printStackTrace();&#125;</span><br><span class="line">      <span class="keyword">return</span> null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> target = findNewMapTask(tts, clusterSize, numUniqueHosts, maxCacheLevel, </span><br><span class="line">                                status.mapProgress());</span><br><span class="line">    <span class="keyword">if</span> (target == -<span class="number">1</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">Task</span> <span class="literal">result</span> = maps[target].getTaskToRun(tts.getTrackerName());</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">result</span> != null) &#123;</span><br><span class="line">      addRunningTaskToTIP(maps[target], <span class="literal">result</span>.getTaskID(), tts, <span class="literal">true</span>);</span><br><span class="line">      // <span class="type">DO</span> <span class="type">NOT</span> reset <span class="keyword">for</span> off-switch!</span><br><span class="line">      <span class="keyword">if</span> (maxCacheLevel != <span class="type">NON_LOCAL_CACHE_LEVEL</span>) &#123;</span><br><span class="line">        resetSchedulingOpportunities();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">result</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>首先判断Job是否初始化，即tasksInited是否为true，未初始化则不调度任务。接着调用findNewMapTask()方法获取一个新的Map任务，同时将maxCacheLevel参数传递过去，该参数的作用是选择不同LocalLevel的Map任务。下面看看findNewMapTask()方法。</p>
<h4 id="JobInProgress-findNewMapTask()："><strong>JobInProgress.findNewMapTask()：</strong></h4><p>首先介绍下该方法的返回值，该方法不是直接返回一个MapTask，而是返回一个maps[]数组的索引值，这个maps[]数组在Job初始化时创建，存放该Job所有的Map任务，根据索引值就可以知道对应的MapTask。<br><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (numMapTasks == <span class="number">0</span>) &#123;</span><br><span class="line">      <span class="keyword">if</span>(<span class="built_in">LOG</span>.isDebugEnabled()) &#123;</span><br><span class="line">        <span class="built_in">LOG</span>.debug(<span class="string">"No maps to schedule for "</span> + profile.getJobID())<span class="comment">;</span></span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> -<span class="number">1</span><span class="comment">;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>首先判断该Job的Map任务数是否为0，numMapTasks是在Job进行初始化（initTasks()方法）时根据输入文件的分片数确定的，即一个Split对应一个Map任务。该值为0表示该Job没有Map任务，所以返回-1，即没有满足条件的Map任务。<br><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">String</span> taskTracker = tts.getTrackerName();</span><br><span class="line">    TaskInProgress tip = <span class="keyword">null</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Update the last-known clusterSize</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="keyword">this</span>.clusterSize = clusterSize;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!shouldRunOnTaskTracker(taskTracker)) &#123;</span><br><span class="line">      <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>判断是否能够在该TT上运行任务，主要根据该Job在该TT上是否有过失败的任务来判断。下面看看该方法。</p>
<h4 id="JobInProgress-shouldRunOnTaskTracker()："><strong>JobInProgress.shouldRunOnTaskTracker()：</strong></h4><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="built_in">boolean</span> shouldRunOnTaskTracker(<span class="built_in">String</span> taskTracker) &#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// Check if too many tasks of this job have failed on this</span></span><br><span class="line">    <span class="comment">// tasktracker prior to assigning it a new one.</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    int taskTrackerFailedTasks = getTrackerTaskFailures(taskTracker);</span><br><span class="line">    <span class="keyword">if</span> ((flakyTaskTrackers &lt; (clusterSize * CLUSTER_BLACKLIST_PERCENT)) <span class="subst">&amp;&amp;</span> </span><br><span class="line">        taskTrackerFailedTasks &gt;= maxTaskFailuresPerTracker) &#123;</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">LOG</span><span class="built_in">.</span>isDebugEnabled()) &#123;</span><br><span class="line">        <span class="built_in">String</span> flakyTracker = convertTrackerNameToHostName(taskTracker); </span><br><span class="line">        <span class="keyword">LOG</span><span class="built_in">.</span>debug(<span class="string">"Ignoring the black-listed tasktracker: '"</span> + flakyTracker </span><br><span class="line">                  + <span class="string">"' for assigning a new task"</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">private</span> int getTrackerTaskFailures(<span class="built_in">String</span> trackerName) &#123;</span><br><span class="line">    <span class="built_in">String</span> trackerHostName = convertTrackerNameToHostName(trackerName);</span><br><span class="line">    <span class="built_in">Integer</span> failedTasks = trackerToFailuresMap<span class="built_in">.</span>get(trackerHostName);</span><br><span class="line">    <span class="keyword">return</span> (failedTasks != <span class="built_in">null</span>) ? failedTasks<span class="built_in">.</span>intValue() : <span class="number">0</span>; </span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>该方法从Job中保存的trackerToFailuresMap队列中获取该TT上所有的失败任务数。提一下，trackerToFailuresMap队列信息也是在TT通过心跳向JT时更新的，即updateTaskStatus()方法。flakyTaskTrackers值记录该Job在多少个TT上面失败的任务数大于maxTaskFailuresPerTracker（即一个Job在一个TT上可允许失败的最大数），当一个Job在一个TT上拥有的失败任务数大于maxTaskFailuresPerTracker时则表示该Job不可再在该TT上执行任何任务，但是当一个Job在超过（clusterSize * CLUSTER_BLACKLIST_PERCENT）个TT上失败的话，则不去考虑该Job是否在该TT上失败，因为可能是Job自身的问题，而非单个TT的问题。总之该方法根据Job的失败任务信息来判断是否应该在一个TT上执行任务。<br>接着返回到JobInProgress.findNewMapTask()方法。</p>
<h4 id="JobInProgress-findNewMapTask()：-1"><strong>JobInProgress.findNewMapTask()：</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Check to ensure this TaskTracker has enough resources to </span></span><br><span class="line">    <span class="comment">// run tasks from this job</span></span><br><span class="line">    <span class="keyword">long</span> outSize = resourceEstimator.getEstimatedMapOutputSize();</span><br><span class="line">    <span class="keyword">long</span> availSpace = tts.getResourceStatus().getAvailableSpace();</span><br><span class="line">    <span class="keyword">if</span>(availSpace &lt; outSize) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"No room for map task. Node "</span> + tts.getHost() + </span><br><span class="line">               <span class="string">" has "</span> + availSpace + </span><br><span class="line">               <span class="string">" bytes free; but we expect map to take "</span> + outSize);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> -<span class="number">1</span>; <span class="comment">//see if a different TIP might work better. </span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>判断该TT是否有够该Job的Map任务使用的资源，主要是根据该Job已完成的Map任务的输出情况来估算一个Map任务可能的输出大小。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">long</span> <span class="title">getEstimatedMapOutputSize</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> estimate = <span class="number">0L</span>;</span><br><span class="line">    <span class="keyword">if</span> (job.desiredMaps() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">      estimate = getEstimatedTotalMapOutputSize()  / job.desiredMaps();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> estimate;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="function"><span class="keyword">protected</span> synchronized <span class="keyword">long</span> <span class="title">getEstimatedTotalMapOutputSize</span><span class="params">()</span>  </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(completedMapsUpdates &lt; threshholdToUse) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">long</span> inputSize = job.getInputLength() + job.desiredMaps(); </span><br><span class="line">      <span class="comment">//add desiredMaps() so that randomwriter case doesn't blow up</span></span><br><span class="line">      <span class="comment">//the multiplication might lead to overflow, casting it with</span></span><br><span class="line">      <span class="comment">//double prevents it</span></span><br><span class="line">      <span class="keyword">long</span> estimate = Math.round(((<span class="keyword">double</span>)inputSize * </span><br><span class="line">          completedMapsOutputSize * <span class="number">2.0</span>)/completedMapsInputSize);</span><br><span class="line">      <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">        LOG.debug(<span class="string">"estimate total map output will be "</span> + estimate);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> estimate;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>具体估算方法是根据（该Job的输入大小/已完成的Map任务的输入大小）<em>（该Job已完成的所有Map任务的总输出大小）</em>2估算出该Job全部Map任务大概的输出大小，然后除以该Job的Map数量即一个Map任务的可能输出大小（至于这些值的跟新基本都是通过心跳通信）。如果TT上可使用的资源小于该Job一个Map任务可能的输出大小则不能在该TT上执行Map任务。</p>
<h4 id="JobInProgress-findNewMapTask()：-2"><strong>JobInProgress.findNewMapTask()：</strong></h4><p>接下来就是该方法的关键部分，首先看下作者们对该部分的一个注释：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">// When scheduling a map task:</span><br><span class="line">    //  0) Schedule a failed task without considering locality</span><br><span class="line">    //  1) Schedule non-running tasks</span><br><span class="line">    //  2) Schedule speculative tasks</span><br><span class="line">    //  3) Schedule tasks with no location information</span><br><span class="line"></span><br><span class="line">    // First a look up is done on the non-running <span class="operator"><span class="keyword">cache</span> <span class="keyword">and</span> <span class="keyword">on</span> a miss, a look </span><br><span class="line">    // up <span class="keyword">is</span> done <span class="keyword">on</span> the running <span class="keyword">cache</span>. The <span class="keyword">order</span> <span class="keyword">for</span> lookup <span class="keyword">within</span> the <span class="keyword">cache</span>:</span><br><span class="line">    //   <span class="number">1.</span> <span class="keyword">from</span> <span class="keyword">local</span> node <span class="keyword">to</span> root [bottom up]</span><br><span class="line">    //   <span class="number">2.</span> breadth wise <span class="keyword">for</span> all the <span class="keyword">parent</span> nodes <span class="keyword">at</span> <span class="keyword">max</span> <span class="keyword">level</span></span><br><span class="line">    // We fall <span class="keyword">to</span> linear <span class="keyword">scan</span> <span class="keyword">of</span> the <span class="keyword">list</span> ((<span class="number">3</span>) above) <span class="keyword">if</span> we have misses <span class="keyword">in</span> the </span><br><span class="line">    // above caches</span></span><br></pre></td></tr></table></figure></p>
<p>第一部分主要是说明选择任务的顺序：失败的Task（不去考虑本地性），未运行的任务，推测执行的任务，输入文件没有对应的Location信息的任务。第二部分是说明在选择每个任务时对集群上所有节点的遍历方式：自下往上一次遍历以及从根节点横向遍历。<br>下面来看第一中选择方式：从失败的任务中选择。<br> <figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 0) Schedule the task with the most failures, unless failure was on this</span></span><br><span class="line">   <span class="comment">//    machine</span></span><br><span class="line">   tip = findTaskFromList(failedMaps, tts, numUniqueHosts, <span class="keyword">false</span>);</span><br><span class="line">   <span class="keyword">if</span> (tip != <span class="keyword">null</span>) &#123;</span><br><span class="line">     <span class="comment">// Add to the running list</span></span><br><span class="line">     scheduleMap(tip);</span><br><span class="line">     LOG.info(<span class="string">"Choosing a failed task "</span> + tip.getTIPId());</span><br><span class="line">     <span class="function"><span class="keyword">return</span> tip.<span class="title">getIdWithinJob</span><span class="params">()</span></span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p>
<p>failedMaps中存放着所有的失败任务信息，直接调用findTaskFromList()方法从failedMaps中选择一个任务。下面三种方式也都是调用该方法，不同的只是传入的List不同，所以看下findTaskFromList()方法。</p>
<h4 id="JobInProgress-findTaskFromList()："><strong>JobInProgress.findTaskFromList()：</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">synchronized</span> <span class="function">TaskInProgress <span class="title">findTaskFromList</span><span class="params">(</span><br><span class="line">      Collection&lt;TaskInProgress&gt; tips, TaskTrackerStatus ttStatus,</span><br><span class="line">      <span class="keyword">int</span> numUniqueHosts,</span><br><span class="line">      <span class="keyword">boolean</span> removeFailedTip)</span> </span>&#123;</span><br><span class="line">    Iterator&lt;TaskInProgress&gt; iter = tips.iterator();</span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">      TaskInProgress tip = iter.next();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Select a tip if</span></span><br><span class="line">      <span class="comment">//   1. runnable   : still needs to be run and is not completed</span></span><br><span class="line">      <span class="comment">//   2. ~running   : no other node is running it</span></span><br><span class="line">      <span class="comment">//   3. earlier attempt failed : has not failed on this host</span></span><br><span class="line">      <span class="comment">//                               and has failed on all the other hosts</span></span><br><span class="line">      <span class="comment">// A TIP is removed from the list if </span></span><br><span class="line">      <span class="comment">// (1) this tip is scheduled</span></span><br><span class="line">      <span class="comment">// (2) if the passed list is a level 0 (host) cache</span></span><br><span class="line">      <span class="comment">// (3) when the TIP is non-schedulable (running, killed, complete)</span></span><br><span class="line">      <span class="keyword">if</span> (tip.isRunnable() &amp;&amp; !tip.isRunning()) &#123;</span><br><span class="line">        <span class="comment">// check if the tip has failed on this host</span></span><br><span class="line">        <span class="keyword">if</span> (!tip.hasFailedOnMachine(ttStatus.getHost()) || </span><br><span class="line">             tip.getNumberOfFailedMachines() &gt;= numUniqueHosts) &#123;</span><br><span class="line">          <span class="comment">// check if the tip has failed on all the nodes</span></span><br><span class="line">          iter.remove();</span><br><span class="line">          <span class="keyword">return</span> tip;</span><br><span class="line">        &#125; <span class="function"><span class="keyword">else</span> <span class="title">if</span> <span class="params">(removeFailedTip)</span> </span>&#123; </span><br><span class="line">          <span class="comment">// the case where we want to remove a failed tip from the host cache</span></span><br><span class="line">          <span class="comment">// point#3 in the TIP removal logic above</span></span><br><span class="line">          iter.remove();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="comment">// see point#3 in the comment above for TIP removal logic</span></span><br><span class="line">        iter.remove();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>该方法的作用是从一个TaskInProgress列表中选择一个适合在TT上执行的Task》从代码中的注释可以看出选择的前提是Task是可运行的（!failed &amp;&amp; (completes == 0)，即未失败也未完成），且非正在运行中（no other node is running it），且该Task没有在该TT所在的HOST上有过失败任务（一个Task会存在多个TaskAttempt任务，TaskAttempt听名字就可以知道是一个Task的多次尝试执行，失败了就再来一次，再失败再来，直到超出一个限度才会标志这个Task失败），或者该Task的失败次数大于等于集群中所有的HOST数量（表示该Task在所有HOST都失败过），满足上面三个条件的Task即可返回。后面就是判断是否将该Task从队列中移除，注释给出了三种会移除的情况：该Task已被调度，即被选中；选择的Task的本地化等级是NODE；该Task处于不可运行状态（运行中，或者完成，或者被kill掉了）。了解了该方法的原理则后面的内容就简单了。下面回到JobInProgress.findNewMapTask()方法。</p>
<h4 id="JobInProgress-findNewMapTask()：-3"><strong>JobInProgress.findNewMapTask()：</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tip = findTaskFromList(failedMaps, tts, numUniqueHosts, <span class="keyword">false</span>);</span><br><span class="line">    <span class="keyword">if</span> (tip != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// Add to the running list</span></span><br><span class="line">      scheduleMap(tip);</span><br><span class="line">      LOG.info(<span class="string">"Choosing a failed task "</span> + tip.getTIPId());</span><br><span class="line">      <span class="function"><span class="keyword">return</span> tip.<span class="title">getIdWithinJob</span><span class="params">()</span></span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>依旧看这段代码，当findTaskFromList()方法成功返回一个Task后，需要将该Task添加到运行中的队列去，<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> scheduleMap(TaskInProgress tip) &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (runningMapCache == <span class="keyword">null</span>) &#123;</span><br><span class="line">      LOG.warn(<span class="string">"Running cache for maps is missing!! "</span> </span><br><span class="line">               + <span class="string">"Job details are missing."</span>);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">String</span>[] splitLocations = tip.getSplitLocations();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Add the TIP to the list of non-local running TIPs</span></span><br><span class="line">    <span class="keyword">if</span> (splitLocations == <span class="keyword">null</span> || splitLocations.length == <span class="number">0</span>) &#123;</span><br><span class="line">      nonLocalRunningMaps.<span class="built_in">add</span>(tip);</span><br><span class="line">      <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">String</span> host: splitLocations) &#123;</span><br><span class="line">      Node node = jobtracker.getNode(host);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">for</span> (<span class="built_in">int</span> j = <span class="number">0</span>; j &lt; maxLevel; ++j) &#123;</span><br><span class="line">        Set&lt;TaskInProgress&gt; hostMaps = runningMapCache.<span class="built_in">get</span>(node);</span><br><span class="line">        <span class="keyword">if</span> (hostMaps == <span class="keyword">null</span>) &#123;</span><br><span class="line">          <span class="comment">// create a cache if needed</span></span><br><span class="line">          hostMaps = <span class="keyword">new</span> LinkedHashSet&lt;TaskInProgress&gt;();</span><br><span class="line">          runningMapCache.put(node, hostMaps);</span><br><span class="line">        &#125;</span><br><span class="line">        hostMaps.<span class="built_in">add</span>(tip);</span><br><span class="line">        node = node.getParent();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>该方法主要将被选中的Task（这里任务都是Map任务）添加到Job中保存运行中任务信息的队列中（nonLocalRunningMaps和runningMapCache），nonLocalRunningMaps保存那些输入文件没有Location信息的Task，而runningMapCache则保存输入文件存在Location的Task。runningMapCache是一个Map，key是Node，而value是一个TaskInProgress对象的集合，说明该Map保持的是一个Node–&gt;其上运行的所有Task的一个映射关系，这里的Node是拥有该Task的输入文件块的所有节点。当有一个Task需要添加到runningMapCache时不仅需要为其建立到Task的输入文件所在的所有Node到该Task的关系，而且分别为其建立输入文件所在Node的父节点到该Task的关系，循环知道遍历的深度等于maxLevel。这样做的好处是可以很方便的知道一个Node上运行的所有Task信息，包括其子节点上运行的Task。继续返回到JobInProgress.findNewMapTask()方法。<br>接下来就是简单地返回该Task在maps[]数组中的索引值。到这里第一种选择Task的方式完成了，下面看看后面几种方式。</p>
<h4 id="JobInProgress-findNewMapTask()：-4"><strong>JobInProgress.findNewMapTask()：</strong></h4><p><code>Node node = jobtracker.getNode(tts.getHost());</code><br>获取该TT所在的HOST对应的Node对象。<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. check from local node to the root [bottom up cache lookup]</span></span><br><span class="line">    <span class="comment">//    i.e if the cache is available and the host has been resolved</span></span><br><span class="line">    <span class="comment">//    (node!=null)</span></span><br><span class="line">    <span class="keyword">if</span> (node != <span class="keyword">null</span>) &#123;</span><br><span class="line">      Node <span class="variable">key</span> = node;</span><br><span class="line">      <span class="built_in">int</span> level = <span class="number">0</span>;</span><br><span class="line">      <span class="comment">// maxCacheLevel might be greater than this.maxLevel if findNewMapTask is</span></span><br><span class="line">      <span class="comment">// called to schedule any task (local, rack-local, off-switch or</span></span><br><span class="line">      <span class="comment">// speculative) tasks or it might be NON_LOCAL_CACHE_LEVEL (i.e. -1) if</span></span><br><span class="line">      <span class="comment">// findNewMapTask is (i.e. -1) if findNewMapTask is to only schedule</span></span><br><span class="line">      <span class="comment">// off-switch/speculative tasks</span></span><br><span class="line">      <span class="built_in">int</span> maxLevelToSchedule = Math.<span class="built_in">min</span>(maxCacheLevel, maxLevel);</span><br><span class="line">      <span class="keyword">for</span> (level = <span class="number">0</span>;level &lt; maxLevelToSchedule; ++level) &#123;</span><br><span class="line">        List &lt;TaskInProgress&gt; cacheForLevel = nonRunningMapCache.<span class="built_in">get</span>(<span class="variable">key</span>);</span><br><span class="line">        <span class="keyword">if</span> (cacheForLevel != <span class="keyword">null</span>) &#123;</span><br><span class="line">          tip = findTaskFromList(cacheForLevel, tts, </span><br><span class="line">              numUniqueHosts,level == <span class="number">0</span>);</span><br><span class="line">          <span class="keyword">if</span> (tip != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// Add to running cache</span></span><br><span class="line">            scheduleMap(tip);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// remove the cache if its empty</span></span><br><span class="line">            <span class="keyword">if</span> (cacheForLevel.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">              nonRunningMapCache.remove(<span class="variable">key</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="keyword">return</span> tip.getIdWithinJob();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="variable">key</span> = <span class="variable">key</span>.getParent();</span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      <span class="comment">// Check if we need to only schedule a local task (node-local/rack-local)</span></span><br><span class="line">      <span class="keyword">if</span> (level == maxCacheLevel) &#123;</span><br><span class="line">        <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>这一部分是从未运行的Map任务中选择一个可执行的Map任务。首先计算maxLevelToSchedule，该值是maxCacheLevel和maxLevel的较小的值，注释给出的解释是maxCacheLevel（调用该方法传入的参数值）可能会比该Job的maxLevel属性值大，所以选择两者之中最小的值作为选择的最大本地等级值（maxLevelToSchedule）。接下来就是自下往上寻找满足条件的Map任务，知道遍历深度达到maxLevelToSchedule。方法较简单，只是从nonRunningMapCache中选择出对应的Node上所有的未执行的Map任务集合，然后调用同上面一样的findTaskFromList()方法从TaskInProgress集合中选择一个适合在该TT上执行的Map任务，选择一个Map任务之后还是一样的步骤调用scheduleMap()方法将其添加到运行中的队列中。当循环结束之后，如果未选择出一个Map任务，则到下面判断如果level==maxCacheLevel，这里level是循环结束时的值，即level==maxLevelToSchedule，而maxLevelToSchedule==Math.min(maxCacheLevel, maxLevel)，那么如果要使level==maxCacheLevel，则maxCacheLevel必须是小于等于maxLevel，从前面三个方法内部调用obtainNewMapTaskCommon()方法时传的maxCacheLevel参数值可以看出，obtainNewNodeLocalMapTask()传的值是1，obtainNewNodeOrRackLocalMapTask()传的值是maxLevel，而obtainNewMapTask传的值是anyCacheLevel（=maxLevel+1），所以这里满足level==maxCacheLevel条件的是obtainNewNodeLocalMapTask和obtainNewNodeOrRackLocalMapTask两个方法，即选择Node级别和TackNode级别的Map任务。而对于这两个任务是不需要进行下面两种方式选择Map任务的：推测执行任务和NoLocal任务，因为这两个方式选择的任务都不满足Node级别和TackNode级别，而是Any级别的，即也就只有obtainNewMapTask()这一个方法（其实还有一个方法obtainNewNonLocalMapTask()，传的maxCacheLevel参数值是NON_LOCAL_CACHE_LEVEL，即-1，这个方法会跳过注视中的1）方式）。下面继续看如何从根节点横向选择Map任务。<br><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//2. Search breadth-wise across parents at max level for non-running </span></span><br><span class="line">    <span class="comment">//   TIP if</span></span><br><span class="line">    <span class="comment">//     - cache exists and there is a cache miss </span></span><br><span class="line">    <span class="comment">//     - node information for the tracker is missing (tracker's topology</span></span><br><span class="line">    <span class="comment">//       info not obtained yet)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// collection of node at max level in the cache structure</span></span><br><span class="line">    Collection&lt;Node&gt; nodesAtMaxLevel = jobtracker<span class="built_in">.</span>getNodesAtMaxLevel();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// get the node parent at max level</span></span><br><span class="line">    Node nodeParentAtMaxLevel = </span><br><span class="line">      (node == <span class="built_in">null</span>) ? <span class="built_in">null</span> : JobTracker<span class="built_in">.</span>getParentNode(node, maxLevel - <span class="number">1</span>);</span><br><span class="line">    </span><br><span class="line">    f<span class="subst">or</span> (Node <span class="keyword">parent</span> : nodesAtMaxLevel) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// skip the parent that has already been scanned</span></span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">parent</span> == nodeParentAtMaxLevel) &#123;</span><br><span class="line">        continue;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="built_in">List</span>&lt;TaskInProgress&gt; <span class="keyword">cache</span> = nonRunningMapCache<span class="built_in">.</span>get(<span class="keyword">parent</span>);</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">cache</span> != <span class="built_in">null</span>) &#123;</span><br><span class="line">        tip = findTaskFromList(<span class="keyword">cache</span>, tts, numUniqueHosts, <span class="literal">false</span>);</span><br><span class="line">        <span class="keyword">if</span> (tip != <span class="built_in">null</span>) &#123;</span><br><span class="line">          <span class="comment">// Add to the running cache</span></span><br><span class="line">          scheduleMap(tip);</span><br><span class="line"></span><br><span class="line">          <span class="comment">// remove the cache if empty</span></span><br><span class="line">          <span class="keyword">if</span> (<span class="keyword">cache</span><span class="built_in">.</span>size() == <span class="number">0</span>) &#123;</span><br><span class="line">            nonRunningMapCache<span class="built_in">.</span>remove(<span class="keyword">parent</span>);</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="keyword">LOG</span><span class="built_in">.</span>info(<span class="string">"Choosing a non-local task "</span> + tip<span class="built_in">.</span>getTIPId());</span><br><span class="line">          <span class="keyword">return</span> tip<span class="built_in">.</span>getIdWithinJob();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>这一种方式直接从根节点集合中选择任务，JT中nodesAtMaxLevel集合保存着所有没有父节点的Node信息，即在集群中处于最高级等的Node，下面就是直接遍历nodesAtMaxLevel中所有的节点选择满足条件的Map任务。同上一步也是从nonRunningMapCache集合中选择出对应Node上所有的未运行的Map任务，该方法基本同上一步一样，只是选择的Node不同。上一种方式是从TT所在的Node开始，自下而上选择Map任务，而此处则直接选择最高等级的Node上的Map任务。显然这一步不考虑任何的Map任务本地化因素。下面再看如何选择No-Local任务。<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3. Search non-local tips for a new task</span></span><br><span class="line">    tip = findTaskFromList(nonLocalMaps, tts, numUniqueHosts, <span class="keyword">false</span>);</span><br><span class="line">    <span class="keyword">if</span> (tip != <span class="keyword">null</span>) &#123;</span><br><span class="line">      <span class="comment">// Add to the running list</span></span><br><span class="line">      scheduleMap(tip);</span><br><span class="line"></span><br><span class="line">      LOG.info(<span class="string">"Choosing a non-local task "</span> + tip.getTIPId());</span><br><span class="line">      <span class="function"><span class="keyword">return</span> tip.<span class="title">getIdWithinJob</span><span class="params">()</span></span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>这一种方式是从nonLocalMaps中选择一个Map任务，nonLocalMaps保存的任务是那些在任务初始化时未找到输入文件所在的Location信息的任务，这些任务是无法放到nonRunningMapCache中的。<br>以上三种方式其实都是一种方式——对应注释上的1）——选择未运行的任务，只是这里分成三种不同的选择方式：1）从TT所在节点自下而上选择满足Node和RackNode本地化要求的任务，2）直接从所有最高等级的Node上选择任务，3）选择那些输入文件没有Location信息的No-Local任务。下面接着看注释中提到的第三种选择方式——选择推测执行任务。</p>
<h4 id="JobInProgress-findNewMapTask()：-5"><strong>JobInProgress.findNewMapTask()：</strong></h4><p>这一中方式同上面一种方式一样，也分为三个不同的选择方式（同上）。当然，这一中方法发生的条件是hasSpeculativeMaps==true，即该Job拥有推测执行任务，或者说可以启用推测执行任务，该参数由mapred.map.tasks.speculative.execution参数值决定，默认是true。下面分别看看三种方式。<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. Check bottom up for speculative tasks from the running cache</span></span><br><span class="line">      <span class="keyword">if</span> (node != <span class="keyword">null</span>) &#123;</span><br><span class="line">        Node <span class="variable">key</span> = node;</span><br><span class="line">        <span class="keyword">for</span> (<span class="built_in">int</span> level = <span class="number">0</span>; level &lt; maxLevel; ++level) &#123;</span><br><span class="line">          Set&lt;TaskInProgress&gt; cacheForLevel = runningMapCache.<span class="built_in">get</span>(<span class="variable">key</span>);</span><br><span class="line">          <span class="keyword">if</span> (cacheForLevel != <span class="keyword">null</span>) &#123;</span><br><span class="line">            tip = findSpeculativeTask(cacheForLevel, tts, </span><br><span class="line">                                      avgProgress, currentTime, level == <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (tip != <span class="keyword">null</span>) &#123;</span><br><span class="line">              <span class="keyword">if</span> (cacheForLevel.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">                runningMapCache.remove(<span class="variable">key</span>);</span><br><span class="line">              &#125;</span><br><span class="line">              <span class="keyword">return</span> tip.getIdWithinJob();</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="variable">key</span> = <span class="variable">key</span>.getParent();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></p>
<p>第一种方式同上一种方式一样，依然是选择本地化Map任务（推测任务），不同的是这里是从runningMapCache中选择出Node上所有正在运行中的Task集合，从中选择一个Map任务对其启动推测执行任务。下面看看findSpeculativeTask()方法。</p>
<h4 id="JobInProgress-findSpeculativeTask()："><strong>JobInProgress.findSpeculativeTask()：</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="function">TaskInProgress <span class="title">findSpeculativeTask</span><span class="params">(</span><br><span class="line">      Collection&lt;TaskInProgress&gt; list, TaskTrackerStatus ttStatus,</span><br><span class="line">      <span class="keyword">double</span> avgProgress, <span class="keyword">long</span> currentTime, <span class="keyword">boolean</span> shouldRemove)</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    Iterator&lt;TaskInProgress&gt; iter = list.iterator();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> (iter.hasNext()) &#123;</span><br><span class="line">      TaskInProgress tip = iter.next();</span><br><span class="line">      <span class="comment">// should never be true! (since we delete completed/failed tasks)</span></span><br><span class="line">      <span class="keyword">if</span> (!tip.isRunning() || !tip.isRunnable()) &#123;</span><br><span class="line">        iter.remove();</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (tip.hasSpeculativeTask(currentTime, avgProgress)) &#123;</span><br><span class="line">        <span class="comment">// Check if this tip can be removed from the list.</span></span><br><span class="line">        <span class="comment">// If the list is shared then we should not remove.</span></span><br><span class="line">        <span class="keyword">if</span>(shouldRemove)&#123;</span><br><span class="line">          iter.remove();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (!tip.hasRunOnMachine(ttStatus.getHost(),</span><br><span class="line">                               ttStatus.getTrackerName())) &#123;</span><br><span class="line">          <span class="keyword">return</span> tip;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (shouldRemove &amp;&amp; tip.hasRunOnMachine(ttStatus.getHost(),</span><br><span class="line">                                         ttStatus.getTrackerName())) &#123;</span><br><span class="line">          iter.remove();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>选择依据是!tip.isRunning() || !tip.isRunnable()，即该Task处于运行中，且未完成，才能对此启动推测执行任务。<br>这里简单介绍下推测执行任务，推测执行任务是Hadoop的一种容错机制，即如果一个Task运行的时间同其他同类的Task所需的时间长很多（且还未完成）时，则根据实际情况考虑启动一个同样的Task，这时集群中就有两个同样的任务同时运行，哪个先完成则提交哪个Task，而kill掉另外一个Task。推测执行任务虽然能够能够更好的保证一个Task在正常时间内完成，但是代价是需要消耗更多的资源。<br>下面是调用hasSpeculativeTask()方法判断该Task是否可以启动一个推测执行任务。<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">hasSpeculativeTask</span><span class="params">(<span class="keyword">long</span> currentTime, <span class="keyword">double</span> averageProgress)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">    <span class="comment">// REMIND - mjc - these constants should be examined</span></span><br><span class="line">    <span class="comment">// in more depth eventually...</span></span><br><span class="line">    <span class="comment">//</span></span><br><span class="line">      </span><br><span class="line">    <span class="keyword">if</span> (!skipping &amp;&amp; activeTasks.size() &lt;= MAX_TASK_EXECS &amp;&amp;</span><br><span class="line">        (averageProgress - progress &gt;= SPECULATIVE_GAP) &amp;&amp;</span><br><span class="line">        (currentTime - startTime &gt;= SPECULATIVE_LAG) </span><br><span class="line">        &amp;&amp; completes == <span class="number">0</span> &amp;&amp; !isOnlyCommitPending()) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>判断条件有点多，主要是：1）skipping==false，即未开启跳过模式；2）该Task正在运行的任务数是否大于MAX_TASK_EXECS（1），大于MAX_TASK_EXECS则表示已经有一个推测执行的任务在运行了；3）averageProgress（Map任务或者Reduce任务完成的进度）是否大于SPECULATIVE_GAP（20%）；4）任务运行的时间是否已超过SPECULATIVE_LAG（60*1000）；5）Task的完成数==0；6）Task是否处于等待提交状态。<br>最后调用TaskInProgress的hasRunOnMachine()方法判断该Task是否在该TT上有正在运行中的TaskAttempt，且在该TT上是否有失败过。到这里findSpeculativeTask()方法就完成了。该方法首先根据Task的运行状态判断是否满足推测执行的条件，然后根据Task的一系列属性判断是否开启推测执行，最后根据该Task在该TT是否有正在运行的TaskAttempt以及是否有过失败记录最终决定是否在该TT上运行该Task的推测执行任务。继续回到JobInProgress.findNewMapTask()。</p>
<h4 id="JobInProgress-findNewMapTask()：-6"><strong>JobInProgress.findNewMapTask()：</strong></h4><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2. Check breadth-wise for speculative tasks</span></span><br><span class="line">      </span><br><span class="line">      f<span class="subst">or</span> (Node <span class="keyword">parent</span> : nodesAtMaxLevel) &#123;</span><br><span class="line">        <span class="comment">// ignore the parent which is already scanned</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">parent</span> == nodeParentAtMaxLevel) &#123;</span><br><span class="line">          continue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">Set</span>&lt;TaskInProgress&gt; <span class="keyword">cache</span> = runningMapCache<span class="built_in">.</span>get(<span class="keyword">parent</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">cache</span> != <span class="built_in">null</span>) &#123;</span><br><span class="line">          tip = findSpeculativeTask(<span class="keyword">cache</span>, tts, avgProgress, </span><br><span class="line">                                    currentTime, <span class="literal">false</span>);</span><br><span class="line">          <span class="keyword">if</span> (tip != <span class="built_in">null</span>) &#123;</span><br><span class="line">            <span class="comment">// remove empty cache entries</span></span><br><span class="line">            <span class="keyword">if</span> (<span class="keyword">cache</span><span class="built_in">.</span>size() == <span class="number">0</span>) &#123;</span><br><span class="line">              runningMapCache<span class="built_in">.</span>remove(<span class="keyword">parent</span>);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">LOG</span><span class="built_in">.</span>info(<span class="string">"Choosing a non-local task "</span> + tip<span class="built_in">.</span>getTIPId() </span><br><span class="line">                     + <span class="string">" for speculation"</span>);</span><br><span class="line">            <span class="keyword">return</span> tip<span class="built_in">.</span>getIdWithinJob();</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">// 3. Check non-local tips for speculation</span></span><br><span class="line">      tip = findSpeculativeTask(nonLocalRunningMaps, tts, avgProgress, </span><br><span class="line">                                currentTime, <span class="literal">false</span>);</span><br><span class="line">      <span class="keyword">if</span> (tip != <span class="built_in">null</span>) &#123;</span><br><span class="line">        <span class="keyword">LOG</span><span class="built_in">.</span>info(<span class="string">"Choosing a non-local task "</span> + tip<span class="built_in">.</span>getTIPId() </span><br><span class="line">                 + <span class="string">" for speculation"</span>);</span><br><span class="line">        <span class="keyword">return</span> tip<span class="built_in">.</span>getIdWithinJob();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里的两种方式其实跟上面一样，无需过多的解释。<br>到这里findNewMapTask()就完成了，下面回到obtainNewMapTaskCommon()方法。</p>
<h4 id="JbInProgress-obtainNewMapTaskCommon()："><strong>JbInProgress.obtainNewMapTaskCommon()：</strong></h4><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> target = findNewMapTask(tts, clusterSize, numUniqueHosts, maxCacheLevel, </span><br><span class="line">                                status.mapProgress());</span><br><span class="line">    <span class="keyword">if</span> (target == -<span class="number">1</span>) &#123;</span><br><span class="line">      <span class="keyword">return</span> null;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">Task</span> <span class="literal">result</span> = maps[target].getTaskToRun(tts.getTrackerName());</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">result</span> != null) &#123;</span><br><span class="line">      addRunningTaskToTIP(maps[target], <span class="literal">result</span>.getTaskID(), tts, <span class="literal">true</span>);</span><br><span class="line">      // <span class="type">DO</span> <span class="type">NOT</span> reset <span class="keyword">for</span> off-switch!</span><br><span class="line">      <span class="keyword">if</span> (maxCacheLevel != <span class="type">NON_LOCAL_CACHE_LEVEL</span>) &#123;</span><br><span class="line">        resetSchedulingOpportunities();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">result</span>;</span><br></pre></td></tr></table></figure>
<p>当调用findNewMapTask()方法得到一个maps[]数组的索引之后，就可以从maps[]数组中获取对应的Map任务。这里调用了一个TaskInProgress的getTaskToRun()方法，为Task生成一个唯一的AttemptId，然后调用addRunningTask()方法创建一个Task对象，方法内部还是比较简单的，主要是new一个Task对象，并为其创建一个TaskStatus对象，以及初始化一些参数值。<br>如果Task！=null，则调用addRunningTaskToTIP()方法处理一些记录值，如记录Task的locality值，以及是否第一个TaskAttempt对象，等等。<br>到此obtainNewMapTaskCommon()方法就完成了，则obtainNewNodeLocalMapTask()，obtainNewNodeOrRackLocalMapTask()，obtainNewMapTask()三个方法也就都完成了。而obtainNewReduceTask()该方法基本和前面三个方法大同小异，也就不需要过多的解释，不同的只是Reduce任务不需要考虑本地性，选择相对更简单些。<br>以上就是一个Job如何选择一个Map/Reduce任务来执行的过程，总体上来看对于Map任务需要考虑Map任务的本地性，以提高执行效率。而任务的选择顺序依次是：失败的任务&gt;未运行的任务&gt;推测执行任务。而对于Map任务第二三种任务（未运行的任务&gt;推测执行任务）又分成从TT所在的Node自下而上选择、从根节点横向选择、选择No-Local任务三种不同的方式。</p>
<hr>
<p>OK，以上如有错误之处还望指出，谢谢！</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="http://vickyqi.com/2013/12/11/FairScheduler%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94assi]]>
    </summary>
    
      <category term="FairScheduler" scheme="http://vickyqi.com/tags/FairScheduler/"/>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="MapReduce" scheme="http://vickyqi.com/tags/MapReduce/"/>
    
      <category term="任务调度" scheme="http://vickyqi.com/tags/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[FairScheduler的任务调度机制——assignTasks]]></title>
    <link href="http://vickyqi.com/2013/12/11/FairScheduler%E7%9A%84%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%9C%BA%E5%88%B6%E2%80%94%E2%80%94assignTasks/"/>
    <id>http://vickyqi.com/2013/12/11/FairScheduler的任务调度机制——assignTasks/</id>
    <published>2013-12-10T16:33:00.000Z</published>
    <updated>2015-10-31T07:08:30.000Z</updated>
    <content type="html"><![CDATA[<p>首先需要了解FairScheduler是如何在各个Pool之间分配资源，以及每个Pool如何在Job之间分配资源的。FairScheduler的分配资源发生在update()方法中，而该方法由一个线程UpdateThread每隔updateInterval（由mapred.fairscheduler.update.interval参数决定，默认是500ms）就调用一次，以保证资源分配的实时性。<br>FairScheduler的资源分配算法由SchedulingAlgorithms的computeFairShares()方法实现，原理是通过二分查找选择出一个使得资源分配数最接近实际资源数的值。具体可以去阅读下<code>SchedulingAlgorithms.computeFairShares()</code>的源码（有点难理解，最好debug下）。<br>下面就来看看FairScheduler如何从众多的任务中选择出一个任务，即任务调度。</p>
<h4 id="FairScheduler-assignTasks()："><strong>FairScheduler.assignTasks()：</strong></h4><p>该方法的调用是发生在JT接收到来自TT的心跳，在返回响应时会根据TT的实际情况选择一个任务交由TT执行，具体可参考<a href="http://blog.csdn.net/vickyway/article/details/17127559" target="_blank" rel="external">Hadoop1.2.1源码解析系列：JT与TT之间的心跳通信机制——JT篇</a>。该方法为指定TT选择一组适合其执行的Task。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Compute total runnable maps and reduces, and currently running ones</span></span><br><span class="line"><span class="keyword">int</span> runnableMaps = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> runningMaps = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> runnableReduces = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> runningReduces = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">for</span> (Pool pool: poolMgr.getPools()) &#123;</span><br><span class="line">  runnableMaps += pool.getMapSchedulable().getDemand();</span><br><span class="line">  runningMaps += pool.getMapSchedulable().getRunningTasks();</span><br><span class="line">  runnableReduces += pool.getReduceSchedulable().getDemand();</span><br><span class="line">  runningReduces += pool.getReduceSchedulable().getRunningTasks();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>此处计算所有的Pool（资源池）总的runnableMaps（所有Map任务运行所需的Slot数量），runningMaps(运行中的Map任务数量)，runnableReduces（所有Reduce任务运行所需的Slot数量），runningReduces（运行中的Reduce任务数量）。<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ClusterStatus clusterStatus = taskTrackerManager.getClusterStatus();</span><br><span class="line"><span class="comment">// Compute total map/reduce slots</span></span><br><span class="line"><span class="comment">// In the future we can precompute this if the Scheduler becomes a </span></span><br><span class="line"><span class="comment">// listener of tracker join/leave events.</span></span><br><span class="line"><span class="keyword">int</span> totalMapSlots = getTotalSlots(TaskType.MAP, clusterStatus);</span><br><span class="line"><span class="keyword">int</span> totalReduceSlots = getTotalSlots(TaskType.REDUCE, clusterStatus);</span><br></pre></td></tr></table></figure></p>
<p>接着根据JT获取集群状态，获取totalMapSlots（集群中所有可运行Map的Slot数量）和totalReduceSlots(集群中所有可运行Reduce的Slot数量).<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// <span class="operator"><span class="keyword">Update</span> <span class="keyword">time</span> waited <span class="keyword">for</span> <span class="keyword">local</span> maps <span class="keyword">for</span> jobs skipped <span class="keyword">on</span> <span class="keyword">last</span> heartbeat</span><br><span class="line">updateLocalityWaitTimes(currentTime);</span></span><br></pre></td></tr></table></figure></p>
<p>次数是更新上一次TT发送心跳时没有进行更新time waited for local maps的Job进行更新time waited for local maps。</p>
<h4 id="FairScheduler-updateLocalityWaitTimes："><strong>FairScheduler.updateLocalityWaitTimes：</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span><br><span class="line"> * Update locality wait times for jobs that were skipped at last heartbeat.</span><br><span class="line"> */</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">updateLocalityWaitTimes</span><span class="params">(<span class="keyword">long</span> currentTime)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">long</span> timeSinceLastHeartbeat = </span><br><span class="line">    (lastHeartbeatTime == <span class="number">0</span> ? <span class="number">0</span> : currentTime - lastHeartbeatTime);</span><br><span class="line">  lastHeartbeatTime = currentTime;</span><br><span class="line">  <span class="keyword">for</span> (JobInfo info: infos.values()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (info.skippedAtLastHeartbeat) &#123;</span><br><span class="line">      info.timeWaitedForLocalMap += timeSinceLastHeartbeat;</span><br><span class="line">      info.skippedAtLastHeartbeat = <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>首先计算出从上次心跳到现在的时间间隔（timeSinceLastHeartbeat），并更新上次的心跳时间。然后遍历infos（存放JobInProgress–&gt;JobInfo的集合）中skippedAtLastHeartbeat==true的Job的JobInfo，将其timeWaitedForLocalMap值增加timeSinceLastHeartbeat，并将JobInfo的skippedAtLastHeartbeat设为false。回到FairScheduler。</p>
<h4 id="FairScheduler-assignTasks()：-1"><strong>FairScheduler.assignTasks()：</strong></h4><figure class="highlight autoit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// Check <span class="keyword">for</span> JT safe-mode</span><br><span class="line"> <span class="keyword">if</span> (taskTrackerManager.isInSafeMode()) &#123;</span><br><span class="line">   <span class="built_in">LOG</span>.info(<span class="string">"JobTracker is in safe-mode, not scheduling any tasks."</span>)<span class="comment">;</span></span><br><span class="line">   <span class="keyword">return</span> <span class="literal">null</span><span class="comment">;</span></span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure>
<p>检查JT是否处于SafeMode，处于SafeMode不进行任何任务的调度。<br><figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">TaskTrackerStatus tts = tracker.getStatus();</span><br><span class="line"></span><br><span class="line">int mapsAssigned = <span class="number">0</span>; // <span class="keyword">loop</span> counter <span class="keyword">for</span> <span class="keyword">map</span> <span class="keyword">in</span> the below <span class="keyword">while</span> <span class="keyword">loop</span></span><br><span class="line">int reducesAssigned = <span class="number">0</span>; // <span class="keyword">loop</span> counter <span class="keyword">for</span> reduce <span class="keyword">in</span> the below <span class="keyword">while</span></span><br><span class="line">int mapCapacity = maxTasksToAssign(TaskType.<span class="keyword">MAP</span>, tts);</span><br><span class="line">int reduceCapacity = maxTasksToAssign(TaskType.REDUCE, tts);</span><br><span class="line"><span class="typename">boolean</span> mapRejected = false; // flag used <span class="keyword">for</span> ending the <span class="keyword">loop</span></span><br><span class="line"><span class="typename">boolean</span> reduceRejected = false; // flag used <span class="keyword">for</span> ending the <span class="keyword">loop</span></span><br><span class="line"></span><br><span class="line">// Keep track <span class="keyword">of</span> which jobs were visited <span class="keyword">for</span> <span class="keyword">map</span> tasks <span class="keyword">and</span> which had tasks</span><br><span class="line">// launched, so that we can later mark skipped jobs <span class="keyword">for</span> delay scheduling</span><br><span class="line">Set&lt;JobInProgress&gt; visitedForMap = <span class="keyword">new</span> HashSet&lt;JobInProgress&gt;();</span><br><span class="line">Set&lt;JobInProgress&gt; visitedForReduce = <span class="keyword">new</span> HashSet&lt;JobInProgress&gt;();</span><br><span class="line">Set&lt;JobInProgress&gt; launchedMap = <span class="keyword">new</span> HashSet&lt;JobInProgress&gt;();</span><br><span class="line"></span><br><span class="line">ArrayList&lt;Task&gt; tasks = <span class="keyword">new</span> ArrayList&lt;Task&gt;();</span><br></pre></td></tr></table></figure></p>
<p>这段代码是初始化一些在调度任务时需要用到的变量，mapsAssigned和reducesAssigned记录已选择的Map/Reduce任务数量，mapCapacity和reduceCapacity记录该TT最大可接收到Map/Reduce任务数量，mapRejected和reduceRejected用来标识是否还可继续接收Map/Reduce任务，visitedForMap和visitedForReduce队列用来记录为寻找可执行的Task而访问的Job，launchedMap队列用来记录选择的Map任务，tasks队列用来存放选择的任务。下面看看maxTasksToAssign()方法是如何计算TT最大可接收的Map/Reduce数量的。</p>
<h4 id="FairScheduler-maxTasksToAssign："><strong>FairScheduler.maxTasksToAssign：</strong></h4><figure class="highlight go"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">protected <span class="typename">int</span> maxTasksToAssign(TaskType <span class="keyword">type</span>, TaskTrackerStatus tts) &#123;</span><br><span class="line">  <span class="keyword">if</span> (!assignMultiple)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">  <span class="typename">int</span> <span class="built_in">cap</span> = (<span class="keyword">type</span> == TaskType.MAP) ? mapAssignCap : reduceAssignCap;</span><br><span class="line">  <span class="typename">int</span> availableSlots = (<span class="keyword">type</span> == TaskType.MAP) ?</span><br><span class="line">      tts.getAvailableMapSlots(): tts.getAvailableReduceSlots();</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">cap</span> == -<span class="number">1</span>) <span class="comment">// Infinite cap; use the TaskTracker's slot count</span></span><br><span class="line">    <span class="keyword">return</span> availableSlots;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> Math.min(<span class="built_in">cap</span>, availableSlots);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此处的assignMultiple变量是由mapred.fairscheduler.assignmultiple参数决定，默认是true，表示是否可同时调度Map和Reduce任务。mapAssignCap和reduceAssignCap变量分别是由mapred.fairscheduler.assignmultiple.maps参数和mapred.fairscheduler.assignmultiple.reduces参数决定，默认值都是-1，表示一次心跳最大可调度的Map/Reduce数量，-1表示无限制。availableSlots表示该TT在发送心跳时可使用的Map/Reduce slot数量，所以接收的任务不能超过该值。</p>
<h4 id="FairScheduler-assignTasks()：-2"><strong>FairScheduler.assignTasks()：</strong></h4><p>下面的代码是一段无限循环，知道满足一定条件才退出，分段来看看循环内部。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (!mapRejected) &#123;</span><br><span class="line">        <span class="keyword">if</span> (mapsAssigned == mapCapacity ||</span><br><span class="line">            runningMaps == runnableMaps ||</span><br><span class="line">            !loadMgr.canAssignMap(tts, runnableMaps,</span><br><span class="line">                totalMapSlots, mapsAssigned)) &#123;</span><br><span class="line">          eventLog.<span class="built_in">log</span>(<span class="string">"INFO"</span>, <span class="string">"Can't assign another MAP to "</span> + trackerName);</span><br><span class="line">          mapRejected = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!reduceRejected) &#123;</span><br><span class="line">        <span class="keyword">if</span> (reducesAssigned == reduceCapacity ||</span><br><span class="line">            runningReduces == runnableReduces ||</span><br><span class="line">            !loadMgr.canAssignReduce(tts, runnableReduces,</span><br><span class="line">                totalReduceSlots, reducesAssigned)) &#123;</span><br><span class="line">          eventLog.<span class="built_in">log</span>(<span class="string">"INFO"</span>, <span class="string">"Can't assign another REDUCE to "</span> + trackerName);</span><br><span class="line">          reduceRejected = <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (mapRejected &amp;&amp; reduceRejected ||</span><br><span class="line">          !assignMultiple &amp;&amp; tasks.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">break</span>; <span class="comment">// This is the only exit of the while (true) loop</span></span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></p>
<p>这一段主要是判断是否退出循环，即通过跟新mapRejected和reduceRejected值来决定是否退出循环。当mapsAssigned==mapCapacity，即已选择的Map数量已达到TT可接收的最大值时，或者runningMaps==runnableMaps，即所有的Map任务都已运行，或者<code>loadMgr.canAssignReduce(tts, runnableReduces,totalReduceSlots, reducesAssigned)</code>返回false，即LoadManager（实现类是CapBasedLoadManager）任务不可再继续调度Map任务。Reduce同上。下面看看LoadManager如何判断是否可以继续调度Map/Reduce任务。</p>
<h4 id="CapBasedLoadManager-LoadManager()："><strong>CapBasedLoadManager.LoadManager()：</strong></h4><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> boolean <span class="title">canAssignMap</span><span class="params">(TaskTrackerStatus tracker,</span><br><span class="line">    <span class="keyword">int</span> totalRunnableMaps, <span class="keyword">int</span> totalMapSlots, <span class="keyword">int</span> alreadyAssigned)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">int</span> cap = getCap(totalRunnableMaps, tracker.getMaxMapSlots(), totalMapSlots);</span><br><span class="line">  <span class="keyword">return</span> tracker.countMapTasks() + alreadyAssigned &lt; cap;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">getCap</span><span class="params">(<span class="keyword">int</span> totalRunnableTasks, <span class="keyword">int</span> localMaxTasks, <span class="keyword">int</span> totalSlots)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">double</span> load = maxDiff + ((<span class="keyword">double</span>)totalRunnableTasks) / totalSlots;</span><br><span class="line">  <span class="keyword">return</span> (<span class="keyword">int</span>) Math.<span class="built_in">ceil</span>(localMaxTasks * Math.min(<span class="number">1.0</span>, load));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>maxDiff值由mapred.fairscheduler.load.max.diff参数决定，默认是0.0f。该方法根据集群总的任务运行数与集群总的Slot数量的比例，来判断一个TT应该运行多个任务，据此决定是否继续向TT发送任务。<br>上面根据一定条件判断mapRejected和reduceRejected的值，下面通过判断mapRejected和reduceRejected值以及assignMultiple==false是已选择的tasks数量是否大于0，因为当assignMultiple==false时只能选择一个任务。当判断出需要退出循环时，则直接退出循环。</p>
<h4 id="FairScheduler-assignTasks()：-3"><strong>FairScheduler.assignTasks()：</strong></h4><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">TaskType taskType;</span><br><span class="line"><span class="keyword">if</span> (mapRejected) &#123;</span><br><span class="line">  taskType = TaskType<span class="built_in">.</span>REDUCE;</span><br><span class="line">&#125; <span class="keyword">else</span> <span class="keyword">if</span> (reduceRejected) &#123;</span><br><span class="line">  taskType = TaskType<span class="built_in">.</span><span class="built_in">MAP</span>;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  <span class="comment">// If both types are available, choose the task type with fewer running</span></span><br><span class="line">  <span class="comment">// tasks on the task tracker to prevent that task type from starving</span></span><br><span class="line">  <span class="keyword">if</span> (tts<span class="built_in">.</span>countMapTasks() + mapsAssigned &lt;=</span><br><span class="line">      tts<span class="built_in">.</span>countReduceTasks() + reducesAssigned) &#123;</span><br><span class="line">    taskType = TaskType<span class="built_in">.</span><span class="built_in">MAP</span>;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    taskType = TaskType<span class="built_in">.</span>REDUCE;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>下面是决定选择Map任务还是Reduce任务。如果mapRejected==true，则选择Reduce任务，相反如何reduceRejected==true，则选择Map任务，当两者都==false时，根据TT上已运行的Map数量+已为该TT选择的Map任务数量与TT上已运行的Reduce数量+已为该TT选择的Reduce任务数量之间的大小决定如何选择，当相等时优选选择Map任务。上面是一些准备工作，下面就开始进行任务的调度了。</p>
<h4 id="FairScheduler-assignTasks()：-4"><strong>FairScheduler.assignTasks()：</strong></h4><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// Get the <span class="built_in">map</span> <span class="built_in">or</span> reduce schedulables <span class="built_in">and</span> <span class="built_in">sort</span> them by fair sharing</span><br><span class="line">List&lt;PoolSchedulable&gt; scheds = getPoolSchedulables(taskType);</span><br><span class="line">Collections.<span class="built_in">sort</span>(scheds, <span class="keyword">new</span> SchedulingAlgorithms.FairShareComparator());</span><br></pre></td></tr></table></figure>
<p>第一句是获取所有的Map/Reduce类型的PoolScheduler。每个Pool中都存放着两个PoolScheduler，一个用来调度Map任务——mapSchedulable，另一个用来调度Reduce任务——reduceSchedulable。然后根据SchedulingAlgorithms.FairShareComparator进行排序，该排序算法主要是根据每个Pool或者Job中运行中的任务与Pool或者Job的自身状态之间的一个比率关系进行排序，即按运行中的任务数/Math.min(minShare,demand)升序排序，按运行中的任务数/weight升序排序。下面看看SchedulingAlgorithms.FairShareComparator类。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> FairShareComparator implements Comparator&lt;Schedulable&gt; &#123;</span><br><span class="line">   @<span class="function">Override</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Schedulable s1, Schedulable s2)</span> </span>&#123;</span><br><span class="line">     <span class="keyword">double</span> minShareRatio1, minShareRatio2;</span><br><span class="line">     <span class="keyword">double</span> tasksToWeightRatio1, tasksToWeightRatio2;</span><br><span class="line">     <span class="keyword">int</span> minShare1 = Math.min(s1.getMinShare(), s1.getDemand());</span><br><span class="line">     <span class="keyword">int</span> minShare2 = Math.min(s2.getMinShare(), s2.getDemand());</span><br><span class="line">     boolean s1Needy = s1.getRunningTasks() &lt; minShare1;</span><br><span class="line">     boolean s2Needy = s2.getRunningTasks() &lt; minShare2;</span><br><span class="line">     minShareRatio1 = s1.getRunningTasks() / Math.max(minShare1, <span class="number">1.0</span>);</span><br><span class="line">     minShareRatio2 = s2.getRunningTasks() / Math.max(minShare2, <span class="number">1.0</span>);</span><br><span class="line">     tasksToWeightRatio1 = s1.getRunningTasks() / s1.getWeight();</span><br><span class="line">     tasksToWeightRatio2 = s2.getRunningTasks() / s2.getWeight();</span><br><span class="line">     <span class="keyword">int</span> res = <span class="number">0</span>;</span><br><span class="line">     <span class="keyword">if</span> (s1Needy &amp;&amp; !s2Needy)</span><br><span class="line">       res = -<span class="number">1</span>;</span><br><span class="line">     <span class="keyword">else</span> <span class="keyword">if</span> (s2Needy &amp;&amp; !s1Needy)</span><br><span class="line">       res = <span class="number">1</span>;</span><br><span class="line">     <span class="keyword">else</span> <span class="keyword">if</span> (s1Needy &amp;&amp; s2Needy)</span><br><span class="line">       res = (<span class="keyword">int</span>) Math.signum(minShareRatio1 - minShareRatio2);</span><br><span class="line">     <span class="keyword">else</span> <span class="comment">// Neither schedulable is needy</span></span><br><span class="line">       res = (<span class="keyword">int</span>) Math.signum(tasksToWeightRatio1 - tasksToWeightRatio2);</span><br><span class="line">     <span class="keyword">if</span> (res == <span class="number">0</span>) &#123;</span><br><span class="line">       <span class="comment">// Jobs are tied in fairness ratio. Break the tie by submit time and job </span></span><br><span class="line">       <span class="comment">// name to get a deterministic ordering, which is useful for unit tests.</span></span><br><span class="line">       res = (<span class="keyword">int</span>) Math.signum(s1.getStartTime() - s2.getStartTime());</span><br><span class="line">       <span class="keyword">if</span> (res == <span class="number">0</span>)</span><br><span class="line">         res = s1.getName().compareTo(s2.getName());</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">return</span> res;</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>先说一下：compare(a,b)–&gt;-1，则a,b；compare(a,b)–&gt;1，则b,a（老是记不住）。这个比较算法还是较简单的，原理就是哪个Scheduler中的运行中的任务数越接近其承受能力那么排序就越靠后，这也是很合理的，优先调度较轻松的Scheduler（表达不好，嘿嘿）。排序好了就可以有序的进行任务调度了。</p>
<h4 id="FairScheduler-assignTasks()：-5"><strong>FairScheduler.assignTasks()：</strong></h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> foundTask = <span class="keyword">false</span>;</span><br><span class="line">      <span class="keyword">for</span> (Schedulable sched: scheds) &#123; <span class="comment">// This loop will assign only one task</span></span><br><span class="line">        eventLog.log(<span class="string">"INFO"</span>, <span class="string">"Checking for "</span> + taskType +</span><br><span class="line">            <span class="string">" task in "</span> + sched.getName());</span><br><span class="line">        <span class="keyword">Task</span> <span class="keyword">task</span> = taskType == TaskType.MAP ? </span><br><span class="line">                    sched.assignTask(tts, currentTime, visitedForMap) : </span><br><span class="line">                    sched.assignTask(tts, currentTime, visitedForReduce);</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">task</span> != <span class="keyword">null</span>) &#123;</span><br><span class="line">          foundTask = <span class="keyword">true</span>;</span><br><span class="line">          JobInProgress job = taskTrackerManager.getJob(<span class="keyword">task</span>.getJobID());</span><br><span class="line">          eventLog.log(<span class="string">"ASSIGN"</span>, trackerName, taskType,</span><br><span class="line">              job.getJobID(), <span class="keyword">task</span>.getTaskID());</span><br><span class="line">          <span class="comment">// Update running task counts, and the job's locality level</span></span><br><span class="line">          <span class="keyword">if</span> (taskType == TaskType.MAP) &#123;</span><br><span class="line">            launchedMap.add(job);</span><br><span class="line">            mapsAssigned++;</span><br><span class="line">            runningMaps++;</span><br><span class="line">            updateLastMapLocalityLevel(job, <span class="keyword">task</span>, tts);</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            reducesAssigned++;</span><br><span class="line">            runningReduces++;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">// Add task to the list of assignments</span></span><br><span class="line">          tasks.add(<span class="keyword">task</span>);</span><br><span class="line">          <span class="keyword">break</span>; <span class="comment">// This break makes this loop assign only one task</span></span><br><span class="line">        &#125; <span class="comment">// end if(task != null)</span></span><br><span class="line">      &#125; <span class="comment">// end for(Schedulable sched: scheds)</span></span><br></pre></td></tr></table></figure>
<p>foundTask标志是否选择到任务，每次遍历只选择一个Task，因为每个选择一个Task之后，Scheduler的状态都会发生变化，然后再重新进行排序，再选择。这里可以看出Task的选择是调用Scheduler的assignTask()方法选择的。Scheduler有两个实现，分别是PoolScheduler和JobScheduler，此处是PoolScheduler。下面来看看PoolScheduler的assignTask()方法。</p>
<h4 id="PoolScheduler-assignTask()："><strong>PoolScheduler.assignTask()：</strong></h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">Task</span> assignTask(TaskTrackerStatus tts, <span class="keyword">long</span> currentTime,</span><br><span class="line">      Collection&lt;JobInProgress&gt; visited) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">    <span class="keyword">int</span> runningTasks = getRunningTasks();</span><br><span class="line">    <span class="keyword">if</span> (runningTasks &gt;= poolMgr.getMaxSlots(pool.getName(), taskType)) &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    SchedulingMode mode = pool.getSchedulingMode();</span><br><span class="line">    Comparator&lt;Schedulable&gt; comparator;</span><br><span class="line">    <span class="keyword">if</span> (mode == SchedulingMode.FIFO) &#123;</span><br><span class="line">      comparator = <span class="keyword">new</span> SchedulingAlgorithms.FifoComparator();</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (mode == SchedulingMode.FAIR) &#123;</span><br><span class="line">      comparator = <span class="keyword">new</span> SchedulingAlgorithms.FairShareComparator();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"Unsupported pool scheduling mode "</span> + mode);</span><br><span class="line">    &#125;</span><br><span class="line">    Collections.<span class="keyword">sort</span>(jobScheds, comparator);</span><br><span class="line">    <span class="keyword">for</span> (JobSchedulable sched: jobScheds) &#123;</span><br><span class="line">      <span class="keyword">Task</span> <span class="keyword">task</span> = sched.assignTask(tts, currentTime, visited);</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">task</span> != <span class="keyword">null</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">task</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>首先获取该PoolScheduler运行中的Task数量，然后判断如果运行中的任务数大于该Pool的该类型任务（Map/Reduce）的最大数量，则不调度任务，返回null。然后根据<code>SchedulingMode mode = pool.getSchedulingMode()</code>获取Pool的调度模式（FIFO/FAIR），即FairScheduler在对Pool中的Job进行调度时支持两种调度方式：FIFO和FAIR。FIFO：先进先出，先添加的Job先调度，使用<code>SchedulingAlgorithms.FifoComparator</code>比较器；FAIR：根据公平原则进行调度（和Pool的调度一样，也是使用SchedulingAlgorithms.FairShareComparator比较器）。该参数由定义Pool时的schedulingMode参数指定。下面简单说一下FIFO调度规则。<br>FIFO：先根据Hadoop自带的Job的优先级priority（分为5个等级，优先级从高到低依次是：VERY_HIGH，HIGH，NORMAL，LOW，VERY_LOW），由在创建Job时通过mapred.job.priority参数指定，默认是NORMAL。然后根据Job的StartTime进行比较，越早的Job优先调度。<br>FAIR方式和PoolScheduler调度时一样。使用比较器对PoolScheduler中的Job（JobScheduler）进行排序。排序完成之后，遍历JobScheduler，通过调用JobScheduler的assignTask()方法选择任务。下面看看JobScheduler的assignTask()方法。</p>
<h4 id="JobScheduler-assignTask()："><strong>JobScheduler.assignTask()：</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function">Task <span class="title">assignTask</span><span class="params">(TaskTrackerStatus tts, <span class="keyword">long</span> currentTime,</span><br><span class="line">      Collection&lt;JobInProgress&gt; visited)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isRunnable()) &#123;</span><br><span class="line">      visited.add(job);</span><br><span class="line">      TaskTrackerManager ttm = scheduler.taskTrackerManager;</span><br><span class="line">      ClusterStatus clusterStatus = ttm.getClusterStatus();</span><br><span class="line">      <span class="keyword">int</span> numTaskTrackers = clusterStatus.getTaskTrackers();</span><br><span class="line"></span><br><span class="line">      <span class="comment">// check with the load manager whether it is safe to </span></span><br><span class="line">      <span class="comment">// launch this task on this taskTracker.</span></span><br><span class="line">      LoadManager loadMgr = scheduler.getLoadManager();</span><br><span class="line">      <span class="keyword">if</span> (!loadMgr.canLaunchTask(tts, job, taskType)) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (taskType == TaskType.MAP) &#123;</span><br><span class="line">        LocalityLevel localityLevel = scheduler.getAllowedLocalityLevel(</span><br><span class="line">            job, currentTime);</span><br><span class="line">        scheduler.getEventLog().log(</span><br><span class="line">            <span class="string">"ALLOWED_LOC_LEVEL"</span>, job.getJobID(), localityLevel);</span><br><span class="line">        <span class="keyword">switch</span> (localityLevel) &#123;</span><br><span class="line">          <span class="keyword">case</span> NODE:</span><br><span class="line">            <span class="keyword">return</span> job.obtainNewNodeLocalMapTask(tts, numTaskTrackers,</span><br><span class="line">                ttm.getNumberOfUniqueHosts());</span><br><span class="line">          <span class="keyword">case</span> RACK:</span><br><span class="line">            <span class="keyword">return</span> job.obtainNewNodeOrRackLocalMapTask(tts, numTaskTrackers,</span><br><span class="line">                ttm.getNumberOfUniqueHosts());</span><br><span class="line">          <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">return</span> job.obtainNewMapTask(tts, numTaskTrackers,</span><br><span class="line">                ttm.getNumberOfUniqueHosts());</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> job.obtainNewReduceTask(tts, numTaskTrackers,</span><br><span class="line">            ttm.getNumberOfUniqueHosts());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>可以看出只有运行中的Job才能调度Task。visited.add(job)将该Job添加到visited队列，表示该Job在任务调度时有被访问过。然后通过LoadManager.canLaunchTask()方法判断是否可以在该TT上运行任务，这里默认是true。针对Map任务需要考虑任务的本地化，即尽可能的使Map任务运行在存放着输入文件的TT上，以提高Map任务运行效率。LocalityLevel localityLevel = scheduler.getAllowedLocalityLevel(job, currentTime)是获取Map任务的一个本地化级别，然后根据本地化级别调用不同方法获取不同的Task，而对于Reduce任务则直接选择一个任务即可。下面看看FairScheduler.getAllowedLocalityLevel()方法。</p>
<h4 id="FairScheduler-getAllowedLocalityLevel()："><strong>FairScheduler.getAllowedLocalityLevel()：</strong></h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">JobInfo info = infos.get(job);</span><br><span class="line">    <span class="keyword">if</span> (info == <span class="keyword">null</span>) &#123; <span class="comment">// Job not in infos (shouldn't happen)</span></span><br><span class="line">      LOG.error(<span class="string">"getAllowedLocalityLevel called on job "</span> + job</span><br><span class="line">          + <span class="string">", which does not have a JobInfo in infos"</span>);</span><br><span class="line">      <span class="keyword">return</span> LocalityLevel.<span class="keyword">ANY</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (job.nonLocalMaps.<span class="keyword">size</span>() &gt; <span class="number">0</span>) &#123; <span class="comment">// Job doesn't have locality information</span></span><br><span class="line">      <span class="keyword">return</span> LocalityLevel.<span class="keyword">ANY</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>首先任务的本地化级别存在四个级别：NODE（表示Map的输入文件需要与任务运行的TT在一个节点上），NODEGROUP（表示Map的输入文件需要与任务运行的TT在一个节点组上），RACK（表示Map的输入文件需要与任务运行的TT在一个节机架上），ANY（无任何要求）。首先获取Job的JobInfo信息，如果不存在对应的JobInfo信息则返回LocalityLevel.ANY，如果Job的nonLocalMaps队列不为空也返回LocalityLevel.ANY。nonLocalMaps是在Job进行初始化时通过判断Job的Split如果没有Location则将该Split对应的Map任务添加到nonLocalMaps队列。<br><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">Pool</span> pool = poolMgr.getPool(job);</span><br><span class="line">    <span class="type">PoolSchedulable</span> sched = pool.getMapSchedulable<span class="literal">()</span>;</span><br><span class="line">    long minShareTimeout = poolMgr.getMinSharePreemptionTimeout(pool.getName<span class="literal">()</span>);</span><br><span class="line">    long fairShareTimeout = poolMgr.getFairSharePreemptionTimeout<span class="literal">()</span>;</span><br><span class="line">    <span class="keyword">if</span> (currentTime - sched.getLastTimeAtMinShare<span class="literal">()</span> &gt; minShareTimeout ||</span><br><span class="line">        currentTime - sched.getLastTimeAtHalfFairShare<span class="literal">()</span> &gt; fairShareTimeout) &#123;</span><br><span class="line">      eventLog.log(<span class="string">"INFO"</span>, <span class="string">"No delay scheduling for "</span></span><br><span class="line">          + job.getJobID<span class="literal">()</span> + <span class="string">" because it is being starved"</span>);</span><br><span class="line">      return <span class="type">LocalityLevel</span>.<span class="type">ANY</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>判断该Job所在的Pool是否处于饥饿状态，是的话则直接返回LocalityLevel.ANY。此处根据Pool的minShareTimeout和fairShareTimeout两个属性值进行判断。Pool的lastTimeAtMinShare和lastTimeAtHalfFairShare值是在FairScheduler的update()方法中更新的，而该方法由一个线程一直调用。<br><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// In the common case, compute locality level based on time waited</span></span><br><span class="line">    <span class="keyword">switch</span>(info.lastMapLocalityLevel) &#123;</span><br><span class="line">    <span class="keyword">case</span> NODE: <span class="comment">// Last task launched was node-local</span></span><br><span class="line">      <span class="keyword">if</span> (info.timeWaitedForLocalMap &gt;=</span><br><span class="line">          nodeLocalityDelay + rackLocalityDelay)</span><br><span class="line">        <span class="keyword">return</span> LocalityLevel.<span class="keyword">ANY</span>;</span><br><span class="line">      <span class="keyword">else</span> <span class="keyword">if</span> (info.timeWaitedForLocalMap &gt;= nodeLocalityDelay)</span><br><span class="line">        <span class="keyword">return</span> LocalityLevel.RACK;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> LocalityLevel.NODE;</span><br><span class="line">    <span class="keyword">case</span> RACK: <span class="comment">// Last task launched was rack-local</span></span><br><span class="line">      <span class="keyword">if</span> (info.timeWaitedForLocalMap &gt;= rackLocalityDelay)</span><br><span class="line">        <span class="keyword">return</span> LocalityLevel.<span class="keyword">ANY</span>;</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> LocalityLevel.RACK;</span><br><span class="line">    <span class="keyword">default</span>: <span class="comment">// Last task was non-local; can launch anywhere</span></span><br><span class="line">      <span class="keyword">return</span> LocalityLevel.<span class="keyword">ANY</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>下面根据Job的lastMapLocalityLevel，即该Job上一次调度Map任务时所选择的的LocalityLevel值决定本次如何进行Map任务的调度。如果lastMapLocalityLevel==NODE，则表示Job上一次调度Map任务是本地化等级是NODE，当等待时间timeWaitedForLocalMap&gt;(nodeLocalityDelay + rackLocalityDelay)这两个属性之和时则选择LocalityLevel.ANY；但是如果timeWaitedForLocalMap只是&gt;nodeLocalityDelay，那么则可以选择RACK级别的本地化，如果timeWaitedForLocalMap<nodelocalitydelay，那么则选择node级别的本地化。timewaitedforlocalmap的值是在fairscheduler的assigntasks()方法中更新的，即fairscheduler开始调度任务之前会先更新fairscheduler上保存的所有job的jobinfo中的timewaitedforlocalmap值，已确保后面能够正确选择map任务的本地化级别。当lastmaplocalitylevel==rack时，只需要timewaitedforlocalmap>=rackLocalityDelay就可以返回ANY，否则返回RACK；默认返回RACK。这里就计算出在选择Map任务时的本地化级别，之后Job在选择Map任务时会根据本地化级别选择不同的任务进行运行。回到JobScheduler.assignTask()方法。</nodelocalitydelay，那么则选择node级别的本地化。timewaitedforlocalmap的值是在fairscheduler的assigntasks()方法中更新的，即fairscheduler开始调度任务之前会先更新fairscheduler上保存的所有job的jobinfo中的timewaitedforlocalmap值，已确保后面能够正确选择map任务的本地化级别。当lastmaplocalitylevel==rack时，只需要timewaitedforlocalmap></p>
<h4 id="JobScheduler-assignTask()：-1"><strong>JobScheduler.assignTask()：</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">switch</span> (localityLevel) &#123;</span><br><span class="line">          <span class="keyword">case</span> NODE:</span><br><span class="line">            <span class="keyword">return</span> job.obtainNewNodeLocalMapTask(tts, numTaskTrackers,</span><br><span class="line">                ttm.getNumberOfUniqueHosts());</span><br><span class="line">          <span class="keyword">case</span> RACK:</span><br><span class="line">            <span class="keyword">return</span> job.obtainNewNodeOrRackLocalMapTask(tts, numTaskTrackers,</span><br><span class="line">                ttm.getNumberOfUniqueHosts());</span><br><span class="line">          <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">return</span> job.obtainNewMapTask(tts, numTaskTrackers,</span><br><span class="line">                ttm.getNumberOfUniqueHosts());</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>这是在选择Map任务时根据本地化级别会调用不同的方法选择不同的任务。主要是obtainNewNodeLocalMapTask()，obtainNewNodeOrRackLocalMapTask()，obtainNewMapTask()三个方法，以及选择Reduce任务的obtainNewReduceTask()方法。这四个方法内部还是有点复杂的下次再深入分析。<br>到这里JobScheduler的assignTask()就完成了，返回Task，回到PoolScheduler的assignTask()方法，可以看到只要得到一个Task，PoolScheduler就会返回该Task，所以继续回到FairScheduler的assignTask()方法。在FairScheduler的assignTask()方法中可以看到，当返回一个Task之后会标志foundTask=true，如果是Map任务则会将Task对应的Job添加到launchedMap中，然后调用updateLastMapLocalityLevel()方法更新Job的JobInfo的lastMapLocalityLevel和timeWaitedForLocalMap值，以便下次正确的选择Map任务。</p>
<h4 id="FairScheduler-assignTask()："><strong>FairScheduler.assignTask()：</strong></h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="title">if</span> (!foundTask) &#123;</span><br><span class="line">        <span class="title">if</span> (taskType == TaskType.MAP) &#123;</span><br><span class="line">          <span class="title">mapRejected</span> = <span class="built_in">true</span>;</span><br><span class="line">        &#125; <span class="title">else</span> &#123;</span><br><span class="line">          <span class="title">reduceRejected</span> = <span class="built_in">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure>
<p>该处很简单，判断如果没有选到Map任务或者Reduce任务，则将相应的标志设为true。<br><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (JobInProgress job: visitedForMap) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!launchedMap.<span class="keyword">contains</span>(job)) &#123;</span><br><span class="line">        infos.<span class="keyword">get</span>(job).skippedAtLastHeartbeat = <span class="constant">true</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<p>visitedForMap该值在进行调度Map任务时每访问一个Job都会被记录在该队列中，如果被访问的Job并不在launchedMap队列（存放被选中Map任务的Job）中，则将该Job对应的JobInfo的skippedAtLastHeartbeat参数设为true，表示本次心跳没有选择该Job的Map任务。这个skippedAtLastHeartbeat参数会影响Job的timeWaitedForLocalMap值，具体可以参考FairScheduler的updateLocalityWaitTimes()方法。</p>
<hr>
<p>以上就是FairScheduler调度任务源码的一些简单的解析，如有错误之处，请指出，谢谢。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>首先需要了解FairScheduler是如何在各个Pool之间分配资源，以及每个Pool如何在Job之间分配资源的。FairScheduler的分配资源发生在update()方法中，而该方法由一个线程UpdateThread每隔updateInterval（由mapred.]]>
    </summary>
    
      <category term="FairScheduler" scheme="http://vickyqi.com/tags/FairScheduler/"/>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="MapReduce" scheme="http://vickyqi.com/tags/MapReduce/"/>
    
      <category term="任务调度" scheme="http://vickyqi.com/tags/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[FairScheduler job初始化过程源码浅析]]></title>
    <link href="http://vickyqi.com/2013/11/21/FairScheduler%20job%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%87%E7%A8%8B%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/"/>
    <id>http://vickyqi.com/2013/11/21/FairScheduler job初始化过程源码浅析/</id>
    <published>2013-11-21T14:31:00.000Z</published>
    <updated>2015-10-31T06:58:44.000Z</updated>
    <content type="html"><![CDATA[<p><a href="http://vickyqi.com/2013/11/18/Hadoop%20JobTracker%E6%8F%90%E4%BA%A4job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/">上一篇文章说到了jobTracker中的submitJob()方法</a>，这个方法最终会调用listener.jobAdded(job)，将Job注册到TaskScheduler中，由其进行调度。<br>今天接着研究hadoop中默认的TaskScheduler是JobQueueTaskScheduler，采用的是FIFO(先进先出)原则进行调度，还有FiarScheduler和CapacityTaskScheduler两种调度类（非hadoop自带，不过hadoop也把他们加入到类库中），这两个类可以在hadoop目录下的lib包下找到，源码在src/contrib下可以找到。主要对FairScheduler进行解读。<br>上文提到jobTracker最终将job注册到jobListener中，下面就来看看FairScheduler的JobListener。</p>
<h4 id="FairScheduler-JobListener-addJob()："><strong>FairScheduler.JobListener.addJob()：</strong></h4><p>这个方法比较简单，<code>JobSchedulable mapSched = ReflectionUtils.newInstance(conf.getClass(“mapred.jobtracker.jobSchedulable”, JobSchedulable.class, JobSchedulable.class), conf)</code>这里通过反射获得两个JobSchedulable对象，也就是默认的FairScheduler.JobSchedulable对象，一个是mapSched，一个是redSched，然后进行JobSchedulable的初始化，比较简单。infos.put(job, info)将job添加到infos（存放所有的jobInPorgress对象）中，同时将job添加到PoolScheduable中，主要是根据配置的poolName获取对应的pool。下面的是重点，update()方法，下面看看这个方法。<br><figure class="highlight roboconf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="component">public void jobAdded(JobInProgress job) &#123;</span><br><span class="line">      synchronized (FairScheduler<span class="string">.this)</span> &#123;</span><br><span class="line">        eventLog<span class="string">.log("JOB_ADDED"</span>, job<span class="string">.getJobID())</span>;</span><br><span class="line">        JobSchedulable mapSched = ReflectionUtils<span class="string">.newInstance(</span></span><br><span class="line">            conf<span class="string">.getClass("mapred.jobtracker.jobSchedulable"</span>, JobSchedulable<span class="string">.class</span>,</span><br><span class="line">                JobSchedulable<span class="string">.class)</span>, conf);</span><br><span class="line">        mapSched<span class="string">.init(FairScheduler.this</span>, job, TaskType<span class="string">.MAP)</span>;</span><br><span class="line"></span><br><span class="line">        JobSchedulable redSched = ReflectionUtils<span class="string">.newInstance(</span></span><br><span class="line">            conf<span class="string">.getClass("mapred.jobtracker.jobSchedulable"</span>, JobSchedulable<span class="string">.class</span>,</span><br><span class="line">                JobSchedulable<span class="string">.class)</span>, conf);</span><br><span class="line">        redSched<span class="string">.init(FairScheduler.this</span>, job, TaskType<span class="string">.REDUCE)</span>;</span><br><span class="line"></span><br><span class="line">        JobInfo info = new JobInfo(mapSched, redSched);</span><br><span class="line">        infos<span class="string">.put(job</span>, info);</span><br><span class="line">        poolMgr<span class="string">.addJob(job)</span>; // Also adds job into the right PoolScheduable</span><br><span class="line">        update();</span><br><span class="line">      &#125;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="FairScheduler-update()："><strong>FairScheduler.update()：</strong></h4><p>跳过看不懂的，直接看<code>poolMgr.reloadAllocsIfNecessary()</code>，这个方法主要是读取FairScheduler的配置文件（fair-scheduler.xml），由mapred.fairscheduler.allocation.file参数设置，这里是根据配置文件的最后修改时间+ALLOC_RELOAD_INTERVAL决定是否重新加载配置文件，加载文件的时候就是简单地读取xml文件。接着看update方法，加载完配置文件之后会遍历infos（保存了FairScheduler所有的jobInProgress），遍历的时候去除成功了的job和失败了的job以及被kill掉的job，同时也会从pool中去掉该job。接下来就是updateRunnability()，这个方法会根据userMaxJob以及poolMaxJob数量进行判断是否启动job。<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">List&lt;JobInProgress&gt; toRemove = <span class="keyword">new</span> ArrayList&lt;JobInProgress&gt;();</span><br><span class="line">     <span class="keyword">for</span> (JobInProgress <span class="string">job:</span> infos.keySet()) &#123; </span><br><span class="line">       <span class="typename">int</span> runState = job.getStatus().getRunState();</span><br><span class="line">       <span class="keyword">if</span> (runState == JobStatus.SUCCEEDED || runState == JobStatus.FAILED</span><br><span class="line">         || runState == JobStatus.KILLED) &#123;</span><br><span class="line">           toRemove.add(job);</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br><span class="line">     <span class="keyword">for</span> (JobInProgress <span class="string">job:</span> toRemove) &#123;</span><br><span class="line">       jobNoLongerRunning(job);</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="FairScheduler-updateRunnability()："><strong>FairScheduler.updateRunnability()：</strong></h4><p>第一步将所有infos中剩余的job（成功以及失败的任务会在update时清除）状态全部设为notrunning。接着对infos中的job进行排序，<code>Collections.sort(jobs, new FifoJobComparator())</code>，排序规则是FIFO原则（奇怪，不懂）。然后接着对jobs进行遍历，同时根据该job的提交用户和提交的pool的最大提交job数量决定是否将其添加到任务队列中（就是两个list），如果该job状态=RUNNING，则jobinfo.running=true，如果job状态=PREP（准备中），则对其进行初始化（注意这里只对job状态=RUNNING和PREP的job进行操作）。<code>jobInitializer.initJob(jobInfo, job)</code>进行job初始化，这里使用到jdk的threadPool（其实就是将thread加入到线程池中，由线程池绝对什么时候对其进行执行，总之都会调用thread的run方法），看看thread的run方法。run方法中调用ttm.initJob(job)，此处的ttm就是jobTracker，现在回到jobTracker去。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (userCount &lt; poolMgr.getUserMaxJobs(user) &amp;&amp;</span><br><span class="line">         poolCount &lt; poolMgr.getPoolMaxJobs(pool)) &#123;</span><br><span class="line">       <span class="keyword">if</span> (job.getStatus().getRunState() == JobStatus.RUNNING ||</span><br><span class="line">           job.getStatus().getRunState() == JobStatus.PREP) &#123;</span><br><span class="line">         userJobs.put(user, userCount + <span class="number">1</span>);</span><br><span class="line">         poolJobs.put(pool, poolCount + <span class="number">1</span>);</span><br><span class="line">         JobInfo jobInfo = infos.get(job);</span><br><span class="line">         <span class="keyword">if</span> (job.getStatus().getRunState() == JobStatus.RUNNING) &#123;</span><br><span class="line">           jobInfo.runnable = <span class="literal">true</span>;</span><br><span class="line">         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           <span class="comment">// The job is in the PREP state. Give it to the job initializer</span></span><br><span class="line">           <span class="comment">// for initialization if we have not already done it.</span></span><br><span class="line">           <span class="keyword">if</span> (jobInfo.needsInitializing) &#123;</span><br><span class="line">             jobInfo.needsInitializing = <span class="literal">false</span>;</span><br><span class="line">             jobInitializer.initJob(jobInfo, job);</span><br><span class="line">           &#125;</span><br><span class="line">         &#125;</span><br><span class="line">       &#125;</span><br><span class="line">     &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="JobTracker-initJob()："><strong>JobTracker.initJob()：</strong></h4><p>主要调用job.initTasks()，下面进入到<code>JobInProgress.initTasks()</code>。</p>
<h4 id="JobInProgress-initTasks()："><strong>JobInProgress.initTasks()：</strong></h4><p>为job对象设置优先级setPriority(this.priority)，接着读取分片信息文件获取分片信息，<code>SplitMetaInfoReader.readSplitMetaInfo()</code>这个方就是jobInPorgress用来读取分分片信息的，读取过程与写入过程相对应，具体还是较简单的。读取了分片信息之后，根据分片数量创建相应数量的mapTask（TaskInProgress对象），接下来会执行<code>nonRunningMapCache = createCache(splits, maxLevel)</code>，这个方法是根据每个分片的location信息，然后根据location的host判断每个host上所有的job，并放入cache中。接着根据设置的reduce数量新建对应的reduceTask（TaskInProgress对象），并加入到nonRunningReduces队列中，并根据mapred.reduce.slowstart.completed.maps（百分比，默认是5%）参数的值计算completedMapsForReduceSlowstart（多少map任务完成的时候启动reduce任务）。之后就是分别新建两个setUp任务和cheanUp任务，分别对应map和reduce task。到此initTask完成，initTask完成JobTracker的initJob也就差不多完成了，接着FairScheduler的updateRunnability()也就完成了。回到FairScheduler.update()。</p>
<h4 id="FairScheduler-update()：-1"><strong>FairScheduler.update()：</strong></h4><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">for (Pool pool: poolMgr.getPools()) &#123;</span><br><span class="line">        pool.getMapSchedulable().updateDemand()<span class="comment">;</span></span><br><span class="line">        pool.getReduceSchedulable().updateDemand()<span class="comment">;</span></span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      // Compute fair shares based on updated demands</span><br><span class="line">      List&lt;PoolSchedulable&gt; mapScheds = getPoolSchedulables(TaskType.MAP)<span class="comment">;</span></span><br><span class="line">      List&lt;PoolSchedulable&gt; reduceScheds = getPoolSchedulables(TaskType.REDUCE)<span class="comment">;</span></span><br><span class="line">      SchedulingAlgorithms.computeFairShares(</span><br><span class="line">          mapScheds, clusterStatus.getMaxMapTasks())<span class="comment">;</span></span><br><span class="line">      SchedulingAlgorithms.computeFairShares(</span><br><span class="line">          reduceScheds, clusterStatus.getMaxReduceTasks())<span class="comment">;</span></span><br><span class="line">      </span><br><span class="line">      // Use the computed shares to assign shares within each pool</span><br><span class="line">      for (Pool pool: poolMgr.getPools()) &#123;</span><br><span class="line">        pool.getMapSchedulable().redistributeShare()<span class="comment">;</span></span><br><span class="line">        pool.getReduceSchedulable().redistributeShare()<span class="comment">;</span></span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      if (preemptionEnabled)</span><br><span class="line">        updatePreemptionVariables()<span class="comment">;</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>看不懂，先到这吧，等下次慢慢研究吧，今天就到这了，好累。</p>
<hr>
<p>今天把上次遗留的问题继续研究一下。<br><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for (<span class="type">Pool</span> pool: poolMgr.getPools<span class="literal">()</span>) &#123;</span><br><span class="line">        pool.getMapSchedulable<span class="literal">()</span>.updateDemand<span class="literal">()</span>;</span><br><span class="line">        pool.getReduceSchedulable<span class="literal">()</span>.updateDemand<span class="literal">()</span>;</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure></p>
<p>这里是更新每个pool的slot需求情况，下面来看看，<code>pool.getMapSchedulable().updateDemand()</code>，<code>pool.getReduceSchedulable().updateDemand()</code>两个基本相同。</p>
<h4 id="PoolSchedulable-updateDemand()："><strong>PoolSchedulable.updateDemand()：</strong></h4><p>第一句<code>poolMgr.getMaxSlots(pool.getName(), taskType)</code>是获取pool的最大slot数量，从配置文件获取，配置文件是之前加载过的，前面有说到。每个PoolSchedulable中都会存在多个JobSchedulable对象，在JobListener.addJob()时添加。一个JobSchedulable对应一个jobInProgress对象。然后调用JobSchedulable.updateDemand()更新每个JobSchedulable的slot的需求。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">updateDemand</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// limit the demand to maxTasks</span></span><br><span class="line">    <span class="keyword">int</span> maxTasks = poolMgr.getMaxSlots(pool.getName(), taskType);</span><br><span class="line">    demand = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (JobSchedulable sched: jobScheds) &#123;</span><br><span class="line">      sched.updateDemand();</span><br><span class="line">      demand += sched.getDemand();</span><br><span class="line">      <span class="keyword">if</span> (demand &gt;= maxTasks) &#123;</span><br><span class="line">        demand = maxTasks;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (LOG.isDebugEnabled()) &#123;</span><br><span class="line">      LOG.debug(<span class="string">"The pool "</span> + pool.getName() + <span class="string">" demand is "</span> + demand</span><br><span class="line">          + <span class="string">"; maxTasks is "</span> + maxTasks);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="JobSchedulable-updateDemand()："><strong>JobSchedulable.updateDemand()：</strong></h4><p>首先第一步就是判断该JobSchedulable的job是否已运行(RUNNING)，没有运行则不分配slot。然后判断该JobSchedulable是Map还是Reduce，如果是Reduce则需先判断完成的Map数量(finishedMapTasks)数量+失败的Map(failedMapTIPs)数量&gt;=completedMapsForReduceSlowstart（由”mapred.reduce.slowstart.completed.maps参数值*numMapTasks），满足则表示Reduce任务可以启动，否则不可启动。而对于Map任务直接计算其slot需求。<code>TaskInProgress[] tips = (taskType == TaskType.MAP ? job.getTasks(TaskType.MAP) : job.getTasks(TaskType.REDUCE))</code>，获取对应的taskInPorgress数量(tip)，<code>boolean speculationEnabled = (taskType == TaskType.MAP ?job.getMapSpeculativeExecution() : job.getReduceSpeculativeExecution())</code>判断是否启用推测执行，<code>double avgProgress = (taskType == TaskType.MAP ?job.getStatus().mapProgress() : job.getStatus().reduceProgress())</code>获取map/reduce任务的进度，即map/reduce已完成多少，之后计算每个taskInProgress的slot需求。如果taskInProgress未完成则正在运行中，则<code>demand += tip.getActiveTasks().size()</code>计算出所需的slot数量，而tip的ActiveTasks则是任务调用的时候，即调用tip.addRunningTask()方法时添加的，而该方法的调用者则是FairScheduler的assignTasks()方法，即方法调度。获取到tip的activeTasks数量，则就是该tip所需要的slot数量，同时如果启用了推测执行，则还需多加一个slot用于推测执行任务，这样就获得了一个JobSchedulable所需的总slot数量，求和即为这个pool所需的总slot数量，当所需数量大于maxTasks（该pool所拥有的最大slot数），则返回。继续回到FairScheduler.update()方法。</p>
<h4 id="FairScheduler-update()：-2"><strong>FairScheduler.update()：</strong></h4><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">List&lt;PoolSchedulable&gt; mapScheds = getPoolSchedulables(TaskType.MAP)<span class="comment">;</span></span><br><span class="line">      List&lt;PoolSchedulable&gt; reduceScheds = getPoolSchedulables(TaskType.REDUCE)<span class="comment">;</span></span><br><span class="line">      SchedulingAlgorithms.computeFairShares(</span><br><span class="line">          mapScheds, clusterStatus.getMaxMapTasks())<span class="comment">;</span></span><br><span class="line">      SchedulingAlgorithms.computeFairShares(</span><br><span class="line">          reduceScheds, clusterStatus.getMaxReduceTasks())<span class="comment">;</span></span><br><span class="line">      </span><br><span class="line">      // Use the computed shares to assign shares within each pool</span><br><span class="line">      for (Pool pool: poolMgr.getPools()) &#123;</span><br><span class="line">        pool.getMapSchedulable().redistributeShare()<span class="comment">;</span></span><br><span class="line">        pool.getReduceSchedulable().redistributeShare()<span class="comment">;</span></span><br><span class="line">      &#125;</span><br><span class="line">      </span><br><span class="line">      if (preemptionEnabled)</span><br><span class="line">        updatePreemptionVariables()<span class="comment">;</span></span><br></pre></td></tr></table></figure>
<p>这里涉及的就是FairScheduler的核心之处——资源分配算法。先看看前两句，前两句就是获取所有的MapPoolSchedulable和ReducePoolSchedulable，一个pool中分别包含一个MapPoolSchedulable和ReducePoolSchedulable。下面两句就是具体的资源分配，调用的是SchedulingAlgorithms类进行资源分配的。</p>
<h4 id="SchedulingAlgorithms-computeFairShares()："><strong>SchedulingAlgorithms.computeFairShares()：</strong></h4><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="function"><span class="keyword">double</span> <span class="title">slotsUsedWithWeightToSlotRatio</span><span class="params">(<span class="keyword">double</span> w2sRatio,</span><br><span class="line">      Collection&lt;? <span class="keyword">extends</span> Schedulable&gt; schedulables)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> slotsTaken = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (Schedulable sched: schedulables) &#123;</span><br><span class="line">      <span class="keyword">double</span> share = computeShare(sched, w2sRatio);</span><br><span class="line">      slotsTaken += share;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> slotsTaken;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>调用computeShare()方法根据job的weight和w2sRatio（相当于总权重，1.0）计算每个Schedulable根据权重应该获得slot数量。</p>
<h4 id="SchedulingAlgorithms-computeShare()："><strong>SchedulingAlgorithms.computeShare()：</strong></h4><p>第一句<code>double share = sched.getWeight() <em> w2sRatio</em></code>，获取Pool的权重，该权重是在fair-scheduler.xml中设置pool时为pool设置了weigth，默认是1.0。获得job权重之后，根据weigthw2sRatio获得一个share值，然后<code>share=Math.max(share, sched.getMinShare())</code>（minShare默认是0），<code>share = Math.min(share, sched.getDemand())</code>，即获得share值。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">getJobWeight</span><span class="params">(JobInProgress job, TaskType taskType)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (!isRunnable(job)) &#123;</span><br><span class="line">      <span class="comment">// Job won't launch tasks, but don't return 0 to avoid division errors</span></span><br><span class="line">      <span class="keyword">return</span> <span class="number">1.0</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">double</span> weight = <span class="number">1.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (sizeBasedWeight) &#123;</span><br><span class="line">        <span class="comment">// Set weight based on runnable tasks</span></span><br><span class="line">        JobInfo info = infos.get(job);</span><br><span class="line">        <span class="keyword">int</span> runnableTasks = (taskType == TaskType.MAP) ?</span><br><span class="line">            info.mapSchedulable.getDemand() : </span><br><span class="line">            info.reduceSchedulable.getDemand();</span><br><span class="line">        weight = Math.log1p(runnableTasks) / Math.<span class="built_in">log</span>(<span class="number">2</span>);</span><br><span class="line">      &#125;</span><br><span class="line">      weight *= getPriorityFactor(job.getPriority());</span><br><span class="line">      <span class="keyword">if</span> (weightAdjuster != null) &#123;</span><br><span class="line">        <span class="comment">// Run weight through the user-supplied weightAdjuster</span></span><br><span class="line">        weight = weightAdjuster.adjustWeight(job, taskType, weight);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> weight;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">double</span> <span class="title">computeShare</span><span class="params">(Schedulable sched, <span class="keyword">double</span> w2sRatio)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">double</span> share = sched.getWeight() * w2sRatio;</span><br><span class="line">    share = Math.max(share, sched.getMinShare());</span><br><span class="line">    share = Math.min(share, sched.getDemand());</span><br><span class="line">    <span class="keyword">return</span> share;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="SchedulingAlgorithms-computeFairShares："><strong>SchedulingAlgorithms.computeFairShares：</strong></h4><p>返回到该方法，全总体来看其实这里是一个算法（好吧，这个类本身就是一个算法类），这个算法旨在找出一个合适的fairShare值，使得所有job的权重<em>fairShare之和最接近cap值（Math.min(totalDemand, totalSlots)），这是一个二分查找算法，至于这样做的原因可以参见SchedulingAlgorithms.computeFairShares的注释，大致的意思好像是这个值叫做weighted fair sharing，We call R the weight-to-slots ratio because it converts a Schedulable’s weight to the number of slots it is assigned。也就是这个可以根据这个值</em>pool的权重得到该pool所分配到的slot数量。就到这，英语不好看不太懂，等别人解释吧。最后<code>sched.setFairShare(computeShare(sched, right))</code>将这个值设置到PoolSchedulable中。<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (Schedulable sched: schedulables) &#123;</span><br><span class="line">      totalDemand += sched.getDemand();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">double</span> cap = Math.min(totalDemand, totalSlots);</span><br><span class="line">    <span class="keyword">double</span> rMax = <span class="number">1.0</span>;</span><br><span class="line">    <span class="keyword">while</span> (slotsUsedWithWeightToSlotRatio(rMax, schedulables) &lt; cap) &#123;</span><br><span class="line">      rMax *= <span class="number">2.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Perform the binary search for up to COMPUTE_FAIR_SHARES_ITERATIONS steps</span></span><br><span class="line">    <span class="keyword">double</span> left = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> right = rMax;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; COMPUTE_FAIR_SHARES_ITERATIONS; i++) &#123;</span><br><span class="line">      <span class="keyword">double</span> mid = (left + right) / <span class="number">2.0</span>;</span><br><span class="line">      <span class="keyword">if</span> (slotsUsedWithWeightToSlotRatio(mid, schedulables) &lt; cap) &#123;</span><br><span class="line">        left = mid;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        right = mid;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="FairScheduler-update()：-3"><strong>FairScheduler.update()：</strong></h4><p>后面是对每个JobSchedulable使用同上方法计算一个fairShare值，意义是为pool中的每个job的可分配的slot数量。这里同样会计算job的weigth,job的权重是由FairScheduler计算得到的，在计算权重时，可以选择是否开启根据job长度调整权重（由mapred.fairscheduler.sizebasedweight参数控制，默认false），然后根据job的优先级判断相应的权重，其对应关系：优先级：VERY_HIGH-权重：4.0/HIGH：2.0/NORMAL：1.0/LOW：0.5，最后根据weightAdjuster进行调整job的权重，需要手动实现，由mapred.fairscheduler.weightadjuster参数设置，如果你自定义了一个weightAdjuster类，则可以通过重写adjustWeight()方法控制job的权重。总之默认情况下一个job的权重只是取决于该Job优先级。后面的跳过，不是太懂</p>
<h4 id="FairScheduler-update()：-4"><strong>FairScheduler.update()：</strong></h4><p>最后是判断是否支持抢占机制，即当一个资源池资源有剩余是否允许将剩余资源共享给其他资源池。具体是判断每个资源池中正在运行的任务是否小于资源池本身最小资源量或者需求量，同时还判断该资源池是否急于将资源共享给其他资源，即资源使用量低于共享量的一半。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">private void <span class="function"><span class="title">updatePreemptionVariables</span></span>() &#123;</span><br><span class="line">   long now = clock.getTime();</span><br><span class="line">   lastPreemptionUpdateTime = now;</span><br><span class="line">   <span class="keyword">for</span> (TaskType <span class="built_in">type</span>: MAP_AND_REDUCE) &#123;</span><br><span class="line">     <span class="keyword">for</span> (PoolSchedulable <span class="built_in">sched</span>: getPoolSchedulables(<span class="built_in">type</span>)) &#123;</span><br><span class="line">       <span class="keyword">if</span> (!isStarvedForM<span class="keyword">in</span>Share(<span class="built_in">sched</span>)) &#123;</span><br><span class="line">         sched.setLastTimeAtM<span class="keyword">in</span>Share(now);</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">if</span> (!isStarvedForFairShare(<span class="built_in">sched</span>)) &#123;</span><br><span class="line">         sched.setLastTimeAtHalfFairShare(now);</span><br><span class="line">       &#125;</span><br><span class="line">       eventLog.log(<span class="string">"PREEMPT_VARS"</span>, sched.getName(), <span class="built_in">type</span>,</span><br><span class="line">           now - sched.getLastTimeAtM<span class="keyword">in</span>Share(),</span><br><span class="line">           now - sched.getLastTimeAtHalfFairShare());</span><br><span class="line">     &#125;</span><br><span class="line">   &#125;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>到此，整个FairScheduler的任务初始化操作或者说JobListener的jobAdded()方法完成了，分析的有遗漏，也许还有错误，如您发现请不吝赐教，谢谢</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="http://vickyqi.com/2013/11/18/Hadoop%20JobTracker%E6%8F%90%E4%BA%A4job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/">上一篇文章说到了jobTracker中]]>
    </summary>
    
      <category term="FairScheduler" scheme="http://vickyqi.com/tags/FairScheduler/"/>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="MapReduce" scheme="http://vickyqi.com/tags/MapReduce/"/>
    
      <category term="任务调度" scheme="http://vickyqi.com/tags/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Hadoop JobTracker提交job源码浅析]]></title>
    <link href="http://vickyqi.com/2013/11/20/Hadoop%20JobTracker%E6%8F%90%E4%BA%A4job%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/"/>
    <id>http://vickyqi.com/2013/11/20/Hadoop JobTracker提交job源码浅析/</id>
    <published>2013-11-19T16:29:00.000Z</published>
    <updated>2015-10-31T06:46:48.000Z</updated>
    <content type="html"><![CDATA[<p><a href="http://vickyqi.com/2013/11/18/hadoop%20job%E5%88%9D%E5%A7%8B%E5%8C%96%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/">上一篇文章说</a>到jobClient提交job的过程，这篇文章是接着上一篇文章继续写的。</p>
<p>上一篇说到<code>jobSubmitClient.submitJob( jobId, submitJobDir.toString(), jobCopy.getCredentials())</code>这里，这里就是jobTracker进行job的提交过程，还有一个JobSubmissionProtocol的实现是LocalJobRunner，这是本地执行的时候使用的，真正集群运行Job还是使用的jobTracker，所以只看jobTracker类的submitJob。</p>
<h4 id="jobTracker-submitJob()："><strong>jobTracker.submitJob()：</strong></h4><p>第一句就是checkJobTrackerState()这个是检查jobTracker状态，是否运行中，这里说一句，jobTracker是在hadoop集群启动的时候启动的，也就是在执行start-all或者start-mapred的时候启动，启动的时候会调用JobTracker的main方法，然后在jps的时候就可以看见一个jobTracker的进程了。下面来看一下JobTracker.main()方法。</p>
<h4 id="JobTracker-main()："><strong>JobTracker.main()：</strong></h4><p>第一句是JobTracker tracker = startTracker(new JobConf())，这是实例化一个jobTracke实例。</p>
<h4 id="JobTracker-startTracker()："><strong>JobTracker.startTracker()：</strong></h4><p>result = new JobTracker(conf, identifier)，实例化一个jobTracker对象，在实例化的时候会做很多事，所以还是进去瞅瞅。</p>
<h4 id="JobTracker-JobTracker()："><strong>JobTracker.JobTracker()：</strong></h4><p>实例化的时候会初始化很多参数，记也记不住，主要看下实例化taskScheduler的内容：<br><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">Class</span>&lt;? extends TaskScheduler&gt; schedulerClass     =<span class="keyword">conf</span>.getClass(<span class="string">"mapred.jobtracker.taskScheduler"</span>,JobQueueTaskScheduler.<span class="keyword">class</span>, TaskScheduler.<span class="keyword">class</span>);</span><br><span class="line">taskScheduler = (TaskScheduler) ReflectionUtils.newInstance(schedulerClass, <span class="keyword">conf</span>)</span><br></pre></td></tr></table></figure></p>
<p>这两句就是根据配置文件设置的taskScheduler类名，通过反射获得对应的taskScheduler对象，在实例化的时候虽然不同的TaskScheduler具体操作不一样，但是统一的都会初始化一个JobListener对象，这个对象就是后面将要监听job的listener。剩下的内容就不说了。回到JobTracker.startTracker()方法。</p>
<h4 id="JobTracker-JobTracker()：-1"><strong>JobTracker.JobTracker()：</strong></h4><p>在实例化jobTracker之后，会执行<code>result.taskScheduler.setTaskTrackerManager(result)</code>，这个就是将jobTracker对象设置给taskScheduler。后面就什么了，现在可以回到main方法了<br><figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">public <span class="keyword">static</span> <span class="type">JobTracker</span> startTracker(<span class="type">JobConf</span> conf, <span class="type">String</span> identifier, boolean initialize) </span><br><span class="line">  throws <span class="type">IOException</span>, <span class="type">InterruptedException</span> &#123;</span><br><span class="line">    <span class="type">DefaultMetricsSystem</span>.initialize(<span class="string">"JobTracker"</span>);</span><br><span class="line">    <span class="type">JobTracker</span> <span class="literal">result</span> = null;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="literal">result</span> = new <span class="type">JobTracker</span>(conf, identifier);</span><br><span class="line">        <span class="literal">result</span>.taskScheduler.setTaskTrackerManager(<span class="literal">result</span>);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125; catch (<span class="type">VersionMismatch</span> e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">      &#125; catch (<span class="type">BindException</span> e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">      &#125; catch (<span class="type">UnknownHostException</span> e) &#123;</span><br><span class="line">        throw e;</span><br><span class="line">      &#125; catch (<span class="type">AccessControlException</span> ace) &#123;</span><br><span class="line">        // <span class="keyword">in</span> <span class="keyword">case</span> <span class="keyword">of</span> jobtracker <span class="keyword">not</span> having right access</span><br><span class="line">        // bail <span class="keyword">out</span></span><br><span class="line">        throw ace;</span><br><span class="line">      &#125; catch (<span class="type">IOException</span> e) &#123;</span><br><span class="line">        <span class="type">LOG</span>.warn(<span class="string">"Error starting tracker: "</span> + </span><br><span class="line">                 <span class="type">StringUtils</span>.stringifyException(e));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="type">Thread</span>.sleep(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="literal">result</span> != null) &#123;</span><br><span class="line">      <span class="type">JobEndNotifier</span>.startNotifier();</span><br><span class="line">      <span class="type">MBeans</span>.register(<span class="string">"JobTracker"</span>, <span class="string">"JobTrackerInfo"</span>, <span class="literal">result</span>);</span><br><span class="line">      <span class="keyword">if</span>(initialize == <span class="literal">true</span>) &#123;</span><br><span class="line">        <span class="literal">result</span>.setSafeModeInternal(<span class="type">SafeModeAction</span>.<span class="type">SAFEMODE_ENTER</span>);</span><br><span class="line">        <span class="literal">result</span>.initializeFilesystem();</span><br><span class="line">        <span class="literal">result</span>.setSafeModeInternal(<span class="type">SafeModeAction</span>.<span class="type">SAFEMODE_LEAVE</span>);</span><br><span class="line">        <span class="literal">result</span>.initialize();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">result</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="JobTracker-main()：-1"><strong>JobTracker.main()：</strong></h4><p>在实例化jobTracker之后，会调用tracker.offerService()方法，之后main方法就没什么了，下面看看tracker.offerService()这个方法。<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> main(<span class="keyword">String</span> argv[]</span><br><span class="line">                          ) <span class="keyword">throws</span> IOException, InterruptedException &#123;</span><br><span class="line">    StringUtils.startupShutdownMessage(JobTracker.class, argv, LOG);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="keyword">if</span>(argv.length == <span class="number">0</span>) &#123;</span><br><span class="line">        JobTracker tracker = startTracker(<span class="keyword">new</span> JobConf());</span><br><span class="line">        tracker.offerService();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (<span class="string">"-dumpConfiguration"</span>.equals(argv[<span class="number">0</span>]) &amp;&amp; argv.length == <span class="number">1</span>) &#123;</span><br><span class="line">          dumpConfiguration(<span class="keyword">new</span> PrintWriter(System.out));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">          System.out.<span class="built_in">println</span>(<span class="string">"usage: JobTracker [-dumpConfiguration]"</span>);</span><br><span class="line">          System.<span class="built_in">exit</span>(-<span class="number">1</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125; <span class="keyword">catch</span> (Throwable e) &#123;</span><br><span class="line">      LOG.fatal(StringUtils.stringifyException(e));</span><br><span class="line">      System.<span class="built_in">exit</span>(-<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="JobTracker-offerService()："><strong>JobTracker.offerService()：</strong></h4><p>这个方法中有一些其他东西，略掉，只看taskScheduler.start()这个方法，因为这里只是想分析下JobTracker提交job的过程，所以省去很多复杂的东西。</p>
<h4 id="taskScheduler-start()："><strong>taskScheduler.start()：</strong></h4><p>这个方法就是启动TaskScheduler，这个方法不同taskScheduler也不同，但是统一的还是会有一个<code>taskTrackerManager.addJobInProgressListener(jobListener)</code>这个操作，taskTrackerManager就是jobTracker（第5步），这句的意思是为jobTracker添加jobListener，用来监听job的。这句的内部就是调用jobTracker的jobInProgressListeners集合的add(listener)方法。<br>到这里可以说看完了整个JobTracker的启动过程，虽然很浅显，但是对于后面将要分析的内容，这些就够了。下面来看看job的提交过程，也就是jobTracker的submit()方法。</p>
<h4 id="jobTracker-submit()："><strong>jobTracker.submit()：</strong></h4><p>第一步是checkSafeMode()，检查是否在安全模式，在安全模式则抛出异常。然后执行<code>jobInfo = new JobInfo(jobId, new Text(ugi.getShortUserName()),new Path(jobSubmitDir)</code>，生成一个jobInfo对象，jobInfo主要保存job的id,user,jobSubmitDir（也就是job的任务目录，上一篇文章提到）。接着是判断job是否可被recovered（job失败的时候尝试再次执行），如果允许的话(默认允许)，则将jobInfo对象序列化到job-info文件中。接着到达最关键的地方，<code>job = new JobInProgress(this, this.conf, jobInfo, 0, ts)</code>，为job实例化一个JobInProgress对象，这个对象将会对job以后的所有情况进行负责，如初始化，执行等。下面看看JobInProgress对象的初始化操作。</p>
<h4 id="JobInProgress："><strong>JobInProgress：</strong></h4><p>这里看下将job.xml下载到本地的操作。然后就是job的队列信息，默认的队列名是default，<code>Queue queue = this.jobtracker.getQueueManager().getQueue(queueName)</code>，这个主要是根据hadoop所使用的taskScheduler有关，具体不研究。剩下的是一些参数的初始化，如map的数目，reduce的数目等。这里还有个设置job的优先级的，默认是normal。<code>this.priority = conf.getJobPriority();this.status.setJobPriority(this.priority);</code>还有检查taskLimit的操作，就是检查map+reduce的任务数是否超出mapred.jobtracker.maxtasks.per.job设置的值，默认是-1，就是没有限制的意思。回到jobTracker.submit()方法<br><figure class="highlight ceylon"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">this</span>.localJobFile = <span class="annotation">default</span><span class="number">_</span>conf.getLocalPath(JobTracker.SUBDIR</span><br><span class="line">          +<span class="string">"/"</span>+jobId + <span class="string">".xml"</span>);</span><br><span class="line">      Path jobFilePath = JobSubmissionFiles.getJobConfPath(jobSubmitDir);</span><br><span class="line">      jobFile = jobFilePath.toString();</span><br><span class="line">      fs.copyToLocalFile(jobFilePath, localJobFile);</span><br><span class="line">      conf = <span class="keyword">new</span> JobConf(localJobFile);</span><br></pre></td></tr></table></figure></p>
<h4 id="jobTracker-submit()：-1"><strong>jobTracker.submit()：</strong></h4><p>实例化JobInProgress之后，会根据jobProfile获取job的队列信息，并判断相应的队列是否在运行中，不在则任务失败。然后检查内存情况checkMemoryRequirements(job)，再调用taskScheduler的<code>taskScheduler.checkJobSubmission(job)</code>检查任务提交情况（具体是啥玩意，不太情况）。接下来就是执行status = addJob(jobId, job)，为Job设置listener。</p>
<h4 id="jobTracker-addJob()："><strong>jobTracker.addJob()：</strong></h4><p>前面说过，在初始化jobTracker的时候会实例化taskScheduler，然后调用taskScheduler的start()方法，为jobTracker添加JobListener对象，所以这里的JobInProgressListener对象就是相应的taskScheduler的JobListener，这里为job添加了JobListener。<br><figure class="highlight sml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">private synchronized <span class="type">JobStatus</span> addJob(<span class="type">JobID</span> jobId, <span class="type">JobInProgress</span> job) </span><br><span class="line">  throws <span class="type">IOException</span> &#123;</span><br><span class="line">    totalSubmissions++;</span><br><span class="line"></span><br><span class="line">    synchronized (jobs) &#123;</span><br><span class="line">      synchronized (taskScheduler) &#123;</span><br><span class="line">        jobs.put(job.getProfile<span class="literal">()</span>.getJobID<span class="literal">()</span>, job);</span><br><span class="line">        for (<span class="type">JobInProgressListener</span> listener : jobInProgressListeners) &#123;</span><br><span class="line">          listener.jobAdded(job);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    myInstrumentation.submitJob(job.getJobConf<span class="literal">()</span>, jobId);</span><br><span class="line">    job.getQueueMetrics<span class="literal">()</span>.submitJob(job.getJobConf<span class="literal">()</span>, jobId);</span><br><span class="line"></span><br><span class="line">    <span class="type">LOG</span>.info(<span class="string">"Job "</span> + jobId + <span class="string">" added successfully for user '"</span> </span><br><span class="line">             + job.getJobConf<span class="literal">()</span>.getUser<span class="literal">()</span> + <span class="string">"' to queue '"</span> </span><br><span class="line">             + job.getJobConf<span class="literal">()</span>.getQueueName<span class="literal">()</span> + <span class="string">"'"</span>);</span><br><span class="line">    <span class="type">AuditLogger</span>.logSuccess(job.getUser<span class="literal">()</span>, </span><br><span class="line">        <span class="type">Operation</span>.<span class="type">SUBMIT_JOB</span>.name<span class="literal">()</span>, jobId.toString<span class="literal">()</span>);</span><br><span class="line">    return job.getStatus<span class="literal">()</span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<p>到这里整个JobTracker的job提交过程就结束了，中间很多东西没有深入去研究，只是浅显的了解了下，如有错误，请指出，谢谢</p>
]]></content>
    <summary type="html">
    <![CDATA[<p><a href="http://vickyqi.com/2013/11/18/hadoop%20job%E5%88%9D%E5%A7%8B%E5%8C%96%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/">上一篇文章说</a>到jobClient]]>
    </summary>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="JobTracker" scheme="http://vickyqi.com/tags/JobTracker/"/>
    
      <category term="MapReduce" scheme="http://vickyqi.com/tags/MapReduce/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[hadoop job初始化源码浅析]]></title>
    <link href="http://vickyqi.com/2013/11/18/hadoop%20job%E5%88%9D%E5%A7%8B%E5%8C%96%E6%BA%90%E7%A0%81%E6%B5%85%E6%9E%90/"/>
    <id>http://vickyqi.com/2013/11/18/hadoop job初始化源码浅析/</id>
    <published>2013-11-18T15:59:00.000Z</published>
    <updated>2015-10-31T06:37:20.000Z</updated>
    <content type="html"><![CDATA[<p>hadoop的job提交过程相对来说还是有点复杂的，所以在学习源码的时候会显得有些乱，时常看了后面忘了前面，所以在看了多遍之后决定用文章的方式记录下来，一边自己下次再看的时候能够清晰些，同时也为初次接触这方面源码的同学提供一些帮助吧。希望自己可以写的足够详细。(本文针对hadoop1.2.1)</p>
<h4 id="job-waitForCompletion："><strong>job.waitForCompletion</strong>：</h4><p>一般情况下我们提交一个job都是通过job.waitForCompletion方法提交，该方法内部会调用job.submit()方法<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">boolean</span> <span class="title">waitForCompletion</span><span class="params">(<span class="keyword">boolean</span> verbose</span><br><span class="line">                                   )</span> <span class="keyword">throws</span> IOException, InterruptedException,</span><br><span class="line">                                            ClassNotFoundException </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (state == JobState.DEFINE) &#123;</span><br><span class="line">      submit();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (verbose) &#123;</span><br><span class="line">      jobClient.monitorAndPrintJob(conf, info);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      info.waitForCompletion();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">return</span> <span class="title">isSuccessful</span><span class="params">()</span></span>;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="job-submit()："><strong>job.submit()：</strong></h4><p>在submit中会调用setUseNewAPI()，setUseNewAPI()这个方法主要是判断是使用新的api还是旧的api，之后会调用connect()方法，该方法主要是实例化jobClient，然后会调用<code>jobClient.submitJobInternal(conf)</code>这个方法进行job的提交。<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">submit</span><span class="params">()</span> <span class="keyword">throws</span> IOException, InterruptedException, </span><br><span class="line">                              ClassNotFoundException </span>&#123;</span><br><span class="line">    ensureState(JobState.DEFINE);</span><br><span class="line">    setUseNewAPI();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Connect to the JobTracker and submit the job</span></span><br><span class="line">    connect();</span><br><span class="line">    info = jobClient.submitJobInternal(conf);</span><br><span class="line">    <span class="keyword">super</span>.setJobID(info.getID());</span><br><span class="line">    state = JobState.RUNNING;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="jobClient-submitJobInternal()："><strong>jobClient.submitJobInternal()：</strong></h4><p>这个方法会将job运行时所需的所有文件上传到jobTarcker文件系统（一般是hdfs）中，同时进行备份（备份数默认是10，通过mapred.submit.replication变量可以设置），这个方法需要深入进行解读。</p>
<h4 id="JobSubmissionFiles-getStagingDir："><strong>JobSubmissionFiles.getStagingDir：</strong></h4><p>这个方法是在jobClient.submitJobInternal()最先调用的，这个方法主要是获取一个job提交的根目录，主要是通过<code>Path stagingArea = client.getStagingAreaDir();</code>方法获得，这个方法最终会调用<code>jobTracker.getStagingAreaDirInternal()</code>方法，代码如下：<br><figure class="highlight processing"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">String</span> getStagingAreaDirInternal(<span class="keyword">String</span> user) <span class="keyword">throws</span> IOException &#123;</span><br><span class="line">   <span class="keyword">final</span> Path stagingRootDir =</span><br><span class="line">     <span class="keyword">new</span> Path(conf.<span class="built_in">get</span>(<span class="string">"mapreduce.jobtracker.staging.root.dir"</span>,</span><br><span class="line">           <span class="string">"/tmp/hadoop/mapred/staging"</span>));</span><br><span class="line">   <span class="keyword">final</span> FileSystem fs = stagingRootDir.getFileSystem(conf);</span><br><span class="line">   <span class="keyword">return</span> fs.makeQualified(<span class="keyword">new</span> Path(stagingRootDir,</span><br><span class="line">                             user+<span class="string">"/.staging"</span>)).toString();</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<p>在获取了stagingDir之后会执行<code>JobID jobId = jobSubmitClient.getNewJobId();</code>为job获取一个jobId，然后执行<code>Path submitJobDir = new Path(jobStagingArea,jobId.toString());</code>获得该job提交的路径，也就是在stagingDir目录下建一个以jobId为文件名的目录。有了submitJobDir之后就可以将job运行所需的全部文件上传到对应的目录下了，具体是调用<code>jobClient.copyAndConfigureFiles(jobCopy, submitJobDir)</code>这个方法。</p>
<h4 id="jobClient-copyAndConfigureFiles(jobCopy,_submitJobDir)："><strong>jobClient.copyAndConfigureFiles(jobCopy, submitJobDir)：</strong></h4><p>这个方法最终调用<code>jobClient.copyAndConfigureFiles(job, jobSubmitDir, replication);</code>这个方法实现文件上传。</p>
<h4 id="jobClient-copyAndConfigureFiles(job,_jobSubmitDir,_replication)："><strong>jobClient.copyAndConfigureFiles(job, jobSubmitDir, replication)：</strong></h4><p>这个方法首先获取用户在使用命令执行job的时候所指定的-libjars, -files, -archives文件，对应的conf配置参数是tmpfiles tmpjars tmparchives，这个过程是在ToolRunner.run()的时候进行解析的，当用户指定了这三个参数之后，会将这三个参数对应的文件都上传到hdfs上，下面我们具体看一个参数的处理：tmpfiles（其他两个基本相同）</p>
<h4 id="jobClient处理tmpfiles："><strong>jobClient处理tmpfiles：</strong></h4><p>该方法会将tmpfiles参数值按‘，’分割，然后将每一个文件上传到hdfs，其中如何文件的路径本身就在hdfs中，那么将不进行上传操作，上传操作只针对文件不在hdfs中的文件。调用的方法是：<code>Path newPath = copyRemoteFiles(fs,filesDir, tmp, job, replication)</code>，该方法内部使用的是<code>FileUtil.copy(remoteFs, originalPath, jtFs, newPath, false, job)</code>方法将文件上传至hdfs，注意此处的remoteFs和jtFs，remoteFs就是需上传文件的原始文件系统，jtFs则是jobTracker的文件系统（hdfs）。在文件上传至hdfs之后，会执行<code>DistributedCache.createSymlink(job)</code>这个方法，这个方法是创建一个别名(好像是这么个名字)，这里需要注意的是tmpfiles和tmparchives都会创建别名，而tmpjars则不会，个人认为tmpjars则jar文件，不是用户在job运行期间调用，所以不需要别名，而tmpfiles和tmparchives则在job运行期间用户可能会调用，所以使用别名可以方便用户调用。<br>将这三个参数指定的文件上传到hdfs之后，需要将job的jar文件上传到hdfs，名称为submitJobDir/job.jar，使用<code>fs.copyFromLocalFile(originalJarFile, submitJarFile)</code>上传即可。<br>到这里<code>jobClient.copyAndConfigureFiles(jobCopy,submitJobDir)</code>方法就完成了，期间丢了<br><code>jobClient.copyAndConfigureFiles(jobCopy,submitJobDir)</code>;<br><code>TrackerDistributedCacheManager.determineTimestampsAndCacheVisibilities(job)</code>;<br><code>TrackerDistributedCacheManager.getDelegationTokens(job,job.getCredentials())</code><br>三个方法，这三个方法是进行一些cached archives and files的校验和保存其时间戳和权限内容。</p>
<p>继续我们的<code>jobClient.submitJobInternal()</code>方法，这之后会根据我们设置的outputFormat类执行<code>output.checkOutputSpecs(context)</code>，进行输出路径的检验，主要是保证输出路径不存在，存在会抛出异常。这之后就是对输入文件进行分片操作了，<code>writeSplits(context, submitJobDir)</code>。</p>
<h4 id="jobClient-writeSplits()："><strong>jobClient.writeSplits()：</strong></h4><p>这个方法内部会根据我们之前判断的使用new-api还是old-api分别进行分片操作，我们只看new-api的分片操作。</p>
<figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">int</span> <span class="title">writeSplits</span><span class="params">(org.apache.hadoop.mapreduce.JobContext job,</span><br><span class="line">      Path jobSubmitDir)</span> <span class="keyword">throws</span> IOException,</span><br><span class="line">      InterruptedException, ClassNotFoundException </span>&#123;</span><br><span class="line">    JobConf jConf = (JobConf)job.getConfiguration();</span><br><span class="line">    <span class="keyword">int</span> maps;</span><br><span class="line">    <span class="keyword">if</span> (jConf.getUseNewMapper()) &#123;</span><br><span class="line">      maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      maps = writeOldSplits(jConf, jobSubmitDir);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> maps;</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<h4 id="jobClient-writeNewSplits()："><strong>jobClient.writeNewSplits()：</strong></h4><p>这个方法主要是根据我们设置的inputFormat.class通过反射获得inputFormat对象，然后调用inputFormat对象的getSplits方法，当获得分片信息之后调用JobSplitWriter.createSplitFiles方法将分片的信息写入到submitJobDir/job.split文件中。<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T extends InputSplit&gt;</span><br><span class="line"> int writeNewSplits(JobContext job, Path jobSubmitDir) throws IOException,</span><br><span class="line">     InterruptedException, ClassNotFoundException &#123;</span><br><span class="line">   Configuration conf = job.getConfiguration();</span><br><span class="line">   InputFormat<span class="preprocessor">&lt;?</span>, <span class="preprocessor">?&gt;</span> input =</span><br><span class="line">     ReflectionUtils.newInstance(job.getInputFormatClass(), conf);</span><br><span class="line"></span><br><span class="line">   <span class="keyword">List</span>&lt;InputSplit&gt; splits = input.getSplits(job);</span><br><span class="line">   T[] <span class="keyword">array</span> = (T[]) splits.toArray(<span class="keyword">new</span> InputSplit[splits.size()]);</span><br><span class="line"></span><br><span class="line">   <span class="comment">// sort the splits into order based on size, so that the biggest</span></span><br><span class="line">   <span class="comment">// go first</span></span><br><span class="line">   Arrays.sort(<span class="keyword">array</span>, <span class="keyword">new</span> SplitComparator());</span><br><span class="line">   JobSplitWriter.createSplitFiles(jobSubmitDir, conf,</span><br><span class="line">       jobSubmitDir.getFileSystem(conf), <span class="keyword">array</span>);</span><br><span class="line">   <span class="keyword">return</span> <span class="keyword">array</span>.length;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p>
<h4 id="JobSplitWriter-createSplitFiles："><strong>JobSplitWriter.createSplitFiles：</strong></h4><p>这个方法的作用就是讲分片信息写入到submitJobDir/job.split文件中，方法内部调用JobSplitWriter.writeNewSplits进行写操作</p>
<h4 id="JobSplitWriter-writeNewSplits："><strong>JobSplitWriter.writeNewSplits：</strong></h4><p>该方法具体对每一个InputSplit对象进行序列化写入到输出流中，具体每个InputSplit对象写入的信息包括：<code>split.getClass().getName()，serializer.serialize(split)</code>将整个对象序列化。然后将InputSplit对象的locations信息放入SplitMetaInfo对象中，同时还包括InputSpilt元信息在job.split文件中的偏移量，该InputSplit的长度，再将SplitMetaInfo对象。然后调用<code>JobSplitWriter.writeJobSplitMetaInfo()</code>方法将SplitMetaInfo对象写入submitJobDir/job.splitmetainfo文件中。</p>
<h4 id="JobSplitWriter-writeJobSplitMetaInfo()："><strong>JobSplitWriter.writeJobSplitMetaInfo()：</strong></h4><p>将SplitMetaInfo对象写入submitJobDir/job.splitmetainfo文件中，具体写入的信息包括：JobSplit.META_SPLIT_FILE_HEADER，splitVersion，allSplitMetaInfo.length（SplitMetaInfo对象的个数，一个split对应一个SplitMetaInfo），然后分别将所有的SplitMetaInfo对象序列化到输出流中，到此文件的分片工作完成。</p>
<h4 id="继续回头看jobClient-submitJobInternal()方法："><strong>继续回头看jobClient.submitJobInternal()方法：</strong></h4><p>在上一步进行分片操作之后，或返回切片的数目，据此设定map的数量，所以在job中设置的map数量是没有用的。</p>
<h4 id="继续往下走："><strong>继续往下走：</strong></h4><figure class="highlight lasso"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">String</span> <span class="built_in">queue</span> = jobCopy<span class="built_in">.</span>getQueueName();</span><br><span class="line">          AccessControlList acl = jobSubmitClient<span class="built_in">.</span>getQueueAdmins(<span class="built_in">queue</span>);</span><br><span class="line">          jobCopy<span class="built_in">.</span><span class="built_in">set</span>(QueueManager<span class="built_in">.</span>toFullPropertyName(<span class="built_in">queue</span>,</span><br><span class="line">              QueueACL<span class="built_in">.</span>ADMINISTER_JOBS<span class="built_in">.</span>getAclName()), acl<span class="built_in">.</span>getACLString());</span><br></pre></td></tr></table></figure>
<p>这三句话是获得job对应的任务队列信息，这里涉及到hadoop的作业调度内容，就不深入研究了</p>
<h4 id="继续："><strong>继续：</strong></h4><p>下面就是讲job的配置文件信息(jobConf对象)写入到xml文件中，以便用户查看，具体文件是：submitJobDir/job.xml，通过jobCopy.writeXml(out)方法，<br>方法比较简单，就是写xml文件。下面就进入到jobTracker提交任务环节了，status = jobSubmitClient.submitJob(jobId, submitJobDir.toString(), jobCopy.getCredentials())，<br>就到这吧，后面下次再慢慢研究。<br>总结下：在用户提交job之后，第一步主要是jobClient对job进行一些必要的文件上传操作，主要包括：</p>
<pre><code><span class="number">1.</span> 为job生成一个jobId，然后获得job提交的stagingDir，根据jobId获得submitJobDir，之后所有的job运行时文件豆浆保存在此目录下
<span class="number">2.</span> 将用户在命令行通过-libjars, -files, -archives指定的文件上传到jobTracker的文件系统中，并将job.jar上传到hdfs中
<span class="number">3.</span> 校验输出路径
<span class="number">4.</span> 进行输入文件的分片操作，并将分片信息写入submitJobDir下的相应文件中，有两个文件：job.split以及job.splitmetainfo
<span class="number">5.</span> 将job的配置参数(jobConf对象)写入到job.xml文件中
</code></pre><hr>
<p>这就是jobClient提交job的全部过程，如有遗漏下面评论指出，谢谢</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>hadoop的job提交过程相对来说还是有点复杂的，所以在学习源码的时候会显得有些乱，时常看了后面忘了前面，所以在看了多遍之后决定用文章的方式记录下来，一边自己下次再看的时候能够清晰些，同时也为初次接触这方面源码的同学提供一些帮助吧。希望自己可以写的足够详细。(本文针对ha]]>
    </summary>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="JobClient" scheme="http://vickyqi.com/tags/JobClient/"/>
    
      <category term="MapReduce" scheme="http://vickyqi.com/tags/MapReduce/"/>
    
      <category term="源码" scheme="http://vickyqi.com/tags/%E6%BA%90%E7%A0%81/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[windows环境下使用MyEclipse调用hadoop集群]]></title>
    <link href="http://vickyqi.com/2013/09/22/windows%E7%8E%AF%E5%A2%83%E4%B8%8B%E4%BD%BF%E7%94%A8MyEclipse%E8%B0%83%E7%94%A8hadoop%E9%9B%86%E7%BE%A4/"/>
    <id>http://vickyqi.com/2013/09/22/windows环境下使用MyEclipse调用hadoop集群/</id>
    <published>2013-09-22T15:03:00.000Z</published>
    <updated>2015-10-25T08:24:44.000Z</updated>
    <content type="html"><![CDATA[<p>之前看网上说要想在windows下访问hadoop集群需要安装cygwin，但是我嫌安装这东西麻烦，所以没弄，但是今天根据linux下使用hadoop插件的eclipse建的一个项目来在Myeclipse下建了一个同样的项目，引入同样的jar包，然后执行调用Hadoop的程序竟然可以执行，大喜。不知道是我一开始理解错了，还是什么原因，总之现在我的windows不用安装cygwin也能通过Myeclipse调用hadoop了。</p>
<p>具体方法是：<br>1.在MyEclipse下新建一个java project<br>2.将hadoop/lib下的所有jar包加到project中，可以直接新建一个src folder，也可以添加外面jar引用<br>3.将hadoop目录下的以hadoop开头的几个jar也引入到project<br>4.在程序中调用hdfs时需将namenode hostname改成namenode ip<br><figure class="highlight dart"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">String</span> dfsUrl = <span class="string">"hdfs://192.168.1.8:9000"</span>;</span><br><span class="line">fs = FileSystem.<span class="literal">get</span>(URI.create(dfsUrl), <span class="keyword">new</span> Configuration());</span><br></pre></td></tr></table></figure></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>之前看网上说要想在windows下访问hadoop集群需要安装cygwin，但是我嫌安装这东西麻烦，所以没弄，但是今天根据linux下使用hadoop插件的eclipse建的一个项目来在Myeclipse下建了一个同样的项目，引入同样的jar包，然后执行调用Hadoop的程]]>
    </summary>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[RedHat安装Hadoop0.20.2小集群]]></title>
    <link href="http://vickyqi.com/2013/09/18/RedHat%E5%AE%89%E8%A3%85Hadoop0.20.2%E5%B0%8F%E9%9B%86%E7%BE%A4/"/>
    <id>http://vickyqi.com/2013/09/18/RedHat安装Hadoop0.20.2小集群/</id>
    <published>2013-09-18T15:37:00.000Z</published>
    <updated>2015-10-25T08:40:20.000Z</updated>
    <content type="html"><![CDATA[<p>在安装Hadoop之前先确保每台机器都装有jdk，版本什么路径什么的最好一样，然后配置好master对其他slavers的SSH无密码访问(可以参考：<a href="http://vickyqi.com/2013/09/17/Linux%E4%B8%8B%E9%85%8D%E7%BD%AESSH%E6%97%A0%E5%AF%86%E7%A0%81%E8%AE%BF%E9%97%AE/">Linux下配置SSH无密码访问</a>)</p>
<p>确保上述条件满足之后就可以开始安装Hadoop了</p>
<p>首先我的版本信息：</p>
<pre>
LinuxOS：RedHat Enterprise 6.0 两台（VMWare虚拟机），一台master，两台slave，master也是slave
Hadoop：0.20.2<下载地址：http: archive.apache.org="" dist="" hadoop="" core="">
系统配置：
master 主机名：rh01 ip:192.168.1.8
slave    主机名：rh02 ip:192.168.1.9
得确保机器之间能够互相访问
</下载地址：http:></pre>

<p>下面开始Hadoop安装</p>
<ol>
<li>将下载hadoop文件解压，tar文件使用tar -zxvf file_name    可以在后面加上-C指定解压路径，最好放到一个固定地方，所有机器路径必须保证一直</li>
<li>解压之后在hadoop-0.20.2(安装根目录)下会看到一个conf文件夹，所有的hadoop配置都在这个文件夹下，也是最主要的</li>
<li><p>配置Hadoop环境变量：</p>
 <pre>
export JAVA_HOME=/develop/java/jdk1.7.0_25
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export HADOOP_HOME=/develop/hadoop/hadoop-0.20.2
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin
</pre>
</li>
<li><p>配好环境变量之后可以选择重启机器让prfile文件生效，或者执行source /etc/profile也可</p>
</li>
<li><p>下面开始配置Hadoop配置文件，有hadoop-env.sh，core-site.xml，hdfs-site.xml，mapred-site.xml，masters，slaves6个文件需要修改</p>
<ul>
<li><p>hadoop-env.sh：在hadoop-env.sh后面添加JAVA_HOME值，这个值被注释掉了，可以直接去掉注释然后将值改成你jdk安装路径即可</p>
</li>
<li><p>core-site.xml：在configuration节点中添加，其中ip为master ip，9000为端口，注意必须是以hdfs开头，不是http。</p>
<figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="variable">&lt;property&gt;</span></span><br><span class="line">	<span class="variable">&lt;name&gt;</span>fs.<span class="keyword">default</span>.name<span class="variable">&lt;/name&gt;</span></span><br><span class="line">	<span class="variable">&lt;value&gt;</span>hdfs://<span class="number">192.168</span>.<span class="number">1.8</span>:<span class="number">9000</span><span class="variable">&lt;/value&gt;</span></span><br><span class="line"><span class="variable">&lt;/property&gt;</span></span><br><span class="line"><span class="variable">&lt;property&gt;</span></span><br><span class="line">	<span class="variable">&lt;name&gt;</span>hadoop.tmp.dir<span class="variable">&lt;/name&gt;</span></span><br><span class="line">	<span class="variable">&lt;value&gt;</span>/develop/hadoop/tmp<span class="variable">&lt;/value&gt;</span></span><br><span class="line"><span class="variable">&lt;/property&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>hdfs-site.xml：在configuration节点中添加，其中dfs.replication值需要注意，如果你的salves机器数&lt;3那就写1或者2，大于2就写3就可以了，我这里是两个slave，所以写2。</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- dfs.replication，设置数据块的复制次数，默认是3，如果slave节点数少于3，则写成相应的1或者2 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="title">value</span>&gt;</span>2<span class="tag">&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span>    </span><br><span class="line">        <span class="comment">&lt;!-- DFS中存储文件命名空间信息的目录 --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.name.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>/develop/hadoop/dfs/name<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span>    </span><br><span class="line">	<span class="comment">&lt;!-- DFS中存储文件数据的目录 --&gt;</span>    </span><br><span class="line">	<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.data.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>     </span><br><span class="line">	<span class="tag">&lt;<span class="title">value</span>&gt;</span>/develop/hadoop/dfs/data<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span>    </span><br><span class="line">	<span class="comment">&lt;!-- 是否对DFS中的文件进行权限控制(测试中一般用false)--&gt;</span>    </span><br><span class="line">	<span class="tag">&lt;<span class="title">name</span>&gt;</span>dfs.permissions<span class="tag">&lt;/<span class="title">name</span>&gt;</span>    </span><br><span class="line">	<span class="tag">&lt;<span class="title">value</span>&gt;</span>false<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>mapred-site.xml：没有这个文件就新建一个即可，其中mapred.job.tracker 是配置jobtracker，ip为master ip，端口 9001，注意必须是以hdfs开头，不是http</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">configuration</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span>    </span><br><span class="line">        <span class="comment">&lt;!-- JobTracker节点 --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.job.tracker<span class="tag">&lt;/<span class="title">name</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>hdfs://192.168.1.8:9001<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span>    </span><br><span class="line">        <span class="comment">&lt;!-- map/reduce的系统目录（使用的HDFS的路径） --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.system.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>/develop/hadoop/mapred/system<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;<span class="title">property</span>&gt;</span>    </span><br><span class="line">        <span class="comment">&lt;!-- map/reduce的临时目录（可使用“,”隔开，设置多重路径来分摊磁盘IO） --&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">name</span>&gt;</span>mapred.local.dir<span class="tag">&lt;/<span class="title">name</span>&gt;</span>    </span><br><span class="line">        <span class="tag">&lt;<span class="title">value</span>&gt;</span>/develop/hadoop/mapred/local<span class="tag">&lt;/<span class="title">value</span>&gt;</span>    </span><br><span class="line"><span class="tag">&lt;/<span class="title">property</span>&gt;</span>    </span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>master：这个文件中写的是master ip（也有资料说是应该写SecondaryNameNode，新手我们就不管吧，反正只要写master ip就可以了）</p>
  <pre>hosts第一行127.0.0.1后面不要写主机名，也就是HOSTNAME值</pre>
</li>
<li><p>slaves：这个文件写的是slave ip，有几个写几个，分行写，master也可以作为slave节点，同master最好都写ip，不要写hostname</p>
</li>
</ul>
</li>
<li><p>将hadoop安装目录整个copy到所有salve主机上，使用scp -r命令即可，同时也可以将/etc/profile文件也copy过去，反正profile和hadoop都得保证完全一致，路径也是</p>
</li>
<li>到这里配置应该就完成了，再启动hadoop前我们需要先格式化namenode：#hadoop namenode -format，这里如果如果提示没有hadoop命令，则先到profile中确认$HADOOP_HOME/bin加入到path中，其次可以进入到hadoop安装目录下使用:#bin/hadoop namenode -format试试，如果还是不行就那检查你的上面配置的文件是否<br>有错.</li>
<li>格式化成功之后就可以启动hadoop了，可以直接启动start-all.sh（配置完全正确情况下这个命令无论在什么目录下都可以执行），之后就可以看到hadoop启动了，你会发现显示将启动日志保存到一个路径下，这些日志在hadoop安装目录的logs文件夹下，是很重要的，但是当你出错时可以清空logs下所有文件，然后重新启动机器让他生成日志，在查看日志信息，因为日志比较多，看起来就不方便，嘿嘿。如果日志没问题那就OK。</li>
<li>在每台机器上使用：#jps 可以查看hadoop进程情况，启动成功slave应该显示：tasktracker jps datanode三个进程，master显示：jobtracker namenode sencondarynamenode jps要是master也是slave的话会多tasktracker datanode两个进程</li>
<li>一切OK之后可以使用浏览器访问<a href="http://192.168.1.8:50030/" target="_blank" rel="external">http://192.168.1.8:50030/</a> ip是master ip，查看hadoop运行情况，之后可以试着做hadoop自带的小测试，自己去网上找吧</li>
</ol>
<p>我知道一次安装成功可以性很小，你是新手的话，所以会出现各种各样的问题，在这里说下可能会出现的问题吧，也是我遇到的问题<br>java.io.IOException: Call to /192.168.1.8:9000 failed on local exception: java.net.NoRouteToHostException: No route to host<br>（1）hadoop版本问题，劝新手不要一开始就是用2.0版本及以上的，首先2.0的资料较少，其他不是很稳定貌似，配置也比较繁琐，我反正弄了一周没搞好，然后果断换了0.20.2才搞定。<br>（2）如果启动失败，log中显示无法连接master什么的，那问题就出在/etc/hosts文件中，这里配置了主机信息，hosts文件配置有点怪，下面是我的master hosts和slave hosts<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">master：</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::<span class="number">1</span> localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">HOSTNAME=rh01</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.8</span> rh01</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.9</span> rh02</span><br><span class="line"></span><br><span class="line">slave：</span><br><span class="line"><span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span> localhost localhost.localdomain localhost4 localhost4.localdomain4</span><br><span class="line">::<span class="number">1</span> localhost localhost.localdomain localhost6 localhost6.localdomain6</span><br><span class="line">HOSTNAME=rh02</span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.9</span> rh02</span><br><span class="line"></span><br><span class="line"><span class="number">192.168</span><span class="number">.1</span><span class="number">.8</span> rh01</span><br></pre></td></tr></table></figure></p>
<p>注意之处在于</p>
<p><pre><br>（1）hosts第一行127.0.0.1后面不要写主机名，也就是HOSTNAME值<br>（2）在HOSTNAME后面写ip与主机名映射的时候一定要先写本机ip<br>（3）防火墙，这个坑爹的货在hadoop中始终是个麻烦，在启动hadoop之前需要将所有机器防火墙关闭，使用：#service iptables stop，也可以直接使用：#chkconfig iptables off命令设置防火墙不自启动，这样下次防火墙就不会自启动了<br></pre><br>我就总结出这三点可能会影响hadoop启动的，错误都是无法连接主机，要是其他错误那就好好看看conf下的那些配置文件是否有错了</p>
<p>好了，安装吧，启动吧，开心吧，查看吧，失望吧，排错吧，绝望吧，总之坚持住你就能搞定 嘻嘻~~~</p>
<hr>
<p>申明有参考网上其他文章</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在安装Hadoop之前先确保每台机器都装有jdk，版本什么路径什么的最好一样，然后配置好master对其他slavers的SSH无密码访问(可以参考：<a href="http://vickyqi.com/2013/09/17/Linux%E4%B8%8B%E9%85%8D]]>
    </summary>
    
      <category term="Hadoop" scheme="http://vickyqi.com/tags/Hadoop/"/>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Linux" scheme="http://vickyqi.com/tags/Linux/"/>
    
      <category term="Hadoop学习" scheme="http://vickyqi.com/categories/Hadoop%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Linux下配置SSH无密码访问]]></title>
    <link href="http://vickyqi.com/2013/09/17/Linux%E4%B8%8B%E9%85%8D%E7%BD%AESSH%E6%97%A0%E5%AF%86%E7%A0%81%E8%AE%BF%E9%97%AE/"/>
    <id>http://vickyqi.com/2013/09/17/Linux下配置SSH无密码访问/</id>
    <published>2013-09-17T14:43:00.000Z</published>
    <updated>2015-10-25T08:40:44.000Z</updated>
    <content type="html"><![CDATA[<p>网上资料很多，基本都是一样。<br>首先确保你已安装ssh，RedHat自带有openSSH，所以不需要考虑。</p>
<p>第一步：使用  #ssh-keygen -t dsa  ，使用这个命令之后会提示是否输入密码，这里不输入密码，一路enter下去就可以了，最后会在用户目录下的隐藏文件夹.ssh下生成id.dsa和id_dsa.pub两个文件，分别为私钥和公钥。<br>也可以直接使用#ssh -keygen -t dsa -P ‘’ -f ~/.ssh/id_dsa，这样就无需再被问询了。<br>这里说一下SSH加密有两种方式：dsa和rsa，对应的命令一样只是在-t指示加密类型时一个是dsa，另一个是rsa。</p>
<p>第二步：将公钥追加到authorized_keys文件中，也在.ssh目录下，没有也没关系，使用#cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys命令即可。</p>
<p>第三步：将authorized_keys拷贝到其他需要被SSH无密码访问的机器上（注意这里是被访问，也就是如果你想从1无密码访问2，那么就得在1上生成密钥对，然后将公钥丢到2上）</p>
<pre><code>scp ~<span class="regexp">/.ssh/authorized</span>_keys root@(other machine ip)<span class="symbol">:/~/</span>.ssh/
</code></pre><p>scp作用是linux从本机复制文件到远程机器，可以在scp后面加上-r，表示传输文件夹<br>到这里配置就完成了，下面可以测试下是否可以无密码访问，测试方法可以先用本机访问本机，使用#ssh localhost，这里第一次会提示你访问的host无法连接，是否仍继续连接，输入yes，然后输入密码，连接上之后，使用#exit可以退出，在此连接就无需密码了。同样的你可以测试一下连接远程机器（你丢authorized_keys文件的机器），过程和localhost一样。如果可以说明配置成功。</p>
<p>可能出现的问题：有些时候就算都按照步骤一步不错的弄，到最后也无法实现无密码访问，可能的问题是用户问题，我之前也遇到过，在一个普通用户下尝试的，结果不行，然后换成root用户就可以了，两边都是用root。<br>建议新手就直接使用root，可以省很多事，不要怕root权限过高误删什么东西，不然权限会搞死人</p>
<p>希望对其他人有所帮助，我也是参考网上来写的，就当给自己做个笔记吧   嘿嘿</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>网上资料很多，基本都是一样。<br>首先确保你已安装ssh，RedHat自带有openSSH，所以不需要考虑。</p>
<p>第一步：使用  #ssh-keygen -t dsa  ，使用这个命令之后会提示是否输入密码，这里不输入密码，一路enter下去就可以了，最后会在用]]>
    </summary>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Linux" scheme="http://vickyqi.com/tags/Linux/"/>
    
      <category term="SSH" scheme="http://vickyqi.com/tags/SSH/"/>
    
      <category term="Linux学习" scheme="http://vickyqi.com/categories/Linux%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java类加载器]]></title>
    <link href="http://vickyqi.com/2012/05/20/Java%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/"/>
    <id>http://vickyqi.com/2012/05/20/Java类加载器/</id>
    <published>2012-05-20T14:15:00.000Z</published>
    <updated>2015-10-25T06:48:54.000Z</updated>
    <content type="html"><![CDATA[<h4 id="类加载器作用">类加载器作用</h4><p>当JVM开始运作时需要使用当某个类时，就需要将对应类的字段吗加载到内存中，而类加载器正式负责加载这些类的工具。另外若果多次重复使用一个类的字节码时加载器不会多次加载，而是使用内存中的字节码。</p>
<h4 id="主要的类加载器">主要的类加载器</h4><p>我们首先看一下JVM预定义的三种类型类加载器，当一个 JVM 启动的时候，Java 缺省开始使用如下三种类型类装入器：</p>
<ul>
<li>引导（Bootstrap）类加载器：引导类装入器是用本地代码实现的类装入器，它负责将JRE/lib/tr.jar加载到内存中。由于引导类加载器涉及到虚拟机本地实现细节，开发者无法直接获取到启动类加载器的引用，所以不允许直接通过引用进行操作。</li>
<li>标准扩展（Extension）类加载器：扩展类加载器是由 Sun 的 ExtClassLoader（sun.misc.Launcher$ExtClassLoader） 实现的。它负责将JRE/lib/ext/*.jar或者由系统变量 java.ext.dir 指定位置中的类库加载到内存中。开发者可以直接使用标准扩展类加载器。</li>
<li>系统（System）类加载器：系统类加载器是由 Sun 的 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。它负责将系统类路径（CLASSPATH）中指定的类库加载到内存中。开发者可以直接使用系统类加载器。</li>
</ul>
<p>三个类加载器之间的继承关系</p>
<p>BootStrap——负责加载JRE/lib/tr.jar</p>
<p>/|\</p>
<p>ExtClassLoader——负责加载JRE/lib/ext/*.jar</p>
<p>/|\</p>
<p>AppClassLoader——负责加载CLASSPATH所指定的所有jar或目录（SystemClassLoader）</p>
<p><strong>说明：</strong>每个加载器也是一个类，也需要被加载器加载，显然需要有一个最顶级加载器，而且它不需要被加载，这个加载器就是BootStrap加载器，它不是一个类，而是贮存在JVM内核中的一段C++代码，JVM启动会自动执行这段代码。BootStrap加载器负责JRE/lib/tr.jar中的类，当然包括其他加载器。</p>
<h4 id="加载器委托加载机制">加载器委托加载机制</h4><p>在加载类时，当前的类加载器（发起者）首先让其父类去加载，其父类加载器又让父类加载器加载，以此类推，直到提交到最顶级类加载器，即BootStrap加载器为止，这时BootStrap加载器开始加载，若找不到该类，则返回给要求它加载的加载器去加载，直到加载到，若发起者（最先请求加载的类加载器）也找不到该类，则抛出ClassNotFoundException。</p>
<h4 id="类加载器中一些重要方法">类加载器中一些重要方法</h4><ul>
<li><p><strong>方法 loadClass</strong></p>
<p>  ClassLoader.loadClass()是ClassLoader的入口点，程序通过调用该方法进行类的加载。方法签名如下：<strong>Class loadClass( String name, boolean resolve);</strong><br>参数name指定Java虚拟机需要的类的全名(含包名)，比如Foo或者java.lang.Object。<br>参数 resolve指定该类是否需要解析你可以把类的解析理解为完全为运行做好准备。解析一般都不需要。如果Java虚拟机只想知道这个类是否存在或者想知道它的父类的话，解析就完全没有必要了。 在Java1.1和它以前的版本，如果要自定义类加载器,loadClass方法是唯一需要在子类中覆盖的方法.(ClassLoader在Java1.2中有所改变，提供了方法findClass())。</p>
</li>
<li><p><strong>方法findClass()</strong></p>
<p>  Java1.2之后自定义类加载器，除了要继承ClassLoader外，只需要覆写该方法即可。在调用loadClass()时，如果父类加载器找不到，会调用该类加载器的findClass()进行查找类。<br>方法 defineClass<br>defineClass 是ClassLoader中一个很神秘的方法。这个方法通过一个字节数组来构建类实例。这个包含数据的原始字节数组可能来自文件系统，也可能是来自网络。defineClass 表<br>明了Java虚拟机的复杂性，神秘性和平台依赖性-它通过解释字节码把它转化为运行时数据<br>结构，检查有效性等等。但是不用担心，这些都不用你去实现。其实，你根本不能覆盖它，<br>因为该方法被关键字final修饰。<br>方法 findSystemClass<br>findSystemClass方法从本地系统加载文件。它在本地系统寻找类文件，如果找到了，调用<br>defineClass把原始字节数组转化成类对象。这是运行Java应用时Java虚拟机加载类的默认机制。对于自定义类加载器，只有在我们无法加载之后才需要用findSystemClass。 原因很简单: 我们的类加载器负责执行类加载中的某些特定的步骤，但并不是对所有的类。比如，即使我们的类加载器从远程站点加载了某些类，仍然有很多基本的类要从本地系统加载。<br>这些类不是我们关心的，所以我们让Java虚拟机以默认的方式加载他们：从本地系统。这就是findSystemClass做的事情。整个过程大致如下：</p>
<ol>
<li>java虚拟机请求我们自定义的类加载器加载类。</li>
<li>我们检查远程站点是否有这个需要加载的类。</li>
<li>如果有，我们获取这个类。</li>
<li><p>如果没有，我们认为这个是类在基本类库中，调用findSystemClass从文件系统中加载。</p>
<p>在大多数自定义类加载器中，你应该先调用findSystemClass来节省从远程查找的时间。<br>实际上，正如我们将在下一部分看到的，只有当我们确定我们已经自动编译完我们的代码后<br>才允许Java虚拟机从本地文件系统加载类。</p>
</li>
</ol>
</li>
<li><p><strong>方法resolveClass</strong></p>
<p>  正如上面说的，类记载可以分为部分加载（不解析）和完全加载（包括解析）。我们创建自<br>定义类加载器的时候，可能要调用resolveClass。</p>
</li>
<li><p><strong>方法 findLoadedClass</strong></p>
<p>  findLoadedClass实现一个缓存:当要求loadClass来加载一个类的时候，可以先调用这个方法看看这个类是否已经被加载，防止重新加载一个已经被加载的类。这个方法必须先被调用，我们看一下这些方法是如何组织在一起的。</p>
</li>
</ul>
<p>我们的例子实现loadClass执行以下的步骤。（我们不指定通过某种具体的技术获得类文件，-它可能从网络，从压缩包或者动态编译的。无论如何，我们获得的是原始字节码文件）</p>
<ol>
<li>程序调用该类加载器的loadClass()方法。</li>
<li>loadClass()内部调用findLoadedClass检查这个类是否已经加载。</li>
<li>如果没有加载，调用父类加载器（父类再调用父类）加载，加载到，返回这个类。</li>
<li>否则，调用findCLass()方法，加载类。具体代码在findClass()中，执行查找文件，读取，编译等操作，生成字节码，返回。</li>
<li>如果参数resolve为true,调用resolveClass来解析类对象。</li>
<li>如果还没有找到类，抛出一个ClassNotFoundException异常。</li>
</ol>
<p>现在我们看一下ClassLoader中的loadClass()源码：</p>
<figure class="highlight monkey"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">protected synchronized <span class="class"><span class="keyword">Class</span>&lt;?&gt; <span class="title">loadClass</span>(<span class="title">String</span> <span class="title">name</span>, <span class="title">boolean</span> <span class="title">resolve</span>)</span></span><br><span class="line">    throws ClassNotFoundException</span><br><span class="line">    &#123;</span><br><span class="line">    // First, check <span class="keyword">if</span> the <span class="class"><span class="keyword">class</span> <span class="title">has</span> <span class="title">alreadybeen</span> <span class="title">loaded</span></span></span><br><span class="line">    <span class="class"><span class="keyword">Class</span> <span class="title">c</span> = <span class="title">findLoadedClass</span>(<span class="title">name</span>);</span></span><br><span class="line">    <span class="keyword">if</span> (c == <span class="literal">null</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">       <span class="keyword">if</span> (parent !=<span class="literal">null</span>) &#123;</span><br><span class="line">           c = parent.loadClass(name,<span class="literal">false</span>);</span><br><span class="line">       &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">           c =findBootstrapClassOrNull(name);</span><br><span class="line">       &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span>(ClassNotFoundException e) &#123;</span><br><span class="line">                // ClassNotFoundException thrown <span class="keyword">if</span> <span class="class"><span class="keyword">class</span> <span class="title">not</span> <span class="title">found</span></span></span><br><span class="line">                // from the non-<span class="literal">null</span> parent <span class="class"><span class="keyword">class</span> <span class="title">loader</span></span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (c ==<span class="literal">null</span>) &#123;</span><br><span class="line">            // <span class="keyword">If</span> still <span class="keyword">not</span> found, <span class="keyword">then</span> invoke findClass in order</span><br><span class="line">            // <span class="keyword">to</span> find the <span class="class"><span class="keyword">class</span>.</span></span><br><span class="line">            c =findClass(name);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>大致这是这样。</p>
<h4 id="用户自定义类加载器">用户自定义类加载器</h4><p>通过前面的分析，我们可以看出，要想实现自定义类加载器，除需要继承ClassLoader之外，还有就是覆写findClass()方法，在这里面写自己的操作。<br>一般用户自定义类加载器的工作流程：</p>
<ol>
<li>首先检查请求的类型是否已经被这个类装载器装载到命名空间中了，如果已经装载，直接返回；否则转入步骤2</li>
<li>委派类加载请求给父类加载器（更准确的说应该是双亲类加载器，整个虚拟机中各种类加载器最终会呈现树状结构），如果父类加载器能够完成，则返回父类加载器加载的Class实例；否则转入步骤3</li>
<li>调用本类加载器的findClass（…）方法，试图获取对应的字节码，如果获取的到，则调用defineClass（…）导入类型到方法区；如果获取不到对应的字节码或者其他原因失败，返回异常给loadClass（…）， loadClass（…）转抛异常，终止加载过程（注意：这里的异常种类不止一种）。<br>（说明：这里说的自定义类加载器是指JDK1.2以后版本的写法，即不覆写改变java.lang.loadClass(…)已有委派逻辑情况下）<br>具体就不举例子了！</li>
</ol>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="类加载器作用">类加载器作用</h4><p>当JVM开始运作时需要使用当某个类时，就需要将对应类的字段吗加载到内存中，而类加载器正式负责加载这些类的工具。另外若果多次重复使用一个类的字节码时加载器不会多次加载，而是使用内存中的字节码。</p>
<h4 id="主要]]>
    </summary>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java类之间的关联关系]]></title>
    <link href="http://vickyqi.com/2012/05/19/Java%E7%B1%BB%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E8%81%94%E5%85%B3%E7%B3%BB/"/>
    <id>http://vickyqi.com/2012/05/19/Java类之间的关联关系/</id>
    <published>2012-05-19T12:43:00.000Z</published>
    <updated>2015-10-24T10:12:54.000Z</updated>
    <content type="html"><![CDATA[<p>UML类图中的关系分为四种：<strong>泛化、依赖、关联、实现</strong>；关联关系又可以细化为聚合和组合。</p>
<h4 id="泛化（Generalization）">泛化（Generalization）</h4><p>泛化是父类和子类之间的关系，子类继承父类的所有结构和行为。在子类中可以增加新的结构和行为，也可以覆写父类的行为。<br>一般用一个带空心箭头的实线表示泛化关系，UML图如下：<br><img src="http://my.csdn.net/uploads/201205/19/1337431354_5691.jpg" alt="泛化关系"><br>泛化对应Java中继承关系，即子类继承父类中出private修饰外的所有东西（变量、方法等）。示例代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">public <span class="class"><span class="keyword">class</span><span class="title">　Animal</span> &#123;</span></span><br><span class="line">&#125;</span><br><span class="line">public <span class="class"><span class="keyword">class</span> <span class="title">Tiger</span> <span class="keyword"><span class="keyword">extends</span></span> <span class="title">Animal</span> &#123;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Tiger继承Animal，因此Tiger与Animal之间是泛化（继承）关系。这个很好理解。</p>
<h4 id="依赖（Dependency）">依赖（Dependency）</h4><p>依赖关系是一种使用关系，特定事物的改变有可能会影响到使用该事物的事物，反之不成立。在你想显示一个事物使用另一个事物时使用。<br>一般用一条指向被依赖事物的虚线表示，UML图如下：<br><img src="http://my.csdn.net/uploads/201205/19/1337431458_2379.jpg" alt="依赖关系"><br>通常情况下，依赖关系体现在某个类的方法使用另一个类作为参数。代码示例：<br><figure class="highlight cs"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Screwdriver</span> &#123;    <span class="comment">//螺丝刀，作为人类的工具，是用来被人类使用的</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title">Person</span>&#123;</span><br><span class="line">       <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">screw</span>(<span class="params">Screwdriver src</span>)</span>&#123;    <span class="comment">//拧螺丝，需使用螺丝刀</span></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Person类的screw()方法在使用时就得传入一个Screwdriver类型的参数，这样Screwdriver的改变就会影响到Person，因此Person与Screwdriver之间就是依赖关系（Person依赖于Screwdriver）。</p>
<h4 id="关联（Association）">关联（Association）</h4><p>是一种结构关系，说明一个事物的对象与另一个事物的对象相联系。给定有关联的两个类，可以从一个类的对象得到另一个类的对象。关联有两元关系和多元关系。两元关系是指一种一对一的关系，多元关系是一对多或多对一的关系。两个类之间的简单关联表示了两个同等地位类之间的结构关系。当你想要表示结构化关系时使用关联。（可以想想Hibernate的关联关系）<br>一般用实线连接有关联的同一个类或不同的两个类。UML图如下：<br><img src="http://my.csdn.net/uploads/201205/19/1337431398_4461.jpg" alt="关联关系"><br>通常情况下，关联关系是通过类的成员变量来实现的。代码示例：<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Company</span> </span>&#123;   <span class="comment">//公司</span></span><br><span class="line"><span class="keyword">private</span> Employee emp ;  <span class="comment">//一个公司雇员，公司与雇员之间就是一种关联关系。</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>雇员作为公司的属性，不同于上面的依赖。依赖的话，雇员的改变会影响公司，显然不是。在这里雇员仅仅作为公司的一个属性而存在。因此Employee与Company之间是关联关系。关联关系还可以细分为聚合和组合两种。</p>
<h5 id="聚合（Aggregation）">聚合（Aggregation）</h5><p>聚合是一种特殊的关联。它描述了“has a”关系，表示整体对象拥有部分对象。<br>关联关系和聚合关系来语法上是没办法区分的，从语义 上才能更好的区分两者的区别。聚合是较强的关联关系，强调的是整体与部分 之间的关系。例如，学校和学生的关系。聚合的整体和部分之间在生命周期上没有什么必然的联系，部分对象可以在整体对象创建之前创建，也可以在整体对象销毁之后销毁。<br>一般用带一个空心菱形（整体的一端-学校）的实线表示。UML图如下：<br><img src="http://my.csdn.net/uploads/201205/19/1337431489_2954.jpg" alt="聚合关系"><br>与关联关系一样，聚合关系也是通过类的成员变量来实现的。示例代码：<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span></span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">School</span></span>&#123;  </span><br><span class="line">       <span class="keyword">private</span> <span class="keyword">List</span>&lt;Student&gt; students ;  <span class="comment">//学校与学生是聚合关系</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>学校是整体，而学生是部分。学校与学生都是可以独立存在的，之间没有什么必然的联系。因此学校与学生就是聚合关系。</p>
<h5 id="组合（Composition）">组合（Composition）</h5><p>组合是聚合的一种形式，它具有更强的拥有关系，强调整体与部分的生命周期是一致的，整体负责部分的生命周期的管理。生命周期一致指的是部分必须在组合创建的同时或者之后创建，在组合销毁之前或者同时销毁，部分的生命周期不会超出组合的生命周期。例如Windows的窗口和窗口上的菜单就是组合关系。如果整体被销毁，部分也必须跟着一起被销毁，如果所有者被复制，部分也必须一起被复制。<br>一般用带实心菱形(整体的一端)的实线来表示。UML图如下：<br><img src="http://my.csdn.net/uploads/201205/19/1337431517_8009.jpg" alt="组合关系"><br>与关联关系一样，组合关系也是通过类的成员变量 来实现的。示例代码：<br><figure class="highlight php"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Menu</span></span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Window</span></span>&#123;</span><br><span class="line">       <span class="keyword">private</span> <span class="keyword">List</span>&lt;Menu&gt; menus ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>菜单的存在前提是窗口的存在，两者之间存在很强的拥有关系。且窗口对菜单的生命周期负责，只有在窗口创建之后，菜单才能够创建，菜单必须在窗口销毁之前销毁。因此Window与Menu之间是组合关系。<br><strong>聚合和组合的区别在于：</strong><br>聚合关系是“has-a”关系，组合关系是“contains-a”关系；聚合关系表示整体与部分的关系比较弱，而组合比较强；聚合关系中代表部分事物的对象与代表聚合事物的对象的生存期无关，一旦删除了聚合对象不一定就删除了代表部分事物的对象。组合中一旦删除了组合对象，同时也就删除了代表部分事物的对象。<br>另外有一个差别是组合中的一个对象在同一时刻只能属于一个组合对象，而聚合的一个部分对象可以被多个整体对象聚合，例如一个学生可以在多个学校就读，而一个菜单在同一时刻只能是某个窗口内的对象。</p>
<h4 id="实现（Realization）">实现（Realization）</h4><p>实现关系指定两个实体之间的一个合约。换言之，一个实体定义一个合约，而另一个实体保证履行该合约。对类来说，就是一个类实现了一个接口。<br>一般用一条指向接口的虚线表示，UML图如下：<br><img src="http://my.csdn.net/uploads/201205/19/1337431557_8347.jpg" alt="实现关系"><br>实现对应Java中的实现接口（implements）。示例代码：<br><figure class="highlight actionscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span> <span class="keyword">implements</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这个和泛化一样很好理解。</p>
<h4 id="总结">总结</h4><p>类间关系有很多种，在大的类别上可以分为两种：纵向关系、横向关系。纵向关系就是继承关系，它的概念非常明确，也成为OO的三个重要特征之一，这里不过多的讨论。<br>横向关系较为微妙，按照UML的建议大体上可以分为四种：</p>
<ul>
<li>依赖    （Dependency）</li>
<li>关联    （Association）</li>
<li>聚合    （Aggregation）</li>
<li>组合    （Composition）</li>
</ul>
<p>关于关联，聚合，组合在实现上并没有显著区别，相区别他们只有通过判断关系双方之间的实际关系，如关系强弱、创建与销毁之间有无必要关联等。<br>它们的强弱关系是没有异议的：依赖 &lt; 关联 &lt; 聚合 &lt; 组合&lt;泛化（继承）<br>实现方式区别：</p>
<ul>
<li>依赖关系：关系对象出现在局部变量或者方法的参数里，或者关系类的静态方法被调用</li>
<li>关联关系：关系对象出现在实例变量中</li>
<li>聚合关系:关系对象出现在实例变量中</li>
<li>合成关系：关系对象出现在实例变量中</li>
<li>Generalization: extends</li>
<li>实现： implements</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<p>UML类图中的关系分为四种：<strong>泛化、依赖、关联、实现</strong>；关联关系又可以细化为聚合和组合。</p>
<h4 id="泛化（Generalization）">泛化（Generalization）</h4><p>泛化是父类和子类之间的关系，子类继承父]]>
    </summary>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Session的理解]]></title>
    <link href="http://vickyqi.com/2012/05/19/Session%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://vickyqi.com/2012/05/19/Session的理解/</id>
    <published>2012-05-18T16:13:00.000Z</published>
    <updated>2015-10-24T10:02:24.000Z</updated>
    <content type="html"><![CDATA[<h4 id="个人误区">个人误区</h4><p>&emsp;&emsp;一开始很傻的把Session的会话与用户的登录与退出弄混淆了，实在很傻！Session的会话指的是当你打开浏览器，请求一个应用服务器时开始，直到与这个应用服务器断开连接（如关闭浏览器等）为止的一系列动作。这与用户登录完全没有关系，被弄混淆个人觉得是Session最普遍的用法就是用来控制用户的登录/退出事件的。</p>
<h4 id="Session的理解">Session的理解</h4><h5 id="Session的机制、创建以及保存">Session的机制、创建以及保存</h5><p>&emsp;&emsp;Session机制是一种服务器端的机制，服务器使用一种类似于散列表的结构（也可能就是使用散列表）来保存信息。当程序需要为某个客户端的请求创建一个Session的时候，服务器首先检查这个客户端的请求里是否已包含了一个Session标识 - 称为 Session id，如果已包含一个Session id则说明以前已经为此客户端创建过Session，服务器就按照Session id把这个 Session检索出来使用（如果检索不到，可能会新建一个），如果客户端请求不包含Session id，则为此客户端创建一个Session并且生 成一个与此Session相关联的Session id，Session id的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串，这个 Session id将被在本次响应中返回给客户端保存(客户端一般使用Cookie保存)。<br>&emsp;&emsp;例如：当你打开浏览器时，然后输入一个地址，这个地址其实对应的是一个服务器，当你的请求被服务器响应之后，如上所说服务器首先会根据你发送的请求是否包含一个Session标识（Session-Id），如果有则不新建Session，但若是没有则新建一个Session，并将该Session的ID返回给客户端（浏览器），客户端就将该Session-Id保存到一个Cookie中（一般这个cookie的名字都是类似于SEEESIONID，而。比如weblogic对于web应用程序生成的cookie，JSESSIONID= ByOK3vjFD75aPnrF7C2HmdnV6QZcEbzWoWiBYEnLerjQ99zWpBng!-145788764，它的名字就是 JSESSIONID），然后每次客户端请求一个新的页面时就将该Cookie通过某种机制发送给服务器端，服务器端就知道Session已经创建了，从而不需要再新建一个Session。</p>
<h5 id="Session的销毁">Session的销毁</h5><p>&emsp;&emsp;Session的销毁并不是在浏览器窗口被关闭时。对于Session的销毁除非程序显示的告诉服务器销毁Session，否则服务器不会主动销毁一个Session。<br>然而浏览器从来不会主动在关闭之前通知服务器它将要关闭，因此服务器根本不会有机会知道浏览器已经关闭，之所以会有这种错觉，是大部分session机制都使用会话cookie来保存session id，而关闭浏览器后这个 session id就消失了，再次连接服务器时也就无法找到原来的session。如果服务器设置的cookie被保存到硬盘上，或者使用某种手段改写浏览器发出的HTTP请求头，把原来的session id发送给服务器，则再次打开浏览器仍然能够找到原来的Session。<br>&emsp;&emsp;Session被销毁的另一个原因就是为Session设置了失效时间，即当距离客户端上一次使用Session的时间超过这个失效时间时，服务器就可以认为客户端已经停止了活动，才会把Session销毁以节省存储空间。此时当用户再次访问时，如刷新页面、再次访问等，服务器会重新创建一个Session，并生成一个新的ID。<br>&emsp;&emsp;说明（实验得出，IE8，Google）：当你访问一个服务器之后，关闭窗口(所有浏览器窗口，如IE，那就关闭所有IE窗口，一个不留)，然后再打开访问同样的服务器，这时虽然上一个Session可能未被销毁，但是服务器找不到，因此就会再新建一个Session，这时会有两个Session。但是如果你未完全关不窗口的话，那么就会使用之前的Session。原因是Session-Id是保存在一个Cookie中的(测试时该Cookie名为JSESSIONID)，而这个Cookie的生命周期为浏览器关闭，即浏览器关闭(完全关闭)则该Cookie就会被删除，因此服务器无法通过这个Cookie找到Session-Id，这时服务器就会认为没有Session存在，就会新建一个Session。同时这个Session的Id会覆盖之前的Session-Id，因为使用的是同一个Cookie，而Cookie会覆盖。<br>自己可以做试验！在IE和Google中都是可以查看Cookie的！</p>
<hr>
<p><strong>个人理解，有错欢迎指出！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="个人误区">个人误区</h4><p>&emsp;&emsp;一开始很傻的把Session的会话与用户的登录与退出弄混淆了，实在很傻！Session的会话指的是当你打开浏览器，请求一个应用服务器时开始，直到与这个应用服务器断开连接（如关闭浏览器等）为止的一系列动作。]]>
    </summary>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Session" scheme="http://vickyqi.com/tags/Session/"/>
    
      <category term="Web" scheme="http://vickyqi.com/tags/Web/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Web开发" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/Web%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Struts2整合Spring方法及原理]]></title>
    <link href="http://vickyqi.com/2012/05/13/Struts2%E6%95%B4%E5%90%88Spring%E6%96%B9%E6%B3%95%E5%8F%8A%E5%8E%9F%E7%90%86/"/>
    <id>http://vickyqi.com/2012/05/13/Struts2整合Spring方法及原理/</id>
    <published>2012-05-13T06:44:00.000Z</published>
    <updated>2015-10-24T10:03:04.000Z</updated>
    <content type="html"><![CDATA[<h4 id="Struts_2框架整合Spring步骤">Struts 2框架整合Spring步骤</h4><ol>
<li>复制文件。复制struts2-spring-plugin-x-x-x.jar和spring.jar到WEB-INF/lib目录下。其中的x对应了Spring的版本号。还需要复制commons-logging.jar文件到WEB-INF/lib目录下。</li>
<li><p>配置struts.objectFactory属性值。在struts.properties中设置struts.objectFactory属性值：struts.objectFactory = spring<br>或者在XML文件中进行常量配置：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="title">struts</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">constant</span> <span class="attribute">name</span>=<span class="value">"struts.objectFactory"</span> <span class="attribute">value</span>=<span class="value">"spring"</span> /&gt;</span></span><br><span class="line">       ...</span><br><span class="line"><span class="tag">&lt;/<span class="title">struts</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置Spring监听器。在web.xml文件中增加如下内容：</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;listener&gt;</span><br><span class="line">       &lt;listener-class&gt;</span><br><span class="line">org<span class="class">.springframework</span><span class="class">.web</span><span class="class">.context</span><span class="class">.ContextLoaderListener</span></span><br><span class="line">&lt;/listener-class&gt;</span><br><span class="line">&lt;/listener&gt;</span><br></pre></td></tr></table></figure>
</li>
<li><p>Spring配置文件。默认情况下，Spring配置文件为applicationContext.xml，该文件需要保存在Web应用的WEB-INF目录下。内容示例如下所示：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="pi">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="doctype">&lt;!DOCTYPE beans PUBLIC</span><br><span class="line">       "-//SPRING//DTD BEAN//EN"</span><br><span class="line">       "http://www.springframework.org/dtd/spring-beans.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">beans</span> <span class="attribute">default-autowire</span>=<span class="value">"byName"</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">bean</span> <span class="attribute">id</span>=<span class="value">"personManager"</span> <span class="attribute">class</span>=<span class="value">"com.acme.PersonManager"</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p> 开发者实际上可以使用多个Spring配置文件，在web.xml中进行下列设置，从而使Spring的ApplicationContext通过匹配所给定模式的文件来初始化对象：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 用来定位Spring XML文件的上下文配置 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">context-param</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">param-name</span>&gt;</span>contextConfigLocation<span class="tag">&lt;/<span class="title">param-name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">param-value</span>&gt;</span></span><br><span class="line">/WEB-INF/applicationContext-*.xml,classpath*:applicationContext-*.xml</span><br><span class="line"><span class="tag">&lt;/<span class="title">param-value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="title">context-param</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>修改Struts配置文件。Struts 2框架整合Spring框架，需要在Struts配置文件中有所改变，下面是一个示例：</p>
<figure class="highlight nimrod"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&lt;!<span class="type">DOCTYPE</span> struts <span class="type">PUBLIC</span></span><br><span class="line">       <span class="string">"-//Apache Software Foundation//DTD Struts Configuration 2.0//EN"</span></span><br><span class="line">       <span class="string">"http://struts.apache.org/dtds/struts-2.0.dtd"</span>&gt;</span><br><span class="line">&lt;struts&gt;</span><br><span class="line">       &lt;<span class="keyword">include</span> file=<span class="string">"struts-default.xml"</span>/&gt;</span><br><span class="line">       &lt;package name=<span class="string">"default"</span> extends=<span class="string">"struts-default"</span>&gt;</span><br><span class="line">           &lt;action name=<span class="string">"foo"</span> class=<span class="string">"com.acme.Foo"</span>&gt;</span><br><span class="line">               &lt;<span class="literal">result</span>&gt;foo.ftl&lt;/<span class="literal">result</span>&gt;</span><br><span class="line">           &lt;/action&gt;</span><br><span class="line">       &lt;/package&gt;</span><br><span class="line">       &lt;package name=<span class="string">"secure"</span> namespace=<span class="string">"/secure"</span> extends=<span class="string">"default"</span>&gt;</span><br><span class="line">           &lt;action name=<span class="string">"bar"</span> class=<span class="string">"bar"</span>&gt;</span><br><span class="line">               &lt;<span class="literal">result</span>&gt;bar.ftl&lt;/<span class="literal">result</span>&gt;</span><br><span class="line">           &lt;/action&gt;</span><br><span class="line">       &lt;/package&gt;</span><br><span class="line">&lt;/struts&gt;</span><br></pre></td></tr></table></figure>
<p> 该配置文件中定义了两个Action配置：foo是一个标准的Struts 2框架Action配置，指定了Action实现类为com.acme.Foo；bar对应的class并不存在，那么框架将在Spring配置文件中查找id属性为“bar”的定义，该配置文件如下所示：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="pi">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="doctype">&lt;!DOCTYPE beans PUBLIC</span><br><span class="line">       "-//SPRING//DTD BEAN//EN"</span><br><span class="line">       "http://www.springframework.org/dtd/spring-beans.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">beans</span> <span class="attribute">default-autowire</span>=<span class="value">"byName"</span>&gt;</span></span><br><span class="line">       <span class="tag">&lt;<span class="title">bean</span> <span class="attribute">id</span>=<span class="value">"bar"</span> <span class="attribute">class</span>=<span class="value">"com.my.BarClass"</span> <span class="attribute">singleton</span>=<span class="value">"false"</span>/&gt;</span></span><br><span class="line">       ...</span><br><span class="line"><span class="tag">&lt;/<span class="title">beans</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<h4 id="整合原理">整合原理</h4><p>Struts2与Spring的集成要用到Spring插件包struts2-spring-plugin-x-x-x.jar，这个包是同Struts2一起发布的。Spring插件是通过覆盖（override）Struts2的ObjectFactory来增强核心框架对象的创建。当创建一个对象的时候，它会用Struts2配置文件中的class属性去和Spring配置文件中的id属性进行关联，如果能找到，则由Spring创建，否则由Struts 2框架自身创建，然后由Spring来装配。Spring插件具体有如下几个作用：</p>
<ul>
<li>允许Spring创建Action、Interceptror和Result。</li>
<li>由Struts创建的对象能够被Spring装配。</li>
<li>如果没有使用Spring ObjectFactory，提供了2个拦截器来自动装配action。</li>
<li>开发者不必在Spring中去注册action，尽管可以这么去做，通常Struts框架会自动地从action mapping中创建action对象</li>
</ul>
<p>struts2-spring-plugin-x-x-x.jar插件中有一个struts-plugin.xml文件，该文件内容如下所示：</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="doctype">&lt;!DOCTYPE struts PUBLIC</span><br><span class="line">    "-//Apache Software Foundation//DTD Struts Configuration 2.0//EN"</span><br><span class="line">    "http://struts.apache.org/dtds/struts-2.0.dtd"&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="title">struts</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">bean</span> <span class="attribute">type</span>=<span class="value">"com.opensymphony.xwork2.ObjectFactory"</span> <span class="attribute">name</span>=<span class="value">"spring"</span> <span class="attribute">class</span>=<span class="value">"org.apache.struts2.spring.StrutsSpringObjectFactory"</span> /&gt;</span></span><br><span class="line">   </span><br><span class="line">    <span class="comment">&lt;!--  设置Spring对象工厂为自动 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">constant</span> <span class="attribute">name</span>=<span class="value">"struts.objectFactory"</span> <span class="attribute">value</span>=<span class="value">"spring"</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="title">package</span> <span class="attribute">name</span>=<span class="value">"spring-default"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="title">interceptors</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">interceptor</span> <span class="attribute">name</span>=<span class="value">"autowiring"</span> <span class="attribute">class</span>=<span class="value">"com.opensymphony.xwork2.spring.interceptor.ActionAutowiringInterceptor"</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="title">interceptor</span> <span class="attribute">name</span>=<span class="value">"sessionAutowiring"</span> <span class="attribute">class</span>=<span class="value">"org.apache.struts2.spring.interceptor.SessionContextAutowiringInterceptor"</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="title">interceptors</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="title">package</span>&gt;</span>   </span><br><span class="line"><span class="tag">&lt;/<span class="title">struts</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>其中设置了Struts 2框架常量struts.objectFactory的值为spring，实际上，spring是org.apache.struts2.spring.StrutsSpringObjectFactory类的缩写，默认情况下所有由Struts 2框架创建的对象都是由ObjectFactory实例化的，ObjectFactory提供了与其他IoC容器如Spring、Pico等集成的方法。覆盖这个ObjectFactory的类必须继承ObjectFactory类或者它的任何子类，并且要带有一个不带参数的构造方法。在这里用org.apache.struts2.spring.StrutsSpring ObjectFactory代替了默认的ObjectFactory。<br>如果Action不是使用Spring ObjectFactory创建的话，插件提供了两个拦截器来自动装配Action，默认情况下框架使用的自动装配策略是name，也就是说框架会去Spring中寻找与Action属性名字相同的bean，可选的装配策略还有：type、auto、constructor，开发者可以通过常量struts.objectFactory.spring.autoWire来进行设置。 </p>
<p>Struts 2框架整合Spring后，处理用户请求的Action并不是Struts框架创建的，而是由Spring插件创建的。创建实例时，不是利用配置Action时指定的class属性值，根据bean的配置id属性，从Spring容器中获得相应的实例。</p>
<hr>
<p><strong>声明：本文由网上一篇文章整理所得！</strong></p>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="Struts_2框架整合Spring步骤">Struts 2框架整合Spring步骤</h4><ol>
<li>复制文件。复制struts2-spring-plugin-x-x-x.jar和spring.jar到WEB-INF/lib目录下。其中的x对应了Spri]]>
    </summary>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="Struts2" scheme="http://vickyqi.com/tags/Struts2/"/>
    
      <category term="Web" scheme="http://vickyqi.com/tags/Web/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="Web开发" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/Web%E5%BC%80%E5%8F%91/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Java多线程和同步的理解]]></title>
    <link href="http://vickyqi.com/2012/05/12/Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E5%90%8C%E6%AD%A5%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://vickyqi.com/2012/05/12/Java多线程和同步的理解/</id>
    <published>2012-05-11T16:41:00.000Z</published>
    <updated>2015-10-24T09:44:04.000Z</updated>
    <content type="html"><![CDATA[<h4 id="进程与线程">进程与线程</h4><p>在谈论线程之前，我们先来看看什么叫进程，以及进程与线程的关系。</p>
<h5 id="进程">进程</h5><p>我们在windows操作系统中打开任务管理器，可以看到有一项是“进程”，里面列举出了用户目前正在运行的所有进程，包括系统进程和用户应用程序进程，以及每个进程所占用的内存资源等信息。进程是操作系统结构的基础，它不仅只包括运行的程序代码，还包括当前的活动。对于每一个进程，操作系统都会为其分配一个独立的内存块，各进程间资源是不共享的。<br>划分时间片，宏观上并行，微观上串行</p>
<h5 id="线程">线程</h5><p>一个Java程序运行之后，就会启动一个JVM实例进程，这个进程就负责处理这个程序所有的操作，直到程序结束，进程也随之结束。<br>而线程就是再在进程的内部将CPU资源进行再次划分，以满足同时处理多条语句的需要（微观上，其实也是并行执行的），这些线程在进程内部的资源是共享的（正因如此，才会有同步以及锁的出现）。<br>JVM进程启动一定会有一个主线程存在，即main方法启动的线程，这个线程是Java程序的入口，我们可以在main方法内部在定义我们自己的线程，这样就可以实现多线程了。</p>
<h4 id="Java多线程的实现方式">Java多线程的实现方式</h4><p><strong>java.lang.Thread</strong>类的一个对象就代表一个线程<br>线程是底层OS（操作系统）维护的资源，JVM跑在OS上，在JVM中创建一个Thread对象，调用其start（）方法，底层OS会申请一个线程资源，线程对象可到底层管理一个线程，创建好线程之后，把要让线程执行的代码封装到线程对象中（覆盖run()方法）。<br>实现线程代码的方式：</p>
<ol>
<li><p>继承Thread类，覆盖run()方法<br>去底层申请线程并运行，对线程对象调start()方法，main方法是一个主线程<br>宏观并行，微观串行</p>
</li>
<li><p>实现Runnable接口<br>使用多态获得Runnable对象，成为目标对象<br>再利用目标对象构造线程对象Thread t = new Thread(target);//target为Runnable接口类型<br>对于中两种方法的具体介绍可以参考：<br><a href="http://hi.baidu.com/hi_place/blog/item/84dcf8f283d4f005b17ec51f.html" target="_blank" rel="external">http://hi.baidu.com/hi_place/blog/item/84dcf8f283d4f005b17ec51f.html</a></p>
</li>
</ol>
<h4 id="线程的优先级">线程的优先级</h4><p>线程的优先级是从0-10的整数，0表示最低，5表示普通，10表示最大；JVM会自动将java线程的优先级转换为操作系统的优先级。<br>main线程的优先级是5。</p>
<h4 id="线程的状态">线程的状态</h4><p>下面为线程中的7个非常重要的状态（有的书上也只有认为前五种状态：而将“锁池”和“等待池”都看成是“阻塞”状态的特殊情况：这种认识也是正确的，但是将“锁池”和“等待池”单独分离出来有利于对程序的理解）:</p>
<ol>
<li>初始状态：线程刚创建（Thread th = new Thread(target);）</li>
<li>可运行状态：线程创建之后调用它的start()方法，此时线程状态就变更为可运行状态，但一定就会立即运行，需要等待获得CPU。</li>
<li>运行状态：调用线程的start()方法之后，线程就会进入等待运行状态（可运行状态），此时一旦该线程获得CPU的使用权，县城就会立即进入运行状态，即执行线程的run()方法。</li>
<li>阻塞状态：线程失去CPU的使用权，进入一种等待状态，注意不是可运行状态。有以下三种情况会使线程进入阻塞状态：<br> 4.1 待外部设备输入：如等待键盘输入，则该线程会进入阻塞状态直到输入完毕，注意：阻塞结束之后是进入可运行状态，而不是运行状态。<br> 4.2 程休眠，即调用线程的sleep()方法。Sleep()方法有一个参数，表示休眠的时间，当线程休眠的时间到达指定时间后，线程会自动结束阻塞状态而进入可运行状态，等待CPU。<br> 4.3 一个线程调用另一个线程的join()方法，join()方法指的是调用该方法的线程将进入阻塞状态直到被调用join()方法的线程运行结束之后，才会进入可运行状态。<br>例：在t2线程的run()方法内部有这样一句代码t1.join();(t1是一个线程对象)，这将意味着党线程t2执行到该语句时就会调用线程t1的join()方法，从而t2进入阻塞状态，直到t1运行结束为止。</li>
<li>终止状态：即线程执行结束</li>
<li>锁池状态</li>
<li>等待队列</li>
</ol>
<h4 id="线程的同步">线程的同步</h4><p>之前说过同意进程中的各线程之间是资源共享的，这种资源共享的特性会带来的后果就是线程同步的问题。<br>下面看一个例子：<br><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">publicclass Test &#123;</span><br><span class="line">   <span class="function">publicstaticvoid <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      Thread1 th = <span class="keyword">new</span> Thread1();</span><br><span class="line">      Thread t1 = <span class="keyword">new</span> Thread(th);</span><br><span class="line">      Thread t2 = <span class="keyword">new</span> Thread(th);</span><br><span class="line">      Thread t3 = <span class="keyword">new</span> Thread(th);</span><br><span class="line">      Thread t4 = <span class="keyword">new</span> Thread(th);</span><br><span class="line">      t1.start();</span><br><span class="line">      t2.start();</span><br><span class="line">      t3.start();</span><br><span class="line">      t4.start();</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">class</span> Thread1implements Runnable &#123;</span><br><span class="line">   privateinttickets = <span class="number">100</span>;</span><br><span class="line">   @<span class="function">Override</span><br><span class="line">   publicvoid <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">      <span class="keyword">while</span> (tickets &gt; <span class="number">0</span>) &#123;</span><br><span class="line">         <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(<span class="number">1000</span>);<span class="comment">//休眠1s</span></span><br><span class="line">         &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">         &#125;</span><br><span class="line">         System.out.println(Thread.currentThread().getName() +<span class="string">":"</span></span><br><span class="line">                + tickets--);</span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>这个程序打印出来的结果绝对不是我们想要的。这就是多线程同时操作一个数据会出现的读脏数据等现象。为避免出现这种情况就需要使用到Java线程的同步机制，即锁机制。</p>
<p><strong>Java实现同步有两种方法：Synchronized和Lock。</strong><br>多线程同时并发访问的资源叫做临界资源。多个线程同时访问对象并要求操作相同资源时分割了原子操作就会出现问题。（原子操作，不可再分的操作）会出现数据的不一致或数据不完整，为避免这种现象采用对访问的线程做限制的方法。</p>
<p><strong>Synchronized用法</strong><br>互斥锁机制，利用每个对象都有一个monitor(锁标记)，当线程拥有这个锁标记时才能访问这个资源，没有锁标记便进入锁池。任何一个对象系统都会为其创建一个互斥锁，这个锁是为了分配给线程的，防止打断原子操作。每个对象的锁只能分配给一个线程。<br>(1) Synchronized修饰代码块（同步代码块）<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">char</span> c)</span></span>&#123;</span><br><span class="line">	<span class="keyword">synchronized</span>(<span class="keyword">this</span>)<span class="comment">//只有持有当前对象锁标记的线程才能访问这个代码块</span></span><br><span class="line">	&#123;</span><br><span class="line">		...</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>此时Synchronized锁的是调用该方法的对象（this），也可以选择锁住任何一个对象。<br>(2)     Synchronized修饰方法（同步方法）<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>此时Synchronized锁的是调用该方法的对象，同上面的this。<br>说明：<br>A、无论Synchronized加在方法上还是对象上，它取得锁都是对象，而不是把一段代码或者函数当做锁——而且同步方法还可能会被其他线程的对象访问。<br>B、每个对象只有一个锁与之相关联。<br>C、实现同步需要很大的系统开销作为代价，甚至可能造成死锁，所以尽量避免无谓的同步控制。<br>接下来继续讨论Synchronized加在方法上和加在对象上两者的区别<br>Synchronized加在对象上：<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">char</span> c)</span></span>&#123;</span><br><span class="line">    <span class="keyword">synchronized</span>(<span class="keyword">this</span>)<span class="comment">//只有持有当前对象锁标记的线程才能访问这个代码块</span></span><br><span class="line">    &#123;</span><br><span class="line">	    ...</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>其中的this也可以是任何其他对象，而synchronized所起的作用就是锁住括号中的对象，使得当其他线程需要调用该方法时由于无法取得对括号中的对象的锁而无法继续执行，而进入锁池。<br>线程因为未拿到锁标记而发生阻塞进入锁池（lock pool）。每个对象都有自己的一个锁池的空间，用于放置等待运行的线程。由系统决定哪个线程拿到锁标记并运行。<br>当有一个明确的对象可以用来锁时，我们直接将这个对象锁起来即可，但是当没有一个明确的对象可以用来加锁时，我们可以创建一个对象来充当锁。</p>
<p>Synchronized加在方法上：<br><figure class="highlight aspectj"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">char</span> c)</span> </span>&#123;</span><br><span class="line">	...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>此时synchronized锁住的是当前调用该方法的对象。若p1调用该方法，此p1这个对象会被锁住，那么p1在不同线程中执行该方法时会形成互斥。但是另一个对象p2却可以人任意调用该方法。</p>
<p>Synchronized加在静态方法上：<br>我们知道静态方法是一个class所拥有的公共方法，由这个class实例化得到的所有的对象都具有对这个方法的访问权，因此我们可以想象如果将它锁住，那么其他对象是不是也不能够调用这个方法了呢？答案是是的。<br>public synchronized static void push(char c) {<br>       …<br>    }<br>对静态方法加锁，锁住的是包含这个静态方法的Class类，即字节码，因此由这份字节码生成的所有对象都将无法调用该方法。</p>
<p><strong>Lock的用法</strong><br>  java.util.concurrent.locks中的Lock接口，有多个实现类，调用lock和unlock方法，实现和synchronized一样的功能；<br>ReadWriteLock接口，有两个获得锁的方法，读锁和写锁。<br>读写锁特征:</p>
<ul>
<li>如果读锁被一个线程锁住了，则其他线程可以再锁读锁，但不允许写锁<br>一个线程读操作，也允许其他线程做读操作，但不允许做写操作</li>
<li>如果写锁被一个线程锁住了，则其他线程读锁和写锁都不可以锁锁<br>一个线程写操作，其他线程读写操作都不可以。</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="进程与线程">进程与线程</h4><p>在谈论线程之前，我们先来看看什么叫进程，以及进程与线程的关系。</p>
<h5 id="进程">进程</h5><p>我们在windows操作系统中打开任务管理器，可以看到有一项是“进程”，里面列举出了用户目前正在运行的所有进]]>
    </summary>
    
      <category term="Java" scheme="http://vickyqi.com/tags/Java/"/>
    
      <category term="并发" scheme="http://vickyqi.com/tags/%E5%B9%B6%E5%8F%91/"/>
    
      <category term="Java学习" scheme="http://vickyqi.com/categories/Java%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
